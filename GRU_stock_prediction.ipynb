{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU-stock-prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sbxpN8jRHG8"
      },
      "source": [
        "PyTorch GRU based stock prediction model. Inspired by this Medium [article](https://towardsdatascience.com/lstm-time-series-forecasting-predicting-stock-prices-using-an-lstm-model-6223e9644a2f) and this Kaggle [post](https://www.kaggle.com/taronzakaryan/stock-prediction-lstm-using-pytorch) on stock prediction. I wanted to benchmark how a GRU performed compared to the LSTMs used previously."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIR4MstFNl2v",
        "outputId": "79651cfd-fcb4-4f59-b3d3-3cc3cc7cb8e0"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "\r\n",
        "!ls \"/content/gdrive/My Drive/GRU Stock Prediction/datasets\"\r\n",
        "\r\n",
        "PATH = '/content/gdrive/My Drive/GRU Stock Prediction/datasets/{symbol}'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "TSLA.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe5IJRZVPWET"
      },
      "source": [
        "import os\r\n",
        "import math\r\n",
        "import random\r\n",
        "import datetime\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "mSKnU1ynQywl",
        "outputId": "c8349e1c-8d37-4a50-f0e1-0772b7a2a47a"
      },
      "source": [
        "def fetch_df(symbols, dates, scale=True):\r\n",
        "    '''\r\n",
        "    csv loader and scaler for dataset\r\n",
        "    source: https://blog.floydhub.com/gru-with-pytorch/\r\n",
        "    '''\r\n",
        "    df = pd.DataFrame(index=dates)\r\n",
        "    label_scalers = {}\r\n",
        "\r\n",
        "    for symbol in symbols:\r\n",
        "        df_temp = pd.read_csv(PATH.format(symbol=symbol+'.csv'), index_col='Date', parse_dates=True, usecols=['Date', 'Close'], na_values=['nan'])\r\n",
        "        df_temp = df_temp.rename(columns={'Close': symbol})\r\n",
        "        df = df.join(df_temp)\r\n",
        "        if scale:\r\n",
        "            # normalize input features\r\n",
        "            sc = MinMaxScaler()\r\n",
        "            label_sc = MinMaxScaler()\r\n",
        "            data = sc.fit_transform(df_temp.values) \r\n",
        "\r\n",
        "            # store scaling for the labels when evaluating output\r\n",
        "            label_sc.fit(df.iloc[:,0].values.reshape(-1,1))\r\n",
        "            label_scalers[symbol] = label_sc\r\n",
        "\r\n",
        "    return df\r\n",
        "\r\n",
        "symbols = ['TSLA']\r\n",
        "dates = pd.date_range(start='2015-07-10',end='2020-07-10',freq='B')\r\n",
        "df = fetch_df(symbols, dates)\r\n",
        "\r\n",
        "print('Data shape:',df.shape)\r\n",
        "print(df.head(5))\r\n",
        "\r\n",
        "df = df.fillna(method='ffill')\r\n",
        "df.interpolate().plot()\r\n",
        "plt.xlabel('Date')\r\n",
        "plt.ylabel('Close')\r\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data shape: (1306, 1)\n",
            "                 TSLA\n",
            "2015-07-10  51.830002\n",
            "2015-07-13  52.431999\n",
            "2015-07-14  53.130001\n",
            "2015-07-15  52.627998\n",
            "2015-07-16  53.335999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzpyB1nkTJdg"
      },
      "source": [
        "Split into test and training sets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82l00NFhOBWW",
        "outputId": "85fc4cd8-59b6-41e0-d904-d0ba8cedffb9"
      },
      "source": [
        "# def min_max_scalar(x, feature_range=(0,1), dim=0):\r\n",
        "#     '''\r\n",
        "#     replicates behaviour of sklearn.preprocessing.MinMaxScalar\r\n",
        "#     '''\r\n",
        "#     x_std = (x - x.min(dim, keepdim=True).values) / (x.max(dim, keepdim=True).values - x.min(dim, keepdim=True).values)\r\n",
        "#     x_scaled = x_std * (feature_range[1] - feature_range[0]) + feature_range[0]\r\n",
        "#     return x_scaled, x_std\r\n",
        "\r\n",
        "\r\n",
        "def symbol_loader(df, symbol, lookback=20, test_split=0.2, shuffle=False):\r\n",
        "    '''\r\n",
        "    convert df of symbol close prices to a tensor array with (n-lookback) sequences of `lookback`\r\n",
        "    '''\r\n",
        "    price = torch.tensor(df[symbol].values)\r\n",
        "    T = len(price) - lookback\r\n",
        "    data = torch.zeros(T, lookback)\r\n",
        "\r\n",
        "    for i in range(T):\r\n",
        "        data[i,:] = price[i:i+lookback]\r\n",
        "    \r\n",
        "    print(data.shape)\r\n",
        "    data = data.view(T, 1, -1)\r\n",
        "    print(data.shape)\r\n",
        "\r\n",
        "    test_size = int(test_split * T)\r\n",
        "    train_size = T - test_size\r\n",
        "\r\n",
        "    idx = list(range(T))\r\n",
        "\r\n",
        "    if shuffle:\r\n",
        "        random.shuffle(idx)\r\n",
        "\r\n",
        "    x_train = data[idx[:train_size], :, :-1]\r\n",
        "    y_train = data[idx[:train_size], 0, -1]\r\n",
        "    x_test = data[idx[train_size:test_size+train_size], :, :-1]\r\n",
        "    y_test = data[idx[train_size:test_size+train_size], 0, -1]\r\n",
        "\r\n",
        "    return x_train, y_train, x_test, y_test, idx\r\n",
        "\r\n",
        "\r\n",
        "lookback = 20\r\n",
        "x_train, y_train, x_test, y_test, idx = symbol_loader(df, 'TSLA', lookback)\r\n",
        "\r\n",
        "print('x_train.shape:', x_train.shape)\r\n",
        "print('y_train.shape:', y_train.shape)\r\n",
        "print('x_test.shape:', x_test.shape)\r\n",
        "print('y_test.shape:', y_test.shape)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1286, 20])\n",
            "torch.Size([1286, 1, 20])\n",
            "x_train.shape: torch.Size([1029, 1, 19])\n",
            "y_train.shape: torch.Size([1029])\n",
            "x_test.shape: torch.Size([257, 1, 19])\n",
            "y_test.shape: torch.Size([257])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m15oMaBCodyH"
      },
      "source": [
        "# print(x_train)\r\n",
        "# print(x_train.min(0, keepdim=True).values)\r\n",
        "# print(x_train - x_train.min(0, keepdim=True).values)\r\n",
        "\r\n",
        "# sc = MinMaxScaler()\r\n",
        "# lsc = MinMaxScaler()\r\n",
        "# data = sc.fit_transform(df.values)\r\n",
        "# lsc.fit(df.iloc[:,0].values.reshape(-1,1))\r\n",
        "# print(lsc.inverse_transform(data))"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeMBJ1gFmA8g"
      },
      "source": [
        "class GRUNet(nn.Module):\r\n",
        "    def __init__(self, input_dim, hidden_dim, n_layers, output_dim, drop=0.2, bi=False):\r\n",
        "        super(GRUNet, self).__init__()\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        "        self.n_layers = n_layers\r\n",
        "\r\n",
        "        # n_layers stacked GRU cells - dropout applied except last layer\r\n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop, bidirectional=bi)\r\n",
        "        # ReLU activation\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "        # fully connected final layer\r\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\r\n",
        "    \r\n",
        "\r\n",
        "    def init_hidden(self, batch_size):\r\n",
        "        weight = next(self.parameters()).data\r\n",
        "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\r\n",
        "        return hidden\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, x, h):\r\n",
        "        x, h = self.gru(x,h)\r\n",
        "        x = self.fc(self.relu(x[:,-1]))\r\n",
        "        return x, h\r\n",
        "\r\n",
        "class LSTMNet(nn.Module):\r\n",
        "    def __init__(self, input_dim, hidden_dim, n_layers, output_dim, drop=0.2):\r\n",
        "        super(LSTMNet, self).__init__()\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        "        self.n_layers = n_layers\r\n",
        "\r\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop)\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\r\n",
        "    \r\n",
        "\r\n",
        "    def init_hidden(self, batch_size):\r\n",
        "        weight = next(self.parameters()).data\r\n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device), \r\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\r\n",
        "        return hidden\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, x, h):\r\n",
        "        x, h = self.lstm(x,h)\r\n",
        "        x = self.fc(self.relu(x[:,-1]))\r\n",
        "        return x, h\r\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PBYpfhemBTv"
      },
      "source": [
        "def model_summary(model):\r\n",
        "    print('Model Summary\\n')\r\n",
        "    print('Layer Name'+'\\t'*7+'Number of Parameters')\r\n",
        "    print('='*100)\r\n",
        "    model_parameters = [layer for layer in model.parameters() if layer.requires_grad]\r\n",
        "    layer_name = [child for child in model.children()]\r\n",
        "    j = 0\r\n",
        "    total_params = 0\r\n",
        "    print('\\t'*10)\r\n",
        "    for i in layer_name:\r\n",
        "      print()\r\n",
        "      param = 0\r\n",
        "      try:\r\n",
        "        bias = (i.bias is not None)\r\n",
        "      except:\r\n",
        "        bias = False  \r\n",
        "      if not bias:\r\n",
        "        param = model_parameters[j].numel()+model_parameters[j+1].numel()\r\n",
        "        j = j + 2\r\n",
        "      else:\r\n",
        "        param = model_parameters[j].numel()\r\n",
        "        j = j + 1\r\n",
        "      print(str(i)+'\\t'*3+str(param))\r\n",
        "      total_params+=param\r\n",
        "    print('='*100)\r\n",
        "    print(f'Total Params:{total_params}')\r\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESVLjAOJymiT"
      },
      "source": [
        "'''\r\n",
        "Set parameters, initialize dataloader\r\n",
        "'''\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "batch_size = 8\r\n",
        "epochs = 4\r\n",
        "lr = 0.0001\r\n",
        "\r\n",
        "train_data = TensorDataset(x_train, y_train)\r\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\r\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WKGvaN1ruIQY",
        "outputId": "49f4fe6a-cb26-4472-9e61-21b15bb6ae49"
      },
      "source": [
        "def train(trainloader, lr, hidden_dim=128, epochs=5, n_layers=2, model='GRU'):\r\n",
        "    input_dim = next(iter(train_loader))[0].shape[1]\r\n",
        "    output_dim = 1\r\n",
        "    \r\n",
        "    '''instantiate models'''\r\n",
        "    if model == 'GRU':\r\n",
        "        net = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\r\n",
        "    else:\r\n",
        "        net = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\r\n",
        "    model_summary(net)\r\n",
        "    net.to(device)\r\n",
        "    net.train()\r\n",
        "\r\n",
        "    '''criterion and optimizer'''\r\n",
        "    criterion = nn.MSELoss()\r\n",
        "    optimizer = optim.Adam(net.parameters(), lr=lr)\r\n",
        "\r\n",
        "    '''train for specified epochs'''\r\n",
        "    print('Starting training...')\r\n",
        "    start = time.time()\r\n",
        "\r\n",
        "    losses = []\r\n",
        "\r\n",
        "    for epoch in range(epochs):\r\n",
        "        h = net.init_hidden(batch_size)\r\n",
        "        running_loss = 0.\r\n",
        "        for i, data in enumerate(trainloader, 0):\r\n",
        "            optimizer.zero_grad()\r\n",
        "            net.zero_grad()\r\n",
        "\r\n",
        "            input, label = data\r\n",
        "\r\n",
        "            if model == 'GRU':\r\n",
        "                h = h.data\r\n",
        "            else:\r\n",
        "                h = tuple([h_.data for h_ in h])\r\n",
        "          \r\n",
        "            out, h = net(input.to(device).float(), h)\r\n",
        "            loss = criterion(out, label.to(device).float())\r\n",
        "\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            running_loss += loss.item()\r\n",
        "\r\n",
        "            if i % 20 == 0:\r\n",
        "                print('Epoch: {} \\tStep: {}/{} \\tAverage loss: {}'.format(epoch+1, i, len(trainloader), running_loss/i))\r\n",
        "                losses.append(running_loss)\r\n",
        "\r\n",
        "    print('Training complete... Final Loss: {}\\nSeconds elapsed:{}'.format(loss, time.time()-start))\r\n",
        "    return net\r\n",
        "\r\n",
        "\r\n",
        "train(train_loader, lr)\r\n",
        "\r\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Summary\n",
            "\n",
            "Layer Name\t\t\t\t\t\t\tNumber of Parameters\n",
            "====================================================================================================\n",
            "\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "GRU(1, 128, batch_first=True, dropout=0.2)\t\t\t384\n",
            "\n",
            "ReLU()\t\t\t49536\n",
            "\n",
            "Linear(in_features=128, out_features=2, bias=True)\t\t\t384\n",
            "====================================================================================================\n",
            "Total Params:50304\n",
            "Starting training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-0f3f81a04898>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-0f3f81a04898>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trainloader, lr, hidden_dim, epochs, n_layers, model)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-eff584e25ca3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    178\u001b[0m             raise RuntimeError(\n\u001b[1;32m    179\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 180\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 1, got 19"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBaUOPVl64rV",
        "outputId": "db8af6cb-3721-4321-b342-8fb3c6a4da44"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1609286017.8016949"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    }
  ]
}