{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU-stock-prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sbxpN8jRHG8"
      },
      "source": [
        "PyTorch GRU based stock prediction model. Inspired by this Medium [article](https://towardsdatascience.com/lstm-time-series-forecasting-predicting-stock-prices-using-an-lstm-model-6223e9644a2f) and this Kaggle [post](https://www.kaggle.com/taronzakaryan/stock-prediction-lstm-using-pytorch) on stock prediction. I wanted to benchmark how a GRU performed compared to the LSTMs used previously."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIR4MstFNl2v",
        "outputId": "ed2aa079-14ca-470e-877e-7bb695f75f75"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "\r\n",
        "!ls \"/content/gdrive/My Drive/GRU Stock Prediction/datasets\"\r\n",
        "\r\n",
        "PATH = '/content/gdrive/My Drive/GRU Stock Prediction/datasets/{symbol}'"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "IBM.csv  TSLA.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe5IJRZVPWET"
      },
      "source": [
        "import os\r\n",
        "import math\r\n",
        "import random\r\n",
        "import time\r\n",
        "import datetime\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "mSKnU1ynQywl",
        "outputId": "169c843a-1050-47b3-ca1e-ffb52c74c952"
      },
      "source": [
        "def fetch_df(symbols, dates, scale=True):\r\n",
        "    '''\r\n",
        "    csv loader and scaler for dataset\r\n",
        "    source: https://blog.floydhub.com/gru-with-pytorch/\r\n",
        "    '''\r\n",
        "    df = pd.DataFrame(index=dates)\r\n",
        "    label_scalers = {}\r\n",
        "\r\n",
        "    for symbol in symbols:\r\n",
        "        df_temp = pd.read_csv(PATH.format(symbol=symbol+'.csv'), index_col='Date', parse_dates=True, usecols=['Date', 'Close'], na_values=['nan'])\r\n",
        "        df_temp = df_temp.rename(columns={'Close': symbol})\r\n",
        "        if scale:\r\n",
        "            # normalize input features\r\n",
        "            sc = MinMaxScaler()\r\n",
        "            label_sc = MinMaxScaler()\r\n",
        "            data = sc.fit_transform(df_temp.values) \r\n",
        "\r\n",
        "            # store scaling for the labels when evaluating output\r\n",
        "            label_sc.fit(df_temp.iloc[:,0].values.reshape(-1,1))\r\n",
        "            label_scalers[symbol] = label_sc\r\n",
        "\r\n",
        "            df_temp[:] = data\r\n",
        "        \r\n",
        "        df = df.join(df_temp)\r\n",
        "        \r\n",
        "    return df, label_scalers\r\n",
        "\r\n",
        "# symbols = ['TSLA']\r\n",
        "symbols = ['IBM']\r\n",
        "dates = pd.date_range(start='1962-01-02',end='2020-12-31 ',freq='B')\r\n",
        "df, label_scalers = fetch_df(symbols, dates, scale=False)\r\n",
        "\r\n",
        "print('Data shape:',df.shape)\r\n",
        "print(df.head(5))\r\n",
        "\r\n",
        "df = df.fillna(method='ffill')\r\n",
        "df.interpolate().plot()\r\n",
        "plt.xlabel('Date')\r\n",
        "plt.ylabel('Close')\r\n",
        "plt.show()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data shape: (15393, 1)\n",
            "                 IBM\n",
            "1962-01-02  7.626667\n",
            "1962-01-03  7.693333\n",
            "1962-01-04  7.616667\n",
            "1962-01-05  7.466667\n",
            "1962-01-08  7.326667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzpyB1nkTJdg"
      },
      "source": [
        "Split into test and training sets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82l00NFhOBWW",
        "outputId": "9fd24475-8f05-4e9b-b147-12ce452f55f4"
      },
      "source": [
        "# def min_max_scalar(x, feature_range=(0,1), dim=0):\r\n",
        "#     '''\r\n",
        "#     replicates behaviour of sklearn.preprocessing.MinMaxScalar\r\n",
        "#     '''\r\n",
        "#     x_std = (x - x.min(dim, keepdim=True).values) / (x.max(dim, keepdim=True).values - x.min(dim, keepdim=True).values)\r\n",
        "#     x_scaled = x_std * (feature_range[1] - feature_range[0]) + feature_range[0]\r\n",
        "#     return x_scaled, x_std\r\n",
        "\r\n",
        "\r\n",
        "def symbol_loader(df, symbol, lookback=20, test_split=0.2, shuffle=False):\r\n",
        "    '''\r\n",
        "    convert df of symbol close prices to a tensor array with (n-lookback) sequences of `lookback`\r\n",
        "    '''\r\n",
        "    price = torch.tensor(df[symbol].values)\r\n",
        "    T = len(price) - lookback\r\n",
        "    data = torch.zeros(T, lookback)\r\n",
        "\r\n",
        "    for i in range(T):\r\n",
        "        data[i,:] = price[i:i+lookback]\r\n",
        "    \r\n",
        "    test_size = int(test_split * T)\r\n",
        "    train_size = T - test_size\r\n",
        "\r\n",
        "    idx = list(range(T))\r\n",
        "\r\n",
        "    if shuffle:\r\n",
        "        random.shuffle(idx)\r\n",
        "\r\n",
        "    print(data.shape)\r\n",
        "    data = data.view(T, -1, 1)\r\n",
        "    print(data.shape)\r\n",
        "\r\n",
        "    x_train = data[idx[:train_size], :-1, :]\r\n",
        "    y_train = data[idx[:train_size], -1, :]\r\n",
        "    x_test = data[idx[train_size:test_size+train_size], :-1, :]\r\n",
        "    y_test = data[idx[train_size:test_size+train_size], -1, :]\r\n",
        "\r\n",
        "    return x_train, y_train, x_test, y_test, idx\r\n",
        "\r\n",
        "\r\n",
        "lookback = 20\r\n",
        "x_train, y_train, x_test, y_test, idx = symbol_loader(df, 'IBM', lookback)\r\n",
        "\r\n",
        "print('x_train.shape:', x_train.shape)\r\n",
        "print('y_train.shape:', y_train.shape)\r\n",
        "print('x_test.shape:', x_test.shape)\r\n",
        "print('y_test.shape:', y_test.shape)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15373, 20])\n",
            "torch.Size([15373, 20, 1])\n",
            "x_train.shape: torch.Size([12299, 19, 1])\n",
            "y_train.shape: torch.Size([12299, 1])\n",
            "x_test.shape: torch.Size([3074, 19, 1])\n",
            "y_test.shape: torch.Size([3074, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeMBJ1gFmA8g"
      },
      "source": [
        "class GRUNet(nn.Module):\r\n",
        "    def __init__(self, input_dim, hidden_dim, n_layers, output_dim, drop=0.2, bi=False, activation='relu'):\r\n",
        "        super(GRUNet, self).__init__()\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        "        self.n_layers = n_layers\r\n",
        "\r\n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop, bidirectional=bi)\r\n",
        "        if activation == 'relu':\r\n",
        "            self.act = nn.ReLU()\r\n",
        "        else:\r\n",
        "            self.act = nn.Tanh()\r\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\r\n",
        "    \r\n",
        "\r\n",
        "    def init_hidden(self, batch_size):\r\n",
        "        weight = next(self.parameters()).data\r\n",
        "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\r\n",
        "        return hidden\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, x, h):\r\n",
        "        x, h = self.gru(x,h)\r\n",
        "        x = self.fc(self.act(x[:,-1]))\r\n",
        "        return x, h\r\n",
        "\r\n",
        "class LSTMNet(nn.Module):\r\n",
        "    def __init__(self, input_dim, hidden_dim, n_layers, output_dim, drop=0.2, activation='relu'):\r\n",
        "        super(LSTMNet, self).__init__()\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        "        self.n_layers = n_layers\r\n",
        "\r\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop)\r\n",
        "        if activation == 'relu':\r\n",
        "            self.act = nn.ReLU()\r\n",
        "        else:\r\n",
        "            self.act = nn.Tanh()\r\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\r\n",
        "    \r\n",
        "\r\n",
        "    def init_hidden(self, batch_size):\r\n",
        "        weight = next(self.parameters()).data\r\n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device), \r\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\r\n",
        "        return hidden\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, x, h):\r\n",
        "        x, h = self.lstm(x,h)\r\n",
        "        x = self.fc(self.act(x[:,-1]))\r\n",
        "        return x, h\r\n"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PBYpfhemBTv"
      },
      "source": [
        "def model_summary(model):\r\n",
        "    print('Model Summary\\n')\r\n",
        "    print('Layer Name'+'\\t'*7+'Number of Parameters')\r\n",
        "    print('='*100)\r\n",
        "    model_parameters = [layer for layer in model.parameters() if layer.requires_grad]\r\n",
        "    layer_name = [child for child in model.children()]\r\n",
        "    j = 0\r\n",
        "    total_params = 0\r\n",
        "    print('\\t'*10)\r\n",
        "    for i in layer_name:\r\n",
        "        print()\r\n",
        "        param = 0\r\n",
        "        try:\r\n",
        "            bias = (i.bias is not None)\r\n",
        "        except:\r\n",
        "            bias = False  \r\n",
        "        if not bias:\r\n",
        "            param = model_parameters[j].numel()+model_parameters[j+1].numel()\r\n",
        "            j = j + 2\r\n",
        "        else:\r\n",
        "            param = model_parameters[j].numel()\r\n",
        "            j = j + 1\r\n",
        "        print(str(i)+'\\t'*3+str(param))\r\n",
        "        total_params+=param\r\n",
        "    print('='*100)\r\n",
        "    print(f'Total Params:{total_params}')\r\n"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESVLjAOJymiT"
      },
      "source": [
        "'''\r\n",
        "Set parameters, initialize dataloader\r\n",
        "'''\r\n",
        "batch_size = 16\r\n",
        "epochs = 100\r\n",
        "lr = 0.001\r\n",
        "\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "traindata = TensorDataset(x_train, y_train)\r\n",
        "trainloader = DataLoader(traindata, shuffle=True, batch_size=batch_size, drop_last=True)\r\n",
        "testdata = TensorDataset(x_test, y_test)\r\n",
        "testloader = DataLoader(testdata, shuffle=True, batch_size=batch_size, drop_last=True)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKGvaN1ruIQY",
        "outputId": "89e48aa5-9c2d-430d-e0d3-5ca002b2c884"
      },
      "source": [
        "def validate(net, testloader, model='GRU'):\r\n",
        "    criterion = nn.MSELoss()\r\n",
        "    loss = 0\r\n",
        "\r\n",
        "    # net.eval()\r\n",
        "\r\n",
        "    h = net.init_hidden(batch_size)\r\n",
        "    if model == 'GRU':\r\n",
        "        h = h.data\r\n",
        "    else:\r\n",
        "        h = tuple([h_ for h_ in h])\r\n",
        "    \r\n",
        "    for i, data in enumerate(testloader, 0):\r\n",
        "        input, label = data\r\n",
        "        input, label = input.to(device), label.to(device)\r\n",
        "        with torch.no_grad():\r\n",
        "            output, h = net(input, h)\r\n",
        "            loss += criterion(output, label.to(device).float())\r\n",
        "\r\n",
        "    return loss / len(testloader)\r\n",
        "\r\n",
        "def train(trainloader, testloader, lr=0.01, hidden_dim=128, epochs=5, n_layers=2, model='GRU', act='relu', drop=0.2):\r\n",
        "    input_dim = next(iter(trainloader))[0].shape[2]\r\n",
        "    output_dim = 1\r\n",
        "    \r\n",
        "    '''instantiate models'''\r\n",
        "    if model == 'GRU':\r\n",
        "        net = GRUNet(input_dim, hidden_dim, n_layers, output_dim, drop=drop, activation=act)\r\n",
        "    else:\r\n",
        "        net = LSTMNet(input_dim, hidden_dim, n_layers, output_dim, drop=drop, activation=act)\r\n",
        "    # model_summary(net)\r\n",
        "    net.to(device)\r\n",
        "    net.train()\r\n",
        "\r\n",
        "    '''criterion and optimizer'''\r\n",
        "    criterion = nn.MSELoss()\r\n",
        "    optimizer = optim.Adam(net.parameters(), lr=lr)\r\n",
        "\r\n",
        "    '''train for specified epochs'''\r\n",
        "    print('Starting training...')\r\n",
        "    start = time.time()\r\n",
        "\r\n",
        "    losses = []\r\n",
        "    val_losses = []\r\n",
        "    c = 0\r\n",
        "\r\n",
        "    for epoch in range(epochs):\r\n",
        "        h = net.init_hidden(batch_size)\r\n",
        "        running_loss = 0.\r\n",
        "        \r\n",
        "        for i, data in enumerate(trainloader, 1):\r\n",
        "            input, label = data\r\n",
        "\r\n",
        "            optimizer.zero_grad()\r\n",
        "            net.zero_grad()\r\n",
        "\r\n",
        "            if model == 'GRU':\r\n",
        "                h = h.data\r\n",
        "            else:\r\n",
        "                h = tuple([h_.data for h_ in h])\r\n",
        "\r\n",
        "\r\n",
        "            out, h = net(input.to(device).float(), h)\r\n",
        "            loss = criterion(out, label.to(device).float())\r\n",
        "\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            running_loss += loss.item()\r\n",
        "            # losses.append(loss.item())\r\n",
        "\r\n",
        "            if c % 100 == 0:\r\n",
        "                val_loss = validate(net, testloader, model=model)\r\n",
        "                print('Epoch: {} \\tStep: {}/{} \\tAverage training loss: {:.5f}\\tAverage validation loss: {:.5f}'.format(epoch+1, i, len(trainloader), running_loss/i, val_loss))\r\n",
        "                losses.append(loss.item())\r\n",
        "                val_losses.append(val_loss)\r\n",
        "\r\n",
        "            c += 1   \r\n",
        "\r\n",
        "    print('Training complete... Final Loss: {}\\nSeconds elapsed:{}'.format(loss, time.time()-start))\r\n",
        "    return net, losses, val_losses\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "lstm_net, lstm_loss, lstm_val_loss = train(trainloader, testloader, lr, model='LSTM', n_layers=2, epochs=epochs, act='tanh', drop=0.2)\r\n",
        "gru_net, gru_loss, gru_val_loss = train(trainloader, testloader, lr, model='GRU', n_layers=2, epochs=epochs, act='tanh', drop=0.2)\r\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Epoch: 1 \tStep: 1/768 \tAverage training loss: 5356.57861\tAverage validation loss: 24914.97266\n",
            "Epoch: 1 \tStep: 101/768 \tAverage training loss: 2129.83354\tAverage validation loss: 20883.08398\n",
            "Epoch: 1 \tStep: 201/768 \tAverage training loss: 1842.68909\tAverage validation loss: 18776.98047\n",
            "Epoch: 1 \tStep: 301/768 \tAverage training loss: 1673.28755\tAverage validation loss: 17233.45312\n",
            "Epoch: 1 \tStep: 401/768 \tAverage training loss: 1546.98399\tAverage validation loss: 16289.48047\n",
            "Epoch: 1 \tStep: 501/768 \tAverage training loss: 1437.81115\tAverage validation loss: 15322.38574\n",
            "Epoch: 1 \tStep: 601/768 \tAverage training loss: 1330.52635\tAverage validation loss: 13605.10449\n",
            "Epoch: 1 \tStep: 701/768 \tAverage training loss: 1230.35663\tAverage validation loss: 12116.91602\n",
            "Epoch: 2 \tStep: 33/768 \tAverage training loss: 402.66461\tAverage validation loss: 10890.47070\n",
            "Epoch: 2 \tStep: 133/768 \tAverage training loss: 390.62860\tAverage validation loss: 9799.00391\n",
            "Epoch: 2 \tStep: 233/768 \tAverage training loss: 353.42182\tAverage validation loss: 8876.64648\n",
            "Epoch: 2 \tStep: 333/768 \tAverage training loss: 321.03240\tAverage validation loss: 8032.68311\n",
            "Epoch: 2 \tStep: 433/768 \tAverage training loss: 287.50350\tAverage validation loss: 7357.93750\n",
            "Epoch: 2 \tStep: 533/768 \tAverage training loss: 258.06763\tAverage validation loss: 6814.81982\n",
            "Epoch: 2 \tStep: 633/768 \tAverage training loss: 236.80518\tAverage validation loss: 6318.60498\n",
            "Epoch: 2 \tStep: 733/768 \tAverage training loss: 218.39204\tAverage validation loss: 5874.57520\n",
            "Epoch: 3 \tStep: 65/768 \tAverage training loss: 61.85361\tAverage validation loss: 5498.81982\n",
            "Epoch: 3 \tStep: 165/768 \tAverage training loss: 58.24152\tAverage validation loss: 5214.98340\n",
            "Epoch: 3 \tStep: 265/768 \tAverage training loss: 58.91322\tAverage validation loss: 4904.60840\n",
            "Epoch: 3 \tStep: 365/768 \tAverage training loss: 57.47840\tAverage validation loss: 4602.68945\n",
            "Epoch: 3 \tStep: 465/768 \tAverage training loss: 53.27158\tAverage validation loss: 4369.64551\n",
            "Epoch: 3 \tStep: 565/768 \tAverage training loss: 50.36055\tAverage validation loss: 4132.33105\n",
            "Epoch: 3 \tStep: 665/768 \tAverage training loss: 46.93509\tAverage validation loss: 3930.38086\n",
            "Epoch: 3 \tStep: 765/768 \tAverage training loss: 44.08621\tAverage validation loss: 3754.43066\n",
            "Epoch: 4 \tStep: 97/768 \tAverage training loss: 20.32867\tAverage validation loss: 3603.50879\n",
            "Epoch: 4 \tStep: 197/768 \tAverage training loss: 17.62398\tAverage validation loss: 3481.92822\n",
            "Epoch: 4 \tStep: 297/768 \tAverage training loss: 16.60299\tAverage validation loss: 3353.16479\n",
            "Epoch: 4 \tStep: 397/768 \tAverage training loss: 15.69093\tAverage validation loss: 3220.80859\n",
            "Epoch: 4 \tStep: 497/768 \tAverage training loss: 14.92901\tAverage validation loss: 3106.39551\n",
            "Epoch: 4 \tStep: 597/768 \tAverage training loss: 14.27407\tAverage validation loss: 2990.44922\n",
            "Epoch: 4 \tStep: 697/768 \tAverage training loss: 13.81276\tAverage validation loss: 2877.51343\n",
            "Epoch: 5 \tStep: 29/768 \tAverage training loss: 9.18892\tAverage validation loss: 2793.77441\n",
            "Epoch: 5 \tStep: 129/768 \tAverage training loss: 7.36075\tAverage validation loss: 2725.10254\n",
            "Epoch: 5 \tStep: 229/768 \tAverage training loss: 6.62911\tAverage validation loss: 2662.10840\n",
            "Epoch: 5 \tStep: 329/768 \tAverage training loss: 6.93796\tAverage validation loss: 2580.60352\n",
            "Epoch: 5 \tStep: 429/768 \tAverage training loss: 6.56254\tAverage validation loss: 2522.35840\n",
            "Epoch: 5 \tStep: 529/768 \tAverage training loss: 6.27162\tAverage validation loss: 2465.95605\n",
            "Epoch: 5 \tStep: 629/768 \tAverage training loss: 6.09882\tAverage validation loss: 2414.89624\n",
            "Epoch: 5 \tStep: 729/768 \tAverage training loss: 6.03155\tAverage validation loss: 2349.35449\n",
            "Epoch: 6 \tStep: 61/768 \tAverage training loss: 5.55369\tAverage validation loss: 2288.06396\n",
            "Epoch: 6 \tStep: 161/768 \tAverage training loss: 4.44160\tAverage validation loss: 2253.91846\n",
            "Epoch: 6 \tStep: 261/768 \tAverage training loss: 4.42328\tAverage validation loss: 2353.03931\n",
            "Epoch: 6 \tStep: 361/768 \tAverage training loss: 4.68303\tAverage validation loss: 2289.93359\n",
            "Epoch: 6 \tStep: 461/768 \tAverage training loss: 4.51365\tAverage validation loss: 2244.27661\n",
            "Epoch: 6 \tStep: 561/768 \tAverage training loss: 4.24819\tAverage validation loss: 2201.76733\n",
            "Epoch: 6 \tStep: 661/768 \tAverage training loss: 4.10326\tAverage validation loss: 2163.74316\n",
            "Epoch: 6 \tStep: 761/768 \tAverage training loss: 3.91863\tAverage validation loss: 2124.19824\n",
            "Epoch: 7 \tStep: 93/768 \tAverage training loss: 3.45128\tAverage validation loss: 2086.79004\n",
            "Epoch: 7 \tStep: 193/768 \tAverage training loss: 3.20231\tAverage validation loss: 2058.18774\n",
            "Epoch: 7 \tStep: 293/768 \tAverage training loss: 3.24728\tAverage validation loss: 2087.86182\n",
            "Epoch: 7 \tStep: 393/768 \tAverage training loss: 3.32309\tAverage validation loss: 2042.50757\n",
            "Epoch: 7 \tStep: 493/768 \tAverage training loss: 3.40889\tAverage validation loss: 2009.63574\n",
            "Epoch: 7 \tStep: 593/768 \tAverage training loss: 3.29341\tAverage validation loss: 1978.55322\n",
            "Epoch: 7 \tStep: 693/768 \tAverage training loss: 3.20202\tAverage validation loss: 1905.55762\n",
            "Epoch: 8 \tStep: 25/768 \tAverage training loss: 2.22326\tAverage validation loss: 1865.85791\n",
            "Epoch: 8 \tStep: 125/768 \tAverage training loss: 2.42432\tAverage validation loss: 1831.37500\n",
            "Epoch: 8 \tStep: 225/768 \tAverage training loss: 2.61878\tAverage validation loss: 1813.22400\n",
            "Epoch: 8 \tStep: 325/768 \tAverage training loss: 2.47190\tAverage validation loss: 1789.60596\n",
            "Epoch: 8 \tStep: 425/768 \tAverage training loss: 2.41150\tAverage validation loss: 1773.30688\n",
            "Epoch: 8 \tStep: 525/768 \tAverage training loss: 2.45286\tAverage validation loss: 1757.28687\n",
            "Epoch: 8 \tStep: 625/768 \tAverage training loss: 2.43273\tAverage validation loss: 1729.15076\n",
            "Epoch: 8 \tStep: 725/768 \tAverage training loss: 2.50758\tAverage validation loss: 1713.52222\n",
            "Epoch: 9 \tStep: 57/768 \tAverage training loss: 2.12706\tAverage validation loss: 1709.16846\n",
            "Epoch: 9 \tStep: 157/768 \tAverage training loss: 2.81324\tAverage validation loss: 1674.28589\n",
            "Epoch: 9 \tStep: 257/768 \tAverage training loss: 2.52896\tAverage validation loss: 1765.68738\n",
            "Epoch: 9 \tStep: 357/768 \tAverage training loss: 2.53538\tAverage validation loss: 1712.65039\n",
            "Epoch: 9 \tStep: 457/768 \tAverage training loss: 2.44612\tAverage validation loss: 1685.59851\n",
            "Epoch: 9 \tStep: 557/768 \tAverage training loss: 2.31895\tAverage validation loss: 1653.77734\n",
            "Epoch: 9 \tStep: 657/768 \tAverage training loss: 2.32828\tAverage validation loss: 1704.97632\n",
            "Epoch: 9 \tStep: 757/768 \tAverage training loss: 2.28461\tAverage validation loss: 1664.09692\n",
            "Epoch: 10 \tStep: 89/768 \tAverage training loss: 1.66990\tAverage validation loss: 1655.10205\n",
            "Epoch: 10 \tStep: 189/768 \tAverage training loss: 1.85975\tAverage validation loss: 1620.77039\n",
            "Epoch: 10 \tStep: 289/768 \tAverage training loss: 1.94193\tAverage validation loss: 1606.89868\n",
            "Epoch: 10 \tStep: 389/768 \tAverage training loss: 2.05807\tAverage validation loss: 1596.97217\n",
            "Epoch: 10 \tStep: 489/768 \tAverage training loss: 2.12995\tAverage validation loss: 1599.63904\n",
            "Epoch: 10 \tStep: 589/768 \tAverage training loss: 2.19622\tAverage validation loss: 1562.99902\n",
            "Epoch: 10 \tStep: 689/768 \tAverage training loss: 2.10222\tAverage validation loss: 1560.38306\n",
            "Epoch: 11 \tStep: 21/768 \tAverage training loss: 2.02124\tAverage validation loss: 1552.88525\n",
            "Epoch: 11 \tStep: 121/768 \tAverage training loss: 2.14212\tAverage validation loss: 1528.28906\n",
            "Epoch: 11 \tStep: 221/768 \tAverage training loss: 2.05089\tAverage validation loss: 1514.91040\n",
            "Epoch: 11 \tStep: 321/768 \tAverage training loss: 1.92011\tAverage validation loss: 1519.81689\n",
            "Epoch: 11 \tStep: 421/768 \tAverage training loss: 1.92615\tAverage validation loss: 1493.51990\n",
            "Epoch: 11 \tStep: 521/768 \tAverage training loss: 2.02119\tAverage validation loss: 1490.99402\n",
            "Epoch: 11 \tStep: 621/768 \tAverage training loss: 2.06810\tAverage validation loss: 1459.70093\n",
            "Epoch: 11 \tStep: 721/768 \tAverage training loss: 2.07447\tAverage validation loss: 1466.68970\n",
            "Epoch: 12 \tStep: 53/768 \tAverage training loss: 2.06278\tAverage validation loss: 1452.41980\n",
            "Epoch: 12 \tStep: 153/768 \tAverage training loss: 1.69188\tAverage validation loss: 1446.23169\n",
            "Epoch: 12 \tStep: 253/768 \tAverage training loss: 1.69482\tAverage validation loss: 1447.65894\n",
            "Epoch: 12 \tStep: 353/768 \tAverage training loss: 1.62326\tAverage validation loss: 1436.90479\n",
            "Epoch: 12 \tStep: 453/768 \tAverage training loss: 1.74293\tAverage validation loss: 1408.57788\n",
            "Epoch: 12 \tStep: 553/768 \tAverage training loss: 1.91771\tAverage validation loss: 1437.21826\n",
            "Epoch: 12 \tStep: 653/768 \tAverage training loss: 1.98391\tAverage validation loss: 1416.01453\n",
            "Epoch: 12 \tStep: 753/768 \tAverage training loss: 1.95630\tAverage validation loss: 1430.26245\n",
            "Epoch: 13 \tStep: 85/768 \tAverage training loss: 2.03155\tAverage validation loss: 1423.27734\n",
            "Epoch: 13 \tStep: 185/768 \tAverage training loss: 1.90424\tAverage validation loss: 1400.85254\n",
            "Epoch: 13 \tStep: 285/768 \tAverage training loss: 1.91274\tAverage validation loss: 1392.43896\n",
            "Epoch: 13 \tStep: 385/768 \tAverage training loss: 1.98950\tAverage validation loss: 1368.97290\n",
            "Epoch: 13 \tStep: 485/768 \tAverage training loss: 1.97381\tAverage validation loss: 1358.07324\n",
            "Epoch: 13 \tStep: 585/768 \tAverage training loss: 1.93244\tAverage validation loss: 1349.08862\n",
            "Epoch: 13 \tStep: 685/768 \tAverage training loss: 1.91390\tAverage validation loss: 1345.58252\n",
            "Epoch: 14 \tStep: 17/768 \tAverage training loss: 2.44931\tAverage validation loss: 1327.01819\n",
            "Epoch: 14 \tStep: 117/768 \tAverage training loss: 1.92267\tAverage validation loss: 1338.25659\n",
            "Epoch: 14 \tStep: 217/768 \tAverage training loss: 1.80312\tAverage validation loss: 1323.51025\n",
            "Epoch: 14 \tStep: 317/768 \tAverage training loss: 1.64727\tAverage validation loss: 1314.83398\n",
            "Epoch: 14 \tStep: 417/768 \tAverage training loss: 1.60923\tAverage validation loss: 1323.64819\n",
            "Epoch: 14 \tStep: 517/768 \tAverage training loss: 1.68178\tAverage validation loss: 1299.72656\n",
            "Epoch: 14 \tStep: 617/768 \tAverage training loss: 1.78617\tAverage validation loss: 1297.56152\n",
            "Epoch: 14 \tStep: 717/768 \tAverage training loss: 1.85557\tAverage validation loss: 1283.78418\n",
            "Epoch: 15 \tStep: 49/768 \tAverage training loss: 1.96521\tAverage validation loss: 1334.21655\n",
            "Epoch: 15 \tStep: 149/768 \tAverage training loss: 1.97248\tAverage validation loss: 1279.37671\n",
            "Epoch: 15 \tStep: 249/768 \tAverage training loss: 1.80329\tAverage validation loss: 1332.06152\n",
            "Epoch: 15 \tStep: 349/768 \tAverage training loss: 1.77110\tAverage validation loss: 1287.94739\n",
            "Epoch: 15 \tStep: 449/768 \tAverage training loss: 1.77315\tAverage validation loss: 1281.29248\n",
            "Epoch: 15 \tStep: 549/768 \tAverage training loss: 1.85896\tAverage validation loss: 1293.60376\n",
            "Epoch: 15 \tStep: 649/768 \tAverage training loss: 1.89280\tAverage validation loss: 1291.33740\n",
            "Epoch: 15 \tStep: 749/768 \tAverage training loss: 1.93709\tAverage validation loss: 1300.85352\n",
            "Epoch: 16 \tStep: 81/768 \tAverage training loss: 1.81082\tAverage validation loss: 1255.78760\n",
            "Epoch: 16 \tStep: 181/768 \tAverage training loss: 1.67160\tAverage validation loss: 1269.75232\n",
            "Epoch: 16 \tStep: 281/768 \tAverage training loss: 1.67702\tAverage validation loss: 1255.17627\n",
            "Epoch: 16 \tStep: 381/768 \tAverage training loss: 1.72980\tAverage validation loss: 1286.58594\n",
            "Epoch: 16 \tStep: 481/768 \tAverage training loss: 1.70384\tAverage validation loss: 1294.78943\n",
            "Epoch: 16 \tStep: 581/768 \tAverage training loss: 1.79870\tAverage validation loss: 1343.09668\n",
            "Epoch: 16 \tStep: 681/768 \tAverage training loss: 1.81234\tAverage validation loss: 1290.53345\n",
            "Epoch: 17 \tStep: 13/768 \tAverage training loss: 1.73262\tAverage validation loss: 1258.45081\n",
            "Epoch: 17 \tStep: 113/768 \tAverage training loss: 1.71624\tAverage validation loss: 1290.40674\n",
            "Epoch: 17 \tStep: 213/768 \tAverage training loss: 1.75180\tAverage validation loss: 1272.98022\n",
            "Epoch: 17 \tStep: 313/768 \tAverage training loss: 1.79220\tAverage validation loss: 1303.20703\n",
            "Epoch: 17 \tStep: 413/768 \tAverage training loss: 1.83668\tAverage validation loss: 1292.54285\n",
            "Epoch: 17 \tStep: 513/768 \tAverage training loss: 1.84264\tAverage validation loss: 1276.38379\n",
            "Epoch: 17 \tStep: 613/768 \tAverage training loss: 1.83941\tAverage validation loss: 1296.44629\n",
            "Epoch: 17 \tStep: 713/768 \tAverage training loss: 1.81195\tAverage validation loss: 1342.81958\n",
            "Epoch: 18 \tStep: 45/768 \tAverage training loss: 1.42416\tAverage validation loss: 1357.33801\n",
            "Epoch: 18 \tStep: 145/768 \tAverage training loss: 1.65406\tAverage validation loss: 1353.73828\n",
            "Epoch: 18 \tStep: 245/768 \tAverage training loss: 1.58763\tAverage validation loss: 1327.81238\n",
            "Epoch: 18 \tStep: 345/768 \tAverage training loss: 1.64654\tAverage validation loss: 1313.49536\n",
            "Epoch: 18 \tStep: 445/768 \tAverage training loss: 1.74751\tAverage validation loss: 1332.48767\n",
            "Epoch: 18 \tStep: 545/768 \tAverage training loss: 1.77518\tAverage validation loss: 1340.56946\n",
            "Epoch: 18 \tStep: 645/768 \tAverage training loss: 1.93197\tAverage validation loss: 1310.49609\n",
            "Epoch: 18 \tStep: 745/768 \tAverage training loss: 1.88895\tAverage validation loss: 1347.19678\n",
            "Epoch: 19 \tStep: 77/768 \tAverage training loss: 1.30771\tAverage validation loss: 1351.40820\n",
            "Epoch: 19 \tStep: 177/768 \tAverage training loss: 1.72870\tAverage validation loss: 1358.00549\n",
            "Epoch: 19 \tStep: 277/768 \tAverage training loss: 1.77228\tAverage validation loss: 1343.59167\n",
            "Epoch: 19 \tStep: 377/768 \tAverage training loss: 1.68190\tAverage validation loss: 1342.16199\n",
            "Epoch: 19 \tStep: 477/768 \tAverage training loss: 1.64966\tAverage validation loss: 1327.72693\n",
            "Epoch: 19 \tStep: 577/768 \tAverage training loss: 1.63414\tAverage validation loss: 1317.16675\n",
            "Epoch: 19 \tStep: 677/768 \tAverage training loss: 1.76324\tAverage validation loss: 1330.83789\n",
            "Epoch: 20 \tStep: 9/768 \tAverage training loss: 1.33902\tAverage validation loss: 1328.74805\n",
            "Epoch: 20 \tStep: 109/768 \tAverage training loss: 1.59001\tAverage validation loss: 1325.99707\n",
            "Epoch: 20 \tStep: 209/768 \tAverage training loss: 1.89537\tAverage validation loss: 1391.35132\n",
            "Epoch: 20 \tStep: 309/768 \tAverage training loss: 1.83583\tAverage validation loss: 1309.67883\n",
            "Epoch: 20 \tStep: 409/768 \tAverage training loss: 1.83217\tAverage validation loss: 1305.95312\n",
            "Epoch: 20 \tStep: 509/768 \tAverage training loss: 1.78092\tAverage validation loss: 1355.23816\n",
            "Epoch: 20 \tStep: 609/768 \tAverage training loss: 1.76512\tAverage validation loss: 1279.96021\n",
            "Epoch: 20 \tStep: 709/768 \tAverage training loss: 1.80251\tAverage validation loss: 1272.66211\n",
            "Epoch: 21 \tStep: 41/768 \tAverage training loss: 1.87322\tAverage validation loss: 1276.10010\n",
            "Epoch: 21 \tStep: 141/768 \tAverage training loss: 1.89515\tAverage validation loss: 1293.29041\n",
            "Epoch: 21 \tStep: 241/768 \tAverage training loss: 1.76417\tAverage validation loss: 1256.46277\n",
            "Epoch: 21 \tStep: 341/768 \tAverage training loss: 1.84077\tAverage validation loss: 1264.94092\n",
            "Epoch: 21 \tStep: 441/768 \tAverage training loss: 1.80035\tAverage validation loss: 1255.71106\n",
            "Epoch: 21 \tStep: 541/768 \tAverage training loss: 1.75951\tAverage validation loss: 1294.22534\n",
            "Epoch: 21 \tStep: 641/768 \tAverage training loss: 1.75869\tAverage validation loss: 1290.38049\n",
            "Epoch: 21 \tStep: 741/768 \tAverage training loss: 1.78636\tAverage validation loss: 1288.81311\n",
            "Epoch: 22 \tStep: 73/768 \tAverage training loss: 2.07257\tAverage validation loss: 1284.27637\n",
            "Epoch: 22 \tStep: 173/768 \tAverage training loss: 1.79031\tAverage validation loss: 1294.88123\n",
            "Epoch: 22 \tStep: 273/768 \tAverage training loss: 1.82769\tAverage validation loss: 1302.01123\n",
            "Epoch: 22 \tStep: 373/768 \tAverage training loss: 1.90650\tAverage validation loss: 1291.65503\n",
            "Epoch: 22 \tStep: 473/768 \tAverage training loss: 1.82096\tAverage validation loss: 1248.97363\n",
            "Epoch: 22 \tStep: 573/768 \tAverage training loss: 1.78194\tAverage validation loss: 1248.04993\n",
            "Epoch: 22 \tStep: 673/768 \tAverage training loss: 1.73158\tAverage validation loss: 1226.96240\n",
            "Epoch: 23 \tStep: 5/768 \tAverage training loss: 1.92684\tAverage validation loss: 1234.86145\n",
            "Epoch: 23 \tStep: 105/768 \tAverage training loss: 1.53856\tAverage validation loss: 1220.76807\n",
            "Epoch: 23 \tStep: 205/768 \tAverage training loss: 1.61312\tAverage validation loss: 1218.11475\n",
            "Epoch: 23 \tStep: 305/768 \tAverage training loss: 1.64737\tAverage validation loss: 1214.33557\n",
            "Epoch: 23 \tStep: 405/768 \tAverage training loss: 1.67053\tAverage validation loss: 1319.80518\n",
            "Epoch: 23 \tStep: 505/768 \tAverage training loss: 1.65214\tAverage validation loss: 1297.47278\n",
            "Epoch: 23 \tStep: 605/768 \tAverage training loss: 1.68122\tAverage validation loss: 1287.96729\n",
            "Epoch: 23 \tStep: 705/768 \tAverage training loss: 1.70970\tAverage validation loss: 1261.94702\n",
            "Epoch: 24 \tStep: 37/768 \tAverage training loss: 1.35043\tAverage validation loss: 1313.63110\n",
            "Epoch: 24 \tStep: 137/768 \tAverage training loss: 2.26134\tAverage validation loss: 1289.97876\n",
            "Epoch: 24 \tStep: 237/768 \tAverage training loss: 1.76369\tAverage validation loss: 1269.70166\n",
            "Epoch: 24 \tStep: 337/768 \tAverage training loss: 1.71397\tAverage validation loss: 1264.93188\n",
            "Epoch: 24 \tStep: 437/768 \tAverage training loss: 1.75629\tAverage validation loss: 1280.13843\n",
            "Epoch: 24 \tStep: 537/768 \tAverage training loss: 1.66406\tAverage validation loss: 1268.09009\n",
            "Epoch: 24 \tStep: 637/768 \tAverage training loss: 1.67579\tAverage validation loss: 1239.42993\n",
            "Epoch: 24 \tStep: 737/768 \tAverage training loss: 1.74958\tAverage validation loss: 1240.30078\n",
            "Epoch: 25 \tStep: 69/768 \tAverage training loss: 1.33496\tAverage validation loss: 1268.73389\n",
            "Epoch: 25 \tStep: 169/768 \tAverage training loss: 1.49691\tAverage validation loss: 1294.20264\n",
            "Epoch: 25 \tStep: 269/768 \tAverage training loss: 1.71594\tAverage validation loss: 1269.94299\n",
            "Epoch: 25 \tStep: 369/768 \tAverage training loss: 1.66966\tAverage validation loss: 1312.88696\n",
            "Epoch: 25 \tStep: 469/768 \tAverage training loss: 1.65592\tAverage validation loss: 1277.23828\n",
            "Epoch: 25 \tStep: 569/768 \tAverage training loss: 1.65016\tAverage validation loss: 1261.62646\n",
            "Epoch: 25 \tStep: 669/768 \tAverage training loss: 1.67204\tAverage validation loss: 1255.37891\n",
            "Epoch: 26 \tStep: 1/768 \tAverage training loss: 0.56153\tAverage validation loss: 1262.23254\n",
            "Epoch: 26 \tStep: 101/768 \tAverage training loss: 1.26364\tAverage validation loss: 1258.60718\n",
            "Epoch: 26 \tStep: 201/768 \tAverage training loss: 1.44166\tAverage validation loss: 1295.88013\n",
            "Epoch: 26 \tStep: 301/768 \tAverage training loss: 1.50947\tAverage validation loss: 1260.38208\n",
            "Epoch: 26 \tStep: 401/768 \tAverage training loss: 1.59415\tAverage validation loss: 1265.30029\n",
            "Epoch: 26 \tStep: 501/768 \tAverage training loss: 1.69354\tAverage validation loss: 1249.80347\n",
            "Epoch: 26 \tStep: 601/768 \tAverage training loss: 1.74055\tAverage validation loss: 1236.98999\n",
            "Epoch: 26 \tStep: 701/768 \tAverage training loss: 1.68971\tAverage validation loss: 1237.98596\n",
            "Epoch: 27 \tStep: 33/768 \tAverage training loss: 1.67592\tAverage validation loss: 1261.40112\n",
            "Epoch: 27 \tStep: 133/768 \tAverage training loss: 1.85089\tAverage validation loss: 1241.20471\n",
            "Epoch: 27 \tStep: 233/768 \tAverage training loss: 1.71643\tAverage validation loss: 1230.26807\n",
            "Epoch: 27 \tStep: 333/768 \tAverage training loss: 1.71669\tAverage validation loss: 1225.70471\n",
            "Epoch: 27 \tStep: 433/768 \tAverage training loss: 1.69418\tAverage validation loss: 1235.97095\n",
            "Epoch: 27 \tStep: 533/768 \tAverage training loss: 1.67813\tAverage validation loss: 1228.99561\n",
            "Epoch: 27 \tStep: 633/768 \tAverage training loss: 1.73313\tAverage validation loss: 1223.12891\n",
            "Epoch: 27 \tStep: 733/768 \tAverage training loss: 1.70586\tAverage validation loss: 1229.78772\n",
            "Epoch: 28 \tStep: 65/768 \tAverage training loss: 1.83744\tAverage validation loss: 1235.71069\n",
            "Epoch: 28 \tStep: 165/768 \tAverage training loss: 1.86800\tAverage validation loss: 1202.02258\n",
            "Epoch: 28 \tStep: 265/768 \tAverage training loss: 1.80144\tAverage validation loss: 1249.91772\n",
            "Epoch: 28 \tStep: 365/768 \tAverage training loss: 1.72573\tAverage validation loss: 1251.91553\n",
            "Epoch: 28 \tStep: 465/768 \tAverage training loss: 1.71770\tAverage validation loss: 1209.40039\n",
            "Epoch: 28 \tStep: 565/768 \tAverage training loss: 1.68135\tAverage validation loss: 1266.56030\n",
            "Epoch: 28 \tStep: 665/768 \tAverage training loss: 1.68656\tAverage validation loss: 1213.58154\n",
            "Epoch: 28 \tStep: 765/768 \tAverage training loss: 1.67419\tAverage validation loss: 1268.37256\n",
            "Epoch: 29 \tStep: 97/768 \tAverage training loss: 1.59210\tAverage validation loss: 1243.57703\n",
            "Epoch: 29 \tStep: 197/768 \tAverage training loss: 1.56114\tAverage validation loss: 1218.02991\n",
            "Epoch: 29 \tStep: 297/768 \tAverage training loss: 1.65366\tAverage validation loss: 1226.99536\n",
            "Epoch: 29 \tStep: 397/768 \tAverage training loss: 1.58779\tAverage validation loss: 1275.06909\n",
            "Epoch: 29 \tStep: 497/768 \tAverage training loss: 1.56790\tAverage validation loss: 1269.05786\n",
            "Epoch: 29 \tStep: 597/768 \tAverage training loss: 1.59552\tAverage validation loss: 1264.00769\n",
            "Epoch: 29 \tStep: 697/768 \tAverage training loss: 1.56707\tAverage validation loss: 1241.39294\n",
            "Epoch: 30 \tStep: 29/768 \tAverage training loss: 2.40594\tAverage validation loss: 1237.64453\n",
            "Epoch: 30 \tStep: 129/768 \tAverage training loss: 1.46975\tAverage validation loss: 1239.22827\n",
            "Epoch: 30 \tStep: 229/768 \tAverage training loss: 1.48084\tAverage validation loss: 1236.70630\n",
            "Epoch: 30 \tStep: 329/768 \tAverage training loss: 1.43855\tAverage validation loss: 1222.25464\n",
            "Epoch: 30 \tStep: 429/768 \tAverage training loss: 1.52370\tAverage validation loss: 1242.31396\n",
            "Epoch: 30 \tStep: 529/768 \tAverage training loss: 1.54730\tAverage validation loss: 1248.92493\n",
            "Epoch: 30 \tStep: 629/768 \tAverage training loss: 1.53960\tAverage validation loss: 1270.26221\n",
            "Epoch: 30 \tStep: 729/768 \tAverage training loss: 1.54564\tAverage validation loss: 1218.86475\n",
            "Epoch: 31 \tStep: 61/768 \tAverage training loss: 1.17995\tAverage validation loss: 1239.74536\n",
            "Epoch: 31 \tStep: 161/768 \tAverage training loss: 1.38254\tAverage validation loss: 1250.25415\n",
            "Epoch: 31 \tStep: 261/768 \tAverage training loss: 1.57417\tAverage validation loss: 1245.42236\n",
            "Epoch: 31 \tStep: 361/768 \tAverage training loss: 1.50819\tAverage validation loss: 1222.64294\n",
            "Epoch: 31 \tStep: 461/768 \tAverage training loss: 1.64473\tAverage validation loss: 1230.50220\n",
            "Epoch: 31 \tStep: 561/768 \tAverage training loss: 1.62096\tAverage validation loss: 1237.88379\n",
            "Epoch: 31 \tStep: 661/768 \tAverage training loss: 1.62640\tAverage validation loss: 1211.35339\n",
            "Epoch: 31 \tStep: 761/768 \tAverage training loss: 1.62721\tAverage validation loss: 1233.62158\n",
            "Epoch: 32 \tStep: 93/768 \tAverage training loss: 1.60708\tAverage validation loss: 1225.36072\n",
            "Epoch: 32 \tStep: 193/768 \tAverage training loss: 1.78903\tAverage validation loss: 1211.68079\n",
            "Epoch: 32 \tStep: 293/768 \tAverage training loss: 1.79820\tAverage validation loss: 1183.42102\n",
            "Epoch: 32 \tStep: 393/768 \tAverage training loss: 1.73946\tAverage validation loss: 1217.93091\n",
            "Epoch: 32 \tStep: 493/768 \tAverage training loss: 1.77653\tAverage validation loss: 1211.50623\n",
            "Epoch: 32 \tStep: 593/768 \tAverage training loss: 1.70883\tAverage validation loss: 1203.09045\n",
            "Epoch: 32 \tStep: 693/768 \tAverage training loss: 1.67484\tAverage validation loss: 1224.54065\n",
            "Epoch: 33 \tStep: 25/768 \tAverage training loss: 1.18637\tAverage validation loss: 1249.93604\n",
            "Epoch: 33 \tStep: 125/768 \tAverage training loss: 1.54990\tAverage validation loss: 1264.16553\n",
            "Epoch: 33 \tStep: 225/768 \tAverage training loss: 1.73767\tAverage validation loss: 1261.01001\n",
            "Epoch: 33 \tStep: 325/768 \tAverage training loss: 1.63322\tAverage validation loss: 1235.39990\n",
            "Epoch: 33 \tStep: 425/768 \tAverage training loss: 1.71041\tAverage validation loss: 1201.60962\n",
            "Epoch: 33 \tStep: 525/768 \tAverage training loss: 1.70972\tAverage validation loss: 1252.15674\n",
            "Epoch: 33 \tStep: 625/768 \tAverage training loss: 1.69479\tAverage validation loss: 1260.80078\n",
            "Epoch: 33 \tStep: 725/768 \tAverage training loss: 1.63025\tAverage validation loss: 1209.43958\n",
            "Epoch: 34 \tStep: 57/768 \tAverage training loss: 1.52650\tAverage validation loss: 1196.15259\n",
            "Epoch: 34 \tStep: 157/768 \tAverage training loss: 1.51674\tAverage validation loss: 1196.83447\n",
            "Epoch: 34 \tStep: 257/768 \tAverage training loss: 1.50212\tAverage validation loss: 1203.24170\n",
            "Epoch: 34 \tStep: 357/768 \tAverage training loss: 1.61674\tAverage validation loss: 1197.37634\n",
            "Epoch: 34 \tStep: 457/768 \tAverage training loss: 1.62052\tAverage validation loss: 1186.82812\n",
            "Epoch: 34 \tStep: 557/768 \tAverage training loss: 1.68150\tAverage validation loss: 1245.48999\n",
            "Epoch: 34 \tStep: 657/768 \tAverage training loss: 1.64343\tAverage validation loss: 1246.36829\n",
            "Epoch: 34 \tStep: 757/768 \tAverage training loss: 1.64470\tAverage validation loss: 1191.76953\n",
            "Epoch: 35 \tStep: 89/768 \tAverage training loss: 2.16406\tAverage validation loss: 1197.38086\n",
            "Epoch: 35 \tStep: 189/768 \tAverage training loss: 1.95440\tAverage validation loss: 1309.61890\n",
            "Epoch: 35 \tStep: 289/768 \tAverage training loss: 1.70046\tAverage validation loss: 1280.95898\n",
            "Epoch: 35 \tStep: 389/768 \tAverage training loss: 1.61955\tAverage validation loss: 1224.93555\n",
            "Epoch: 35 \tStep: 489/768 \tAverage training loss: 1.59010\tAverage validation loss: 1225.04211\n",
            "Epoch: 35 \tStep: 589/768 \tAverage training loss: 1.58642\tAverage validation loss: 1193.62695\n",
            "Epoch: 35 \tStep: 689/768 \tAverage training loss: 1.57284\tAverage validation loss: 1186.99512\n",
            "Epoch: 36 \tStep: 21/768 \tAverage training loss: 2.08058\tAverage validation loss: 1183.47083\n",
            "Epoch: 36 \tStep: 121/768 \tAverage training loss: 1.64579\tAverage validation loss: 1208.40039\n",
            "Epoch: 36 \tStep: 221/768 \tAverage training loss: 1.74420\tAverage validation loss: 1209.86121\n",
            "Epoch: 36 \tStep: 321/768 \tAverage training loss: 1.57827\tAverage validation loss: 1310.88733\n",
            "Epoch: 36 \tStep: 421/768 \tAverage training loss: 1.58024\tAverage validation loss: 1247.02808\n",
            "Epoch: 36 \tStep: 521/768 \tAverage training loss: 1.62472\tAverage validation loss: 1170.19153\n",
            "Epoch: 36 \tStep: 621/768 \tAverage training loss: 1.70372\tAverage validation loss: 1274.90076\n",
            "Epoch: 36 \tStep: 721/768 \tAverage training loss: 1.72199\tAverage validation loss: 1184.59448\n",
            "Epoch: 37 \tStep: 53/768 \tAverage training loss: 1.45252\tAverage validation loss: 1180.94995\n",
            "Epoch: 37 \tStep: 153/768 \tAverage training loss: 1.66249\tAverage validation loss: 1168.41479\n",
            "Epoch: 37 \tStep: 253/768 \tAverage training loss: 1.64966\tAverage validation loss: 1185.14966\n",
            "Epoch: 37 \tStep: 353/768 \tAverage training loss: 1.66821\tAverage validation loss: 1134.81873\n",
            "Epoch: 37 \tStep: 453/768 \tAverage training loss: 1.54429\tAverage validation loss: 1142.89551\n",
            "Epoch: 37 \tStep: 553/768 \tAverage training loss: 1.55791\tAverage validation loss: 1166.27722\n",
            "Epoch: 37 \tStep: 653/768 \tAverage training loss: 1.51459\tAverage validation loss: 1195.00525\n",
            "Epoch: 37 \tStep: 753/768 \tAverage training loss: 1.50831\tAverage validation loss: 1249.03308\n",
            "Epoch: 38 \tStep: 85/768 \tAverage training loss: 1.45630\tAverage validation loss: 1146.41919\n",
            "Epoch: 38 \tStep: 185/768 \tAverage training loss: 1.58511\tAverage validation loss: 1140.90393\n",
            "Epoch: 38 \tStep: 285/768 \tAverage training loss: 1.69390\tAverage validation loss: 1180.31555\n",
            "Epoch: 38 \tStep: 385/768 \tAverage training loss: 1.62389\tAverage validation loss: 1195.35645\n",
            "Epoch: 38 \tStep: 485/768 \tAverage training loss: 1.70064\tAverage validation loss: 1198.27930\n",
            "Epoch: 38 \tStep: 585/768 \tAverage training loss: 1.67257\tAverage validation loss: 1230.93054\n",
            "Epoch: 38 \tStep: 685/768 \tAverage training loss: 1.61143\tAverage validation loss: 1248.58679\n",
            "Epoch: 39 \tStep: 17/768 \tAverage training loss: 0.87290\tAverage validation loss: 1189.67383\n",
            "Epoch: 39 \tStep: 117/768 \tAverage training loss: 1.83438\tAverage validation loss: 1236.34631\n",
            "Epoch: 39 \tStep: 217/768 \tAverage training loss: 1.65174\tAverage validation loss: 1167.47888\n",
            "Epoch: 39 \tStep: 317/768 \tAverage training loss: 1.68167\tAverage validation loss: 1318.73230\n",
            "Epoch: 39 \tStep: 417/768 \tAverage training loss: 1.73560\tAverage validation loss: 1166.82080\n",
            "Epoch: 39 \tStep: 517/768 \tAverage training loss: 1.76171\tAverage validation loss: 1337.23511\n",
            "Epoch: 39 \tStep: 617/768 \tAverage training loss: 1.69119\tAverage validation loss: 1299.80762\n",
            "Epoch: 39 \tStep: 717/768 \tAverage training loss: 1.62636\tAverage validation loss: 1276.65234\n",
            "Epoch: 40 \tStep: 49/768 \tAverage training loss: 1.70640\tAverage validation loss: 1253.39343\n",
            "Epoch: 40 \tStep: 149/768 \tAverage training loss: 1.69696\tAverage validation loss: 1231.67017\n",
            "Epoch: 40 \tStep: 249/768 \tAverage training loss: 1.56174\tAverage validation loss: 1231.96802\n",
            "Epoch: 40 \tStep: 349/768 \tAverage training loss: 1.64718\tAverage validation loss: 1241.25269\n",
            "Epoch: 40 \tStep: 449/768 \tAverage training loss: 1.75613\tAverage validation loss: 1243.76941\n",
            "Epoch: 40 \tStep: 549/768 \tAverage training loss: 1.75890\tAverage validation loss: 1192.46436\n",
            "Epoch: 40 \tStep: 649/768 \tAverage training loss: 1.71671\tAverage validation loss: 1180.86304\n",
            "Epoch: 40 \tStep: 749/768 \tAverage training loss: 1.65857\tAverage validation loss: 1169.15234\n",
            "Epoch: 41 \tStep: 81/768 \tAverage training loss: 1.37274\tAverage validation loss: 1173.98828\n",
            "Epoch: 41 \tStep: 181/768 \tAverage training loss: 1.50006\tAverage validation loss: 1183.92969\n",
            "Epoch: 41 \tStep: 281/768 \tAverage training loss: 1.56151\tAverage validation loss: 1147.02161\n",
            "Epoch: 41 \tStep: 381/768 \tAverage training loss: 1.49241\tAverage validation loss: 1160.28857\n",
            "Epoch: 41 \tStep: 481/768 \tAverage training loss: 1.45626\tAverage validation loss: 1181.40442\n",
            "Epoch: 41 \tStep: 581/768 \tAverage training loss: 1.49862\tAverage validation loss: 1167.98694\n",
            "Epoch: 41 \tStep: 681/768 \tAverage training loss: 1.49820\tAverage validation loss: 1171.18896\n",
            "Epoch: 42 \tStep: 13/768 \tAverage training loss: 1.77481\tAverage validation loss: 1215.76416\n",
            "Epoch: 42 \tStep: 113/768 \tAverage training loss: 1.56494\tAverage validation loss: 1168.40283\n",
            "Epoch: 42 \tStep: 213/768 \tAverage training loss: 1.59017\tAverage validation loss: 1213.71606\n",
            "Epoch: 42 \tStep: 313/768 \tAverage training loss: 1.59868\tAverage validation loss: 1168.42725\n",
            "Epoch: 42 \tStep: 413/768 \tAverage training loss: 1.57450\tAverage validation loss: 1151.14832\n",
            "Epoch: 42 \tStep: 513/768 \tAverage training loss: 1.49728\tAverage validation loss: 1133.27661\n",
            "Epoch: 42 \tStep: 613/768 \tAverage training loss: 1.49944\tAverage validation loss: 1161.86047\n",
            "Epoch: 42 \tStep: 713/768 \tAverage training loss: 1.51735\tAverage validation loss: 1147.20923\n",
            "Epoch: 43 \tStep: 45/768 \tAverage training loss: 1.71751\tAverage validation loss: 1244.64124\n",
            "Epoch: 43 \tStep: 145/768 \tAverage training loss: 1.56250\tAverage validation loss: 1191.76782\n",
            "Epoch: 43 \tStep: 245/768 \tAverage training loss: 1.47553\tAverage validation loss: 1221.77478\n",
            "Epoch: 43 \tStep: 345/768 \tAverage training loss: 1.45705\tAverage validation loss: 1163.20032\n",
            "Epoch: 43 \tStep: 445/768 \tAverage training loss: 1.48176\tAverage validation loss: 1169.06555\n",
            "Epoch: 43 \tStep: 545/768 \tAverage training loss: 1.52690\tAverage validation loss: 1152.83752\n",
            "Epoch: 43 \tStep: 645/768 \tAverage training loss: 1.52064\tAverage validation loss: 1096.87109\n",
            "Epoch: 43 \tStep: 745/768 \tAverage training loss: 1.56017\tAverage validation loss: 1213.16138\n",
            "Epoch: 44 \tStep: 77/768 \tAverage training loss: 1.45977\tAverage validation loss: 1221.68945\n",
            "Epoch: 44 \tStep: 177/768 \tAverage training loss: 1.50807\tAverage validation loss: 1246.67053\n",
            "Epoch: 44 \tStep: 277/768 \tAverage training loss: 1.50181\tAverage validation loss: 1201.17566\n",
            "Epoch: 44 \tStep: 377/768 \tAverage training loss: 1.48029\tAverage validation loss: 1172.90259\n",
            "Epoch: 44 \tStep: 477/768 \tAverage training loss: 1.48322\tAverage validation loss: 1178.88159\n",
            "Epoch: 44 \tStep: 577/768 \tAverage training loss: 1.49387\tAverage validation loss: 1163.58484\n",
            "Epoch: 44 \tStep: 677/768 \tAverage training loss: 1.47159\tAverage validation loss: 1171.98999\n",
            "Epoch: 45 \tStep: 9/768 \tAverage training loss: 1.79666\tAverage validation loss: 1269.00391\n",
            "Epoch: 45 \tStep: 109/768 \tAverage training loss: 1.63968\tAverage validation loss: 1221.96436\n",
            "Epoch: 45 \tStep: 209/768 \tAverage training loss: 1.57386\tAverage validation loss: 1219.66089\n",
            "Epoch: 45 \tStep: 309/768 \tAverage training loss: 1.50247\tAverage validation loss: 1176.40320\n",
            "Epoch: 45 \tStep: 409/768 \tAverage training loss: 1.52628\tAverage validation loss: 1151.26978\n",
            "Epoch: 45 \tStep: 509/768 \tAverage training loss: 1.54026\tAverage validation loss: 1196.03833\n",
            "Epoch: 45 \tStep: 609/768 \tAverage training loss: 1.55021\tAverage validation loss: 1164.51025\n",
            "Epoch: 45 \tStep: 709/768 \tAverage training loss: 1.54935\tAverage validation loss: 1159.82812\n",
            "Epoch: 46 \tStep: 41/768 \tAverage training loss: 1.24604\tAverage validation loss: 1233.25024\n",
            "Epoch: 46 \tStep: 141/768 \tAverage training loss: 1.30802\tAverage validation loss: 1238.86816\n",
            "Epoch: 46 \tStep: 241/768 \tAverage training loss: 1.36195\tAverage validation loss: 1177.76196\n",
            "Epoch: 46 \tStep: 341/768 \tAverage training loss: 1.39791\tAverage validation loss: 1184.61011\n",
            "Epoch: 46 \tStep: 441/768 \tAverage training loss: 1.43791\tAverage validation loss: 1183.53259\n",
            "Epoch: 46 \tStep: 541/768 \tAverage training loss: 1.42041\tAverage validation loss: 1176.08264\n",
            "Epoch: 46 \tStep: 641/768 \tAverage training loss: 1.48654\tAverage validation loss: 1227.78442\n",
            "Epoch: 46 \tStep: 741/768 \tAverage training loss: 1.50731\tAverage validation loss: 1181.51904\n",
            "Epoch: 47 \tStep: 73/768 \tAverage training loss: 1.23160\tAverage validation loss: 1157.89758\n",
            "Epoch: 47 \tStep: 173/768 \tAverage training loss: 1.25845\tAverage validation loss: 1175.78735\n",
            "Epoch: 47 \tStep: 273/768 \tAverage training loss: 1.29330\tAverage validation loss: 1206.01697\n",
            "Epoch: 47 \tStep: 373/768 \tAverage training loss: 1.53376\tAverage validation loss: 1244.29419\n",
            "Epoch: 47 \tStep: 473/768 \tAverage training loss: 1.50891\tAverage validation loss: 1243.27380\n",
            "Epoch: 47 \tStep: 573/768 \tAverage training loss: 1.59074\tAverage validation loss: 1207.47119\n",
            "Epoch: 47 \tStep: 673/768 \tAverage training loss: 1.61618\tAverage validation loss: 1241.69263\n",
            "Epoch: 48 \tStep: 5/768 \tAverage training loss: 2.05441\tAverage validation loss: 1247.72522\n",
            "Epoch: 48 \tStep: 105/768 \tAverage training loss: 1.54987\tAverage validation loss: 1254.55762\n",
            "Epoch: 48 \tStep: 205/768 \tAverage training loss: 1.41359\tAverage validation loss: 1231.67676\n",
            "Epoch: 48 \tStep: 305/768 \tAverage training loss: 1.51643\tAverage validation loss: 1266.15271\n",
            "Epoch: 48 \tStep: 405/768 \tAverage training loss: 1.51280\tAverage validation loss: 1243.72998\n",
            "Epoch: 48 \tStep: 505/768 \tAverage training loss: 1.49419\tAverage validation loss: 1282.63293\n",
            "Epoch: 48 \tStep: 605/768 \tAverage training loss: 1.50229\tAverage validation loss: 1240.72339\n",
            "Epoch: 48 \tStep: 705/768 \tAverage training loss: 1.52080\tAverage validation loss: 1241.91345\n",
            "Epoch: 49 \tStep: 37/768 \tAverage training loss: 1.00952\tAverage validation loss: 1214.60376\n",
            "Epoch: 49 \tStep: 137/768 \tAverage training loss: 1.22221\tAverage validation loss: 1223.79138\n",
            "Epoch: 49 \tStep: 237/768 \tAverage training loss: 1.53062\tAverage validation loss: 1219.92639\n",
            "Epoch: 49 \tStep: 337/768 \tAverage training loss: 1.62518\tAverage validation loss: 1225.13672\n",
            "Epoch: 49 \tStep: 437/768 \tAverage training loss: 1.56134\tAverage validation loss: 1227.73230\n",
            "Epoch: 49 \tStep: 537/768 \tAverage training loss: 1.61650\tAverage validation loss: 1209.82922\n",
            "Epoch: 49 \tStep: 637/768 \tAverage training loss: 1.55756\tAverage validation loss: 1201.33093\n",
            "Epoch: 49 \tStep: 737/768 \tAverage training loss: 1.52544\tAverage validation loss: 1234.54956\n",
            "Epoch: 50 \tStep: 69/768 \tAverage training loss: 2.01359\tAverage validation loss: 1230.48279\n",
            "Epoch: 50 \tStep: 169/768 \tAverage training loss: 1.98995\tAverage validation loss: 1220.07581\n",
            "Epoch: 50 \tStep: 269/768 \tAverage training loss: 1.78023\tAverage validation loss: 1201.30396\n",
            "Epoch: 50 \tStep: 369/768 \tAverage training loss: 1.61109\tAverage validation loss: 1209.57690\n",
            "Epoch: 50 \tStep: 469/768 \tAverage training loss: 1.58770\tAverage validation loss: 1274.39514\n",
            "Epoch: 50 \tStep: 569/768 \tAverage training loss: 1.53976\tAverage validation loss: 1332.50122\n",
            "Epoch: 50 \tStep: 669/768 \tAverage training loss: 1.52101\tAverage validation loss: 1197.21362\n",
            "Epoch: 51 \tStep: 1/768 \tAverage training loss: 0.37938\tAverage validation loss: 1270.04724\n",
            "Epoch: 51 \tStep: 101/768 \tAverage training loss: 1.14924\tAverage validation loss: 1255.66602\n",
            "Epoch: 51 \tStep: 201/768 \tAverage training loss: 1.34201\tAverage validation loss: 1211.76941\n",
            "Epoch: 51 \tStep: 301/768 \tAverage training loss: 1.52343\tAverage validation loss: 1217.02783\n",
            "Epoch: 51 \tStep: 401/768 \tAverage training loss: 1.52941\tAverage validation loss: 1195.53894\n",
            "Epoch: 51 \tStep: 501/768 \tAverage training loss: 1.48738\tAverage validation loss: 1221.87854\n",
            "Epoch: 51 \tStep: 601/768 \tAverage training loss: 1.50368\tAverage validation loss: 1186.99023\n",
            "Epoch: 51 \tStep: 701/768 \tAverage training loss: 1.52163\tAverage validation loss: 1204.08142\n",
            "Epoch: 52 \tStep: 33/768 \tAverage training loss: 1.98942\tAverage validation loss: 1314.90881\n",
            "Epoch: 52 \tStep: 133/768 \tAverage training loss: 1.68821\tAverage validation loss: 1301.30786\n",
            "Epoch: 52 \tStep: 233/768 \tAverage training loss: 1.52787\tAverage validation loss: 1292.14673\n",
            "Epoch: 52 \tStep: 333/768 \tAverage training loss: 1.53726\tAverage validation loss: 1273.19482\n",
            "Epoch: 52 \tStep: 433/768 \tAverage training loss: 1.50629\tAverage validation loss: 1197.10181\n",
            "Epoch: 52 \tStep: 533/768 \tAverage training loss: 1.48620\tAverage validation loss: 1286.46997\n",
            "Epoch: 52 \tStep: 633/768 \tAverage training loss: 1.58343\tAverage validation loss: 1321.26208\n",
            "Epoch: 52 \tStep: 733/768 \tAverage training loss: 1.57177\tAverage validation loss: 1183.12891\n",
            "Epoch: 53 \tStep: 65/768 \tAverage training loss: 1.53742\tAverage validation loss: 1150.25806\n",
            "Epoch: 53 \tStep: 165/768 \tAverage training loss: 1.61391\tAverage validation loss: 1122.23962\n",
            "Epoch: 53 \tStep: 265/768 \tAverage training loss: 1.44371\tAverage validation loss: 1127.45972\n",
            "Epoch: 53 \tStep: 365/768 \tAverage training loss: 1.44408\tAverage validation loss: 1152.02686\n",
            "Epoch: 53 \tStep: 465/768 \tAverage training loss: 1.47244\tAverage validation loss: 1156.54712\n",
            "Epoch: 53 \tStep: 565/768 \tAverage training loss: 1.48496\tAverage validation loss: 1150.72119\n",
            "Epoch: 53 \tStep: 665/768 \tAverage training loss: 1.51905\tAverage validation loss: 1139.64722\n",
            "Epoch: 53 \tStep: 765/768 \tAverage training loss: 1.55538\tAverage validation loss: 1128.59656\n",
            "Epoch: 54 \tStep: 97/768 \tAverage training loss: 1.75997\tAverage validation loss: 1117.62708\n",
            "Epoch: 54 \tStep: 197/768 \tAverage training loss: 1.73360\tAverage validation loss: 1143.02258\n",
            "Epoch: 54 \tStep: 297/768 \tAverage training loss: 1.83405\tAverage validation loss: 1130.54224\n",
            "Epoch: 54 \tStep: 397/768 \tAverage training loss: 1.73770\tAverage validation loss: 1138.71155\n",
            "Epoch: 54 \tStep: 497/768 \tAverage training loss: 1.64762\tAverage validation loss: 1164.24072\n",
            "Epoch: 54 \tStep: 597/768 \tAverage training loss: 1.67099\tAverage validation loss: 1199.19226\n",
            "Epoch: 54 \tStep: 697/768 \tAverage training loss: 1.60400\tAverage validation loss: 1148.05908\n",
            "Epoch: 55 \tStep: 29/768 \tAverage training loss: 1.42397\tAverage validation loss: 1224.60291\n",
            "Epoch: 55 \tStep: 129/768 \tAverage training loss: 1.49971\tAverage validation loss: 1256.88550\n",
            "Epoch: 55 \tStep: 229/768 \tAverage training loss: 1.41534\tAverage validation loss: 1199.01685\n",
            "Epoch: 55 \tStep: 329/768 \tAverage training loss: 1.50754\tAverage validation loss: 1190.09558\n",
            "Epoch: 55 \tStep: 429/768 \tAverage training loss: 1.48006\tAverage validation loss: 1191.71899\n",
            "Epoch: 55 \tStep: 529/768 \tAverage training loss: 1.46063\tAverage validation loss: 1268.35120\n",
            "Epoch: 55 \tStep: 629/768 \tAverage training loss: 1.47149\tAverage validation loss: 1241.93787\n",
            "Epoch: 55 \tStep: 729/768 \tAverage training loss: 1.43933\tAverage validation loss: 1230.29126\n",
            "Epoch: 56 \tStep: 61/768 \tAverage training loss: 1.63818\tAverage validation loss: 1212.06494\n",
            "Epoch: 56 \tStep: 161/768 \tAverage training loss: 1.65109\tAverage validation loss: 1180.45996\n",
            "Epoch: 56 \tStep: 261/768 \tAverage training loss: 1.68901\tAverage validation loss: 1180.14062\n",
            "Epoch: 56 \tStep: 361/768 \tAverage training loss: 1.59145\tAverage validation loss: 1260.89771\n",
            "Epoch: 56 \tStep: 461/768 \tAverage training loss: 1.51605\tAverage validation loss: 1206.61340\n",
            "Epoch: 56 \tStep: 561/768 \tAverage training loss: 1.48415\tAverage validation loss: 1209.27417\n",
            "Epoch: 56 \tStep: 661/768 \tAverage training loss: 1.42540\tAverage validation loss: 1211.32141\n",
            "Epoch: 56 \tStep: 761/768 \tAverage training loss: 1.40242\tAverage validation loss: 1183.88245\n",
            "Epoch: 57 \tStep: 93/768 \tAverage training loss: 1.75530\tAverage validation loss: 1259.36926\n",
            "Epoch: 57 \tStep: 193/768 \tAverage training loss: 1.69190\tAverage validation loss: 1238.55737\n",
            "Epoch: 57 \tStep: 293/768 \tAverage training loss: 1.57065\tAverage validation loss: 1230.66150\n",
            "Epoch: 57 \tStep: 393/768 \tAverage training loss: 1.49986\tAverage validation loss: 1225.65112\n",
            "Epoch: 57 \tStep: 493/768 \tAverage training loss: 1.47273\tAverage validation loss: 1206.26978\n",
            "Epoch: 57 \tStep: 593/768 \tAverage training loss: 1.47777\tAverage validation loss: 1202.74072\n",
            "Epoch: 57 \tStep: 693/768 \tAverage training loss: 1.50616\tAverage validation loss: 1211.59888\n",
            "Epoch: 58 \tStep: 25/768 \tAverage training loss: 0.94985\tAverage validation loss: 1208.85620\n",
            "Epoch: 58 \tStep: 125/768 \tAverage training loss: 1.27782\tAverage validation loss: 1209.32129\n",
            "Epoch: 58 \tStep: 225/768 \tAverage training loss: 1.51483\tAverage validation loss: 1301.91138\n",
            "Epoch: 58 \tStep: 325/768 \tAverage training loss: 1.45526\tAverage validation loss: 1296.49365\n",
            "Epoch: 58 \tStep: 425/768 \tAverage training loss: 1.54082\tAverage validation loss: 1239.81030\n",
            "Epoch: 58 \tStep: 525/768 \tAverage training loss: 1.55813\tAverage validation loss: 1267.85242\n",
            "Epoch: 58 \tStep: 625/768 \tAverage training loss: 1.49882\tAverage validation loss: 1256.57141\n",
            "Epoch: 58 \tStep: 725/768 \tAverage training loss: 1.46139\tAverage validation loss: 1203.00732\n",
            "Epoch: 59 \tStep: 57/768 \tAverage training loss: 1.52593\tAverage validation loss: 1228.66394\n",
            "Epoch: 59 \tStep: 157/768 \tAverage training loss: 1.47699\tAverage validation loss: 1168.27954\n",
            "Epoch: 59 \tStep: 257/768 \tAverage training loss: 1.40848\tAverage validation loss: 1258.75867\n",
            "Epoch: 59 \tStep: 357/768 \tAverage training loss: 1.45788\tAverage validation loss: 1194.21729\n",
            "Epoch: 59 \tStep: 457/768 \tAverage training loss: 1.49129\tAverage validation loss: 1273.34033\n",
            "Epoch: 59 \tStep: 557/768 \tAverage training loss: 1.51592\tAverage validation loss: 1266.42212\n",
            "Epoch: 59 \tStep: 657/768 \tAverage training loss: 1.54026\tAverage validation loss: 1199.87292\n",
            "Epoch: 59 \tStep: 757/768 \tAverage training loss: 1.49881\tAverage validation loss: 1255.19934\n",
            "Epoch: 60 \tStep: 89/768 \tAverage training loss: 1.37898\tAverage validation loss: 1227.38232\n",
            "Epoch: 60 \tStep: 189/768 \tAverage training loss: 1.32899\tAverage validation loss: 1276.94751\n",
            "Epoch: 60 \tStep: 289/768 \tAverage training loss: 1.35970\tAverage validation loss: 1167.79077\n",
            "Epoch: 60 \tStep: 389/768 \tAverage training loss: 1.33956\tAverage validation loss: 1179.14941\n",
            "Epoch: 60 \tStep: 489/768 \tAverage training loss: 1.39848\tAverage validation loss: 1204.70862\n",
            "Epoch: 60 \tStep: 589/768 \tAverage training loss: 1.41672\tAverage validation loss: 1167.15894\n",
            "Epoch: 60 \tStep: 689/768 \tAverage training loss: 1.46414\tAverage validation loss: 1150.22656\n",
            "Epoch: 61 \tStep: 21/768 \tAverage training loss: 1.81943\tAverage validation loss: 1096.92126\n",
            "Epoch: 61 \tStep: 121/768 \tAverage training loss: 1.24402\tAverage validation loss: 1192.52734\n",
            "Epoch: 61 \tStep: 221/768 \tAverage training loss: 1.39930\tAverage validation loss: 1141.30823\n",
            "Epoch: 61 \tStep: 321/768 \tAverage training loss: 1.35110\tAverage validation loss: 1140.82837\n",
            "Epoch: 61 \tStep: 421/768 \tAverage training loss: 1.38498\tAverage validation loss: 1153.36792\n",
            "Epoch: 61 \tStep: 521/768 \tAverage training loss: 1.43442\tAverage validation loss: 1115.72571\n",
            "Epoch: 61 \tStep: 621/768 \tAverage training loss: 1.39776\tAverage validation loss: 1117.84460\n",
            "Epoch: 61 \tStep: 721/768 \tAverage training loss: 1.37548\tAverage validation loss: 1069.31299\n",
            "Epoch: 62 \tStep: 53/768 \tAverage training loss: 1.62040\tAverage validation loss: 1073.53638\n",
            "Epoch: 62 \tStep: 153/768 \tAverage training loss: 1.46301\tAverage validation loss: 997.98578\n",
            "Epoch: 62 \tStep: 253/768 \tAverage training loss: 1.58799\tAverage validation loss: 1131.74512\n",
            "Epoch: 62 \tStep: 353/768 \tAverage training loss: 1.54873\tAverage validation loss: 1172.60156\n",
            "Epoch: 62 \tStep: 453/768 \tAverage training loss: 1.53603\tAverage validation loss: 1110.92603\n",
            "Epoch: 62 \tStep: 553/768 \tAverage training loss: 1.53130\tAverage validation loss: 1149.22534\n",
            "Epoch: 62 \tStep: 653/768 \tAverage training loss: 1.49886\tAverage validation loss: 1185.78015\n",
            "Epoch: 62 \tStep: 753/768 \tAverage training loss: 1.47795\tAverage validation loss: 1169.57141\n",
            "Epoch: 63 \tStep: 85/768 \tAverage training loss: 1.36081\tAverage validation loss: 1175.80591\n",
            "Epoch: 63 \tStep: 185/768 \tAverage training loss: 1.29726\tAverage validation loss: 1168.28174\n",
            "Epoch: 63 \tStep: 285/768 \tAverage training loss: 1.34682\tAverage validation loss: 1193.20654\n",
            "Epoch: 63 \tStep: 385/768 \tAverage training loss: 1.42264\tAverage validation loss: 1206.42407\n",
            "Epoch: 63 \tStep: 485/768 \tAverage training loss: 1.40676\tAverage validation loss: 1179.55212\n",
            "Epoch: 63 \tStep: 585/768 \tAverage training loss: 1.37514\tAverage validation loss: 1196.56616\n",
            "Epoch: 63 \tStep: 685/768 \tAverage training loss: 1.37951\tAverage validation loss: 1154.60437\n",
            "Epoch: 64 \tStep: 17/768 \tAverage training loss: 1.17054\tAverage validation loss: 1233.24902\n",
            "Epoch: 64 \tStep: 117/768 \tAverage training loss: 1.66317\tAverage validation loss: 1223.80164\n",
            "Epoch: 64 \tStep: 217/768 \tAverage training loss: 1.74322\tAverage validation loss: 1134.07776\n",
            "Epoch: 64 \tStep: 317/768 \tAverage training loss: 1.67354\tAverage validation loss: 1173.16785\n",
            "Epoch: 64 \tStep: 417/768 \tAverage training loss: 1.56613\tAverage validation loss: 1166.67749\n",
            "Epoch: 64 \tStep: 517/768 \tAverage training loss: 1.53118\tAverage validation loss: 1283.35889\n",
            "Epoch: 64 \tStep: 617/768 \tAverage training loss: 1.54553\tAverage validation loss: 1321.68335\n",
            "Epoch: 64 \tStep: 717/768 \tAverage training loss: 1.52769\tAverage validation loss: 1297.81287\n",
            "Epoch: 65 \tStep: 49/768 \tAverage training loss: 1.01467\tAverage validation loss: 1340.87402\n",
            "Epoch: 65 \tStep: 149/768 \tAverage training loss: 1.25612\tAverage validation loss: 1309.43750\n",
            "Epoch: 65 \tStep: 249/768 \tAverage training loss: 1.32693\tAverage validation loss: 1215.92212\n",
            "Epoch: 65 \tStep: 349/768 \tAverage training loss: 1.56008\tAverage validation loss: 1141.19800\n",
            "Epoch: 65 \tStep: 449/768 \tAverage training loss: 1.52838\tAverage validation loss: 1218.45020\n",
            "Epoch: 65 \tStep: 549/768 \tAverage training loss: 1.49352\tAverage validation loss: 1149.02551\n",
            "Epoch: 65 \tStep: 649/768 \tAverage training loss: 1.45467\tAverage validation loss: 1162.36902\n",
            "Epoch: 65 \tStep: 749/768 \tAverage training loss: 1.46893\tAverage validation loss: 1262.42725\n",
            "Epoch: 66 \tStep: 81/768 \tAverage training loss: 1.49610\tAverage validation loss: 1242.79785\n",
            "Epoch: 66 \tStep: 181/768 \tAverage training loss: 1.41373\tAverage validation loss: 1276.27014\n",
            "Epoch: 66 \tStep: 281/768 \tAverage training loss: 1.43761\tAverage validation loss: 1289.05396\n",
            "Epoch: 66 \tStep: 381/768 \tAverage training loss: 1.43426\tAverage validation loss: 1235.20825\n",
            "Epoch: 66 \tStep: 481/768 \tAverage training loss: 1.48784\tAverage validation loss: 1208.36230\n",
            "Epoch: 66 \tStep: 581/768 \tAverage training loss: 1.47073\tAverage validation loss: 1226.26343\n",
            "Epoch: 66 \tStep: 681/768 \tAverage training loss: 1.46411\tAverage validation loss: 1263.96777\n",
            "Epoch: 67 \tStep: 13/768 \tAverage training loss: 1.52567\tAverage validation loss: 1182.54858\n",
            "Epoch: 67 \tStep: 113/768 \tAverage training loss: 1.31694\tAverage validation loss: 1162.62061\n",
            "Epoch: 67 \tStep: 213/768 \tAverage training loss: 1.21053\tAverage validation loss: 1160.37708\n",
            "Epoch: 67 \tStep: 313/768 \tAverage training loss: 1.20053\tAverage validation loss: 1211.82153\n",
            "Epoch: 67 \tStep: 413/768 \tAverage training loss: 1.24333\tAverage validation loss: 1233.35242\n",
            "Epoch: 67 \tStep: 513/768 \tAverage training loss: 1.26067\tAverage validation loss: 1194.63977\n",
            "Epoch: 67 \tStep: 613/768 \tAverage training loss: 1.33914\tAverage validation loss: 1178.53540\n",
            "Epoch: 67 \tStep: 713/768 \tAverage training loss: 1.32925\tAverage validation loss: 1160.08789\n",
            "Epoch: 68 \tStep: 45/768 \tAverage training loss: 1.35362\tAverage validation loss: 1245.48181\n",
            "Epoch: 68 \tStep: 145/768 \tAverage training loss: 1.44193\tAverage validation loss: 1174.48267\n",
            "Epoch: 68 \tStep: 245/768 \tAverage training loss: 1.38517\tAverage validation loss: 1308.67212\n",
            "Epoch: 68 \tStep: 345/768 \tAverage training loss: 1.55270\tAverage validation loss: 1333.65381\n",
            "Epoch: 68 \tStep: 445/768 \tAverage training loss: 1.50812\tAverage validation loss: 1242.80713\n",
            "Epoch: 68 \tStep: 545/768 \tAverage training loss: 1.50840\tAverage validation loss: 1353.26050\n",
            "Epoch: 68 \tStep: 645/768 \tAverage training loss: 1.50881\tAverage validation loss: 1173.05054\n",
            "Epoch: 68 \tStep: 745/768 \tAverage training loss: 1.49097\tAverage validation loss: 1133.04883\n",
            "Epoch: 69 \tStep: 77/768 \tAverage training loss: 1.39336\tAverage validation loss: 1208.45862\n",
            "Epoch: 69 \tStep: 177/768 \tAverage training loss: 1.34635\tAverage validation loss: 1201.21680\n",
            "Epoch: 69 \tStep: 277/768 \tAverage training loss: 1.36946\tAverage validation loss: 1192.26392\n",
            "Epoch: 69 \tStep: 377/768 \tAverage training loss: 1.38248\tAverage validation loss: 1191.22498\n",
            "Epoch: 69 \tStep: 477/768 \tAverage training loss: 1.37736\tAverage validation loss: 1244.71094\n",
            "Epoch: 69 \tStep: 577/768 \tAverage training loss: 1.42139\tAverage validation loss: 1242.98962\n",
            "Epoch: 69 \tStep: 677/768 \tAverage training loss: 1.42090\tAverage validation loss: 1260.11560\n",
            "Epoch: 70 \tStep: 9/768 \tAverage training loss: 2.34704\tAverage validation loss: 1176.94604\n",
            "Epoch: 70 \tStep: 109/768 \tAverage training loss: 1.40756\tAverage validation loss: 1200.96155\n",
            "Epoch: 70 \tStep: 209/768 \tAverage training loss: 1.40756\tAverage validation loss: 1218.73022\n",
            "Epoch: 70 \tStep: 309/768 \tAverage training loss: 1.44300\tAverage validation loss: 1203.46887\n",
            "Epoch: 70 \tStep: 409/768 \tAverage training loss: 1.40348\tAverage validation loss: 1182.57593\n",
            "Epoch: 70 \tStep: 509/768 \tAverage training loss: 1.35677\tAverage validation loss: 1189.38757\n",
            "Epoch: 70 \tStep: 609/768 \tAverage training loss: 1.39026\tAverage validation loss: 1180.74280\n",
            "Epoch: 70 \tStep: 709/768 \tAverage training loss: 1.36921\tAverage validation loss: 1185.49365\n",
            "Epoch: 71 \tStep: 41/768 \tAverage training loss: 1.11360\tAverage validation loss: 1149.33813\n",
            "Epoch: 71 \tStep: 141/768 \tAverage training loss: 1.26624\tAverage validation loss: 1217.65662\n",
            "Epoch: 71 \tStep: 241/768 \tAverage training loss: 1.29368\tAverage validation loss: 1206.28894\n",
            "Epoch: 71 \tStep: 341/768 \tAverage training loss: 1.34542\tAverage validation loss: 1181.20361\n",
            "Epoch: 71 \tStep: 441/768 \tAverage training loss: 1.33928\tAverage validation loss: 1181.97705\n",
            "Epoch: 71 \tStep: 541/768 \tAverage training loss: 1.37801\tAverage validation loss: 1125.95581\n",
            "Epoch: 71 \tStep: 641/768 \tAverage training loss: 1.41897\tAverage validation loss: 1136.02588\n",
            "Epoch: 71 \tStep: 741/768 \tAverage training loss: 1.40662\tAverage validation loss: 1175.41675\n",
            "Epoch: 72 \tStep: 73/768 \tAverage training loss: 1.53516\tAverage validation loss: 1177.03174\n",
            "Epoch: 72 \tStep: 173/768 \tAverage training loss: 1.43262\tAverage validation loss: 1168.70972\n",
            "Epoch: 72 \tStep: 273/768 \tAverage training loss: 1.42288\tAverage validation loss: 1150.31824\n",
            "Epoch: 72 \tStep: 373/768 \tAverage training loss: 1.40688\tAverage validation loss: 1155.42749\n",
            "Epoch: 72 \tStep: 473/768 \tAverage training loss: 1.35039\tAverage validation loss: 1171.11499\n",
            "Epoch: 72 \tStep: 573/768 \tAverage training loss: 1.34074\tAverage validation loss: 1132.82690\n",
            "Epoch: 72 \tStep: 673/768 \tAverage training loss: 1.33922\tAverage validation loss: 1117.80469\n",
            "Epoch: 73 \tStep: 5/768 \tAverage training loss: 1.37236\tAverage validation loss: 1121.93481\n",
            "Epoch: 73 \tStep: 105/768 \tAverage training loss: 1.29426\tAverage validation loss: 1186.14771\n",
            "Epoch: 73 \tStep: 205/768 \tAverage training loss: 1.29962\tAverage validation loss: 1127.22900\n",
            "Epoch: 73 \tStep: 305/768 \tAverage training loss: 1.34183\tAverage validation loss: 1123.73267\n",
            "Epoch: 73 \tStep: 405/768 \tAverage training loss: 1.37795\tAverage validation loss: 1228.82275\n",
            "Epoch: 73 \tStep: 505/768 \tAverage training loss: 1.41109\tAverage validation loss: 1194.23535\n",
            "Epoch: 73 \tStep: 605/768 \tAverage training loss: 1.44413\tAverage validation loss: 1216.96387\n",
            "Epoch: 73 \tStep: 705/768 \tAverage training loss: 1.46814\tAverage validation loss: 1219.93738\n",
            "Epoch: 74 \tStep: 37/768 \tAverage training loss: 1.73391\tAverage validation loss: 1172.27087\n",
            "Epoch: 74 \tStep: 137/768 \tAverage training loss: 1.43746\tAverage validation loss: 1220.00793\n",
            "Epoch: 74 \tStep: 237/768 \tAverage training loss: 1.48805\tAverage validation loss: 1235.33374\n",
            "Epoch: 74 \tStep: 337/768 \tAverage training loss: 1.53583\tAverage validation loss: 1210.97729\n",
            "Epoch: 74 \tStep: 437/768 \tAverage training loss: 1.47719\tAverage validation loss: 1210.64087\n",
            "Epoch: 74 \tStep: 537/768 \tAverage training loss: 1.44618\tAverage validation loss: 1159.98926\n",
            "Epoch: 74 \tStep: 637/768 \tAverage training loss: 1.39855\tAverage validation loss: 1104.35278\n",
            "Epoch: 74 \tStep: 737/768 \tAverage training loss: 1.38378\tAverage validation loss: 1192.64429\n",
            "Epoch: 75 \tStep: 69/768 \tAverage training loss: 1.53880\tAverage validation loss: 1187.45715\n",
            "Epoch: 75 \tStep: 169/768 \tAverage training loss: 1.38778\tAverage validation loss: 1155.37183\n",
            "Epoch: 75 \tStep: 269/768 \tAverage training loss: 1.37938\tAverage validation loss: 1140.64307\n",
            "Epoch: 75 \tStep: 369/768 \tAverage training loss: 1.40320\tAverage validation loss: 1170.34412\n",
            "Epoch: 75 \tStep: 469/768 \tAverage training loss: 1.41891\tAverage validation loss: 1183.52686\n",
            "Epoch: 75 \tStep: 569/768 \tAverage training loss: 1.38108\tAverage validation loss: 1197.71045\n",
            "Epoch: 75 \tStep: 669/768 \tAverage training loss: 1.41261\tAverage validation loss: 1145.29565\n",
            "Epoch: 76 \tStep: 1/768 \tAverage training loss: 1.07952\tAverage validation loss: 1187.78735\n",
            "Epoch: 76 \tStep: 101/768 \tAverage training loss: 1.42179\tAverage validation loss: 1166.32227\n",
            "Epoch: 76 \tStep: 201/768 \tAverage training loss: 1.48788\tAverage validation loss: 1136.92676\n",
            "Epoch: 76 \tStep: 301/768 \tAverage training loss: 1.52493\tAverage validation loss: 1151.48767\n",
            "Epoch: 76 \tStep: 401/768 \tAverage training loss: 1.50911\tAverage validation loss: 1164.24939\n",
            "Epoch: 76 \tStep: 501/768 \tAverage training loss: 1.45699\tAverage validation loss: 1114.71460\n",
            "Epoch: 76 \tStep: 601/768 \tAverage training loss: 1.44066\tAverage validation loss: 1136.06262\n",
            "Epoch: 76 \tStep: 701/768 \tAverage training loss: 1.42497\tAverage validation loss: 1134.69775\n",
            "Epoch: 77 \tStep: 33/768 \tAverage training loss: 1.12095\tAverage validation loss: 1161.82935\n",
            "Epoch: 77 \tStep: 133/768 \tAverage training loss: 1.15255\tAverage validation loss: 1212.27515\n",
            "Epoch: 77 \tStep: 233/768 \tAverage training loss: 1.28499\tAverage validation loss: 1172.88599\n",
            "Epoch: 77 \tStep: 333/768 \tAverage training loss: 1.33823\tAverage validation loss: 1237.87744\n",
            "Epoch: 77 \tStep: 433/768 \tAverage training loss: 1.40418\tAverage validation loss: 1238.68054\n",
            "Epoch: 77 \tStep: 533/768 \tAverage training loss: 1.40753\tAverage validation loss: 1195.00977\n",
            "Epoch: 77 \tStep: 633/768 \tAverage training loss: 1.47875\tAverage validation loss: 1197.96558\n",
            "Epoch: 77 \tStep: 733/768 \tAverage training loss: 1.51036\tAverage validation loss: 1216.31567\n",
            "Epoch: 78 \tStep: 65/768 \tAverage training loss: 1.27066\tAverage validation loss: 1149.44946\n",
            "Epoch: 78 \tStep: 165/768 \tAverage training loss: 1.34540\tAverage validation loss: 1162.82764\n",
            "Epoch: 78 \tStep: 265/768 \tAverage training loss: 1.47438\tAverage validation loss: 1168.14795\n",
            "Epoch: 78 \tStep: 365/768 \tAverage training loss: 1.41884\tAverage validation loss: 1147.71912\n",
            "Epoch: 78 \tStep: 465/768 \tAverage training loss: 1.44199\tAverage validation loss: 1184.13977\n",
            "Epoch: 78 \tStep: 565/768 \tAverage training loss: 1.40614\tAverage validation loss: 1163.03064\n",
            "Epoch: 78 \tStep: 665/768 \tAverage training loss: 1.37789\tAverage validation loss: 1156.60425\n",
            "Epoch: 78 \tStep: 765/768 \tAverage training loss: 1.37914\tAverage validation loss: 1160.68262\n",
            "Epoch: 79 \tStep: 97/768 \tAverage training loss: 1.10982\tAverage validation loss: 1164.77515\n",
            "Epoch: 79 \tStep: 197/768 \tAverage training loss: 1.35417\tAverage validation loss: 1167.21704\n",
            "Epoch: 79 \tStep: 297/768 \tAverage training loss: 1.32437\tAverage validation loss: 1156.85742\n",
            "Epoch: 79 \tStep: 397/768 \tAverage training loss: 1.35171\tAverage validation loss: 1155.31665\n",
            "Epoch: 79 \tStep: 497/768 \tAverage training loss: 1.42604\tAverage validation loss: 1200.31775\n",
            "Epoch: 79 \tStep: 597/768 \tAverage training loss: 1.44329\tAverage validation loss: 1191.64771\n",
            "Epoch: 79 \tStep: 697/768 \tAverage training loss: 1.42563\tAverage validation loss: 1200.48926\n",
            "Epoch: 80 \tStep: 29/768 \tAverage training loss: 1.58949\tAverage validation loss: 1210.18652\n",
            "Epoch: 80 \tStep: 129/768 \tAverage training loss: 1.42350\tAverage validation loss: 1188.90662\n",
            "Epoch: 80 \tStep: 229/768 \tAverage training loss: 1.43713\tAverage validation loss: 1191.49902\n",
            "Epoch: 80 \tStep: 329/768 \tAverage training loss: 1.37027\tAverage validation loss: 1211.47217\n",
            "Epoch: 80 \tStep: 429/768 \tAverage training loss: 1.40905\tAverage validation loss: 1186.91150\n",
            "Epoch: 80 \tStep: 529/768 \tAverage training loss: 1.43470\tAverage validation loss: 1169.76807\n",
            "Epoch: 80 \tStep: 629/768 \tAverage training loss: 1.45509\tAverage validation loss: 1205.50159\n",
            "Epoch: 80 \tStep: 729/768 \tAverage training loss: 1.46958\tAverage validation loss: 1232.03394\n",
            "Epoch: 81 \tStep: 61/768 \tAverage training loss: 1.83363\tAverage validation loss: 1234.94727\n",
            "Epoch: 81 \tStep: 161/768 \tAverage training loss: 1.54182\tAverage validation loss: 1165.74829\n",
            "Epoch: 81 \tStep: 261/768 \tAverage training loss: 1.63665\tAverage validation loss: 1171.24109\n",
            "Epoch: 81 \tStep: 361/768 \tAverage training loss: 1.59043\tAverage validation loss: 1271.84668\n",
            "Epoch: 81 \tStep: 461/768 \tAverage training loss: 1.57125\tAverage validation loss: 1222.02222\n",
            "Epoch: 81 \tStep: 561/768 \tAverage training loss: 1.54192\tAverage validation loss: 1215.08521\n",
            "Epoch: 81 \tStep: 661/768 \tAverage training loss: 1.50095\tAverage validation loss: 1202.00647\n",
            "Epoch: 81 \tStep: 761/768 \tAverage training loss: 1.50707\tAverage validation loss: 1199.90112\n",
            "Epoch: 82 \tStep: 93/768 \tAverage training loss: 1.33446\tAverage validation loss: 1189.10461\n",
            "Epoch: 82 \tStep: 193/768 \tAverage training loss: 1.41106\tAverage validation loss: 1194.32764\n",
            "Epoch: 82 \tStep: 293/768 \tAverage training loss: 1.34532\tAverage validation loss: 1178.98364\n",
            "Epoch: 82 \tStep: 393/768 \tAverage training loss: 1.47536\tAverage validation loss: 1197.02844\n",
            "Epoch: 82 \tStep: 493/768 \tAverage training loss: 1.43657\tAverage validation loss: 1117.15991\n",
            "Epoch: 82 \tStep: 593/768 \tAverage training loss: 1.41927\tAverage validation loss: 1153.14539\n",
            "Epoch: 82 \tStep: 693/768 \tAverage training loss: 1.39627\tAverage validation loss: 1155.92407\n",
            "Epoch: 83 \tStep: 25/768 \tAverage training loss: 1.24015\tAverage validation loss: 1278.00964\n",
            "Epoch: 83 \tStep: 125/768 \tAverage training loss: 1.31949\tAverage validation loss: 1223.83838\n",
            "Epoch: 83 \tStep: 225/768 \tAverage training loss: 1.31969\tAverage validation loss: 1217.58105\n",
            "Epoch: 83 \tStep: 325/768 \tAverage training loss: 1.33509\tAverage validation loss: 1187.59216\n",
            "Epoch: 83 \tStep: 425/768 \tAverage training loss: 1.32130\tAverage validation loss: 1163.58777\n",
            "Epoch: 83 \tStep: 525/768 \tAverage training loss: 1.35290\tAverage validation loss: 1151.31006\n",
            "Epoch: 83 \tStep: 625/768 \tAverage training loss: 1.38143\tAverage validation loss: 1105.89380\n",
            "Epoch: 83 \tStep: 725/768 \tAverage training loss: 1.35674\tAverage validation loss: 1122.86047\n",
            "Epoch: 84 \tStep: 57/768 \tAverage training loss: 1.23806\tAverage validation loss: 1176.38452\n",
            "Epoch: 84 \tStep: 157/768 \tAverage training loss: 1.50534\tAverage validation loss: 1163.80774\n",
            "Epoch: 84 \tStep: 257/768 \tAverage training loss: 1.55091\tAverage validation loss: 1155.92822\n",
            "Epoch: 84 \tStep: 357/768 \tAverage training loss: 1.53844\tAverage validation loss: 1213.55640\n",
            "Epoch: 84 \tStep: 457/768 \tAverage training loss: 1.45847\tAverage validation loss: 1196.87732\n",
            "Epoch: 84 \tStep: 557/768 \tAverage training loss: 1.44722\tAverage validation loss: 1211.37158\n",
            "Epoch: 84 \tStep: 657/768 \tAverage training loss: 1.44360\tAverage validation loss: 1214.96570\n",
            "Epoch: 84 \tStep: 757/768 \tAverage training loss: 1.43895\tAverage validation loss: 1220.47852\n",
            "Epoch: 85 \tStep: 89/768 \tAverage training loss: 1.53189\tAverage validation loss: 1174.64270\n",
            "Epoch: 85 \tStep: 189/768 \tAverage training loss: 1.70455\tAverage validation loss: 1209.15674\n",
            "Epoch: 85 \tStep: 289/768 \tAverage training loss: 1.53331\tAverage validation loss: 1192.52124\n",
            "Epoch: 85 \tStep: 389/768 \tAverage training loss: 1.49879\tAverage validation loss: 1187.18970\n",
            "Epoch: 85 \tStep: 489/768 \tAverage training loss: 1.50977\tAverage validation loss: 1223.60425\n",
            "Epoch: 85 \tStep: 589/768 \tAverage training loss: 1.49517\tAverage validation loss: 1223.06238\n",
            "Epoch: 85 \tStep: 689/768 \tAverage training loss: 1.48609\tAverage validation loss: 1208.57410\n",
            "Epoch: 86 \tStep: 21/768 \tAverage training loss: 1.59153\tAverage validation loss: 1213.71008\n",
            "Epoch: 86 \tStep: 121/768 \tAverage training loss: 1.33644\tAverage validation loss: 1170.67065\n",
            "Epoch: 86 \tStep: 221/768 \tAverage training loss: 1.31364\tAverage validation loss: 1255.05237\n",
            "Epoch: 86 \tStep: 321/768 \tAverage training loss: 1.23367\tAverage validation loss: 1272.80713\n",
            "Epoch: 86 \tStep: 421/768 \tAverage training loss: 1.32017\tAverage validation loss: 1398.30713\n",
            "Epoch: 86 \tStep: 521/768 \tAverage training loss: 1.39776\tAverage validation loss: 1348.80139\n",
            "Epoch: 86 \tStep: 621/768 \tAverage training loss: 1.40727\tAverage validation loss: 1250.35229\n",
            "Epoch: 86 \tStep: 721/768 \tAverage training loss: 1.37982\tAverage validation loss: 1277.40918\n",
            "Epoch: 87 \tStep: 53/768 \tAverage training loss: 1.62768\tAverage validation loss: 1176.16724\n",
            "Epoch: 87 \tStep: 153/768 \tAverage training loss: 1.71848\tAverage validation loss: 1228.70227\n",
            "Epoch: 87 \tStep: 253/768 \tAverage training loss: 1.51697\tAverage validation loss: 1169.93628\n",
            "Epoch: 87 \tStep: 353/768 \tAverage training loss: 1.41600\tAverage validation loss: 1190.87695\n",
            "Epoch: 87 \tStep: 453/768 \tAverage training loss: 1.51939\tAverage validation loss: 1199.62671\n",
            "Epoch: 87 \tStep: 553/768 \tAverage training loss: 1.51832\tAverage validation loss: 1186.86328\n",
            "Epoch: 87 \tStep: 653/768 \tAverage training loss: 1.48938\tAverage validation loss: 1226.70044\n",
            "Epoch: 87 \tStep: 753/768 \tAverage training loss: 1.42475\tAverage validation loss: 1189.95142\n",
            "Epoch: 88 \tStep: 85/768 \tAverage training loss: 1.18885\tAverage validation loss: 1181.91431\n",
            "Epoch: 88 \tStep: 185/768 \tAverage training loss: 1.30422\tAverage validation loss: 1195.88977\n",
            "Epoch: 88 \tStep: 285/768 \tAverage training loss: 1.31375\tAverage validation loss: 1204.08105\n",
            "Epoch: 88 \tStep: 385/768 \tAverage training loss: 1.29088\tAverage validation loss: 1107.67627\n",
            "Epoch: 88 \tStep: 485/768 \tAverage training loss: 1.26623\tAverage validation loss: 1114.37866\n",
            "Epoch: 88 \tStep: 585/768 \tAverage training loss: 1.31951\tAverage validation loss: 1254.04480\n",
            "Epoch: 88 \tStep: 685/768 \tAverage training loss: 1.35287\tAverage validation loss: 1197.94214\n",
            "Epoch: 89 \tStep: 17/768 \tAverage training loss: 1.49906\tAverage validation loss: 1209.70007\n",
            "Epoch: 89 \tStep: 117/768 \tAverage training loss: 1.63536\tAverage validation loss: 1199.46326\n",
            "Epoch: 89 \tStep: 217/768 \tAverage training loss: 1.34864\tAverage validation loss: 1171.55676\n",
            "Epoch: 89 \tStep: 317/768 \tAverage training loss: 1.33082\tAverage validation loss: 1309.35608\n",
            "Epoch: 89 \tStep: 417/768 \tAverage training loss: 1.30931\tAverage validation loss: 1196.78113\n",
            "Epoch: 89 \tStep: 517/768 \tAverage training loss: 1.30195\tAverage validation loss: 1192.06982\n",
            "Epoch: 89 \tStep: 617/768 \tAverage training loss: 1.38290\tAverage validation loss: 1180.10364\n",
            "Epoch: 89 \tStep: 717/768 \tAverage training loss: 1.38922\tAverage validation loss: 1124.95557\n",
            "Epoch: 90 \tStep: 49/768 \tAverage training loss: 1.48586\tAverage validation loss: 1121.93726\n",
            "Epoch: 90 \tStep: 149/768 \tAverage training loss: 1.49384\tAverage validation loss: 1148.06909\n",
            "Epoch: 90 \tStep: 249/768 \tAverage training loss: 1.58041\tAverage validation loss: 1197.57678\n",
            "Epoch: 90 \tStep: 349/768 \tAverage training loss: 1.55385\tAverage validation loss: 1134.86255\n",
            "Epoch: 90 \tStep: 449/768 \tAverage training loss: 1.47320\tAverage validation loss: 1124.19226\n",
            "Epoch: 90 \tStep: 549/768 \tAverage training loss: 1.48110\tAverage validation loss: 1148.34668\n",
            "Epoch: 90 \tStep: 649/768 \tAverage training loss: 1.45517\tAverage validation loss: 1177.48474\n",
            "Epoch: 90 \tStep: 749/768 \tAverage training loss: 1.44257\tAverage validation loss: 1247.14966\n",
            "Epoch: 91 \tStep: 81/768 \tAverage training loss: 1.32455\tAverage validation loss: 1185.72351\n",
            "Epoch: 91 \tStep: 181/768 \tAverage training loss: 1.19229\tAverage validation loss: 1182.95947\n",
            "Epoch: 91 \tStep: 281/768 \tAverage training loss: 1.18665\tAverage validation loss: 1174.32410\n",
            "Epoch: 91 \tStep: 381/768 \tAverage training loss: 1.26534\tAverage validation loss: 1115.41724\n",
            "Epoch: 91 \tStep: 481/768 \tAverage training loss: 1.30989\tAverage validation loss: 1123.75439\n",
            "Epoch: 91 \tStep: 581/768 \tAverage training loss: 1.29056\tAverage validation loss: 1100.86328\n",
            "Epoch: 91 \tStep: 681/768 \tAverage training loss: 1.34140\tAverage validation loss: 1088.84509\n",
            "Epoch: 92 \tStep: 13/768 \tAverage training loss: 0.96022\tAverage validation loss: 1162.53503\n",
            "Epoch: 92 \tStep: 113/768 \tAverage training loss: 1.53643\tAverage validation loss: 1187.60791\n",
            "Epoch: 92 \tStep: 213/768 \tAverage training loss: 1.41468\tAverage validation loss: 1199.05005\n",
            "Epoch: 92 \tStep: 313/768 \tAverage training loss: 1.40354\tAverage validation loss: 1213.53662\n",
            "Epoch: 92 \tStep: 413/768 \tAverage training loss: 1.35361\tAverage validation loss: 1222.57812\n",
            "Epoch: 92 \tStep: 513/768 \tAverage training loss: 1.33641\tAverage validation loss: 1291.63696\n",
            "Epoch: 92 \tStep: 613/768 \tAverage training loss: 1.31520\tAverage validation loss: 1126.35400\n",
            "Epoch: 92 \tStep: 713/768 \tAverage training loss: 1.29236\tAverage validation loss: 1120.03564\n",
            "Epoch: 93 \tStep: 45/768 \tAverage training loss: 1.13067\tAverage validation loss: 1111.90344\n",
            "Epoch: 93 \tStep: 145/768 \tAverage training loss: 1.35418\tAverage validation loss: 1149.70093\n",
            "Epoch: 93 \tStep: 245/768 \tAverage training loss: 1.37908\tAverage validation loss: 1183.16626\n",
            "Epoch: 93 \tStep: 345/768 \tAverage training loss: 1.47938\tAverage validation loss: 1184.76733\n",
            "Epoch: 93 \tStep: 445/768 \tAverage training loss: 1.41954\tAverage validation loss: 1162.29346\n",
            "Epoch: 93 \tStep: 545/768 \tAverage training loss: 1.38023\tAverage validation loss: 1175.69946\n",
            "Epoch: 93 \tStep: 645/768 \tAverage training loss: 1.41461\tAverage validation loss: 1100.03857\n",
            "Epoch: 93 \tStep: 745/768 \tAverage training loss: 1.42381\tAverage validation loss: 1130.81335\n",
            "Epoch: 94 \tStep: 77/768 \tAverage training loss: 1.57735\tAverage validation loss: 1197.79358\n",
            "Epoch: 94 \tStep: 177/768 \tAverage training loss: 1.44157\tAverage validation loss: 1297.63159\n",
            "Epoch: 94 \tStep: 277/768 \tAverage training loss: 1.40404\tAverage validation loss: 1161.95386\n",
            "Epoch: 94 \tStep: 377/768 \tAverage training loss: 1.37672\tAverage validation loss: 1163.09595\n",
            "Epoch: 94 \tStep: 477/768 \tAverage training loss: 1.35658\tAverage validation loss: 1200.83533\n",
            "Epoch: 94 \tStep: 577/768 \tAverage training loss: 1.33022\tAverage validation loss: 1171.00879\n",
            "Epoch: 94 \tStep: 677/768 \tAverage training loss: 1.32657\tAverage validation loss: 1178.47668\n",
            "Epoch: 95 \tStep: 9/768 \tAverage training loss: 1.35561\tAverage validation loss: 1138.72937\n",
            "Epoch: 95 \tStep: 109/768 \tAverage training loss: 1.43631\tAverage validation loss: 1206.48511\n",
            "Epoch: 95 \tStep: 209/768 \tAverage training loss: 1.42973\tAverage validation loss: 1199.83423\n",
            "Epoch: 95 \tStep: 309/768 \tAverage training loss: 1.49920\tAverage validation loss: 1148.90015\n",
            "Epoch: 95 \tStep: 409/768 \tAverage training loss: 1.45438\tAverage validation loss: 1169.90320\n",
            "Epoch: 95 \tStep: 509/768 \tAverage training loss: 1.48576\tAverage validation loss: 1207.95752\n",
            "Epoch: 95 \tStep: 609/768 \tAverage training loss: 1.43758\tAverage validation loss: 1214.42310\n",
            "Epoch: 95 \tStep: 709/768 \tAverage training loss: 1.40227\tAverage validation loss: 1203.32568\n",
            "Epoch: 96 \tStep: 41/768 \tAverage training loss: 1.62808\tAverage validation loss: 1229.18030\n",
            "Epoch: 96 \tStep: 141/768 \tAverage training loss: 1.23285\tAverage validation loss: 1221.63745\n",
            "Epoch: 96 \tStep: 241/768 \tAverage training loss: 1.31568\tAverage validation loss: 1178.80005\n",
            "Epoch: 96 \tStep: 341/768 \tAverage training loss: 1.30269\tAverage validation loss: 1170.13843\n",
            "Epoch: 96 \tStep: 441/768 \tAverage training loss: 1.32035\tAverage validation loss: 1213.79138\n",
            "Epoch: 96 \tStep: 541/768 \tAverage training loss: 1.32809\tAverage validation loss: 1185.05396\n",
            "Epoch: 96 \tStep: 641/768 \tAverage training loss: 1.32154\tAverage validation loss: 1230.57959\n",
            "Epoch: 96 \tStep: 741/768 \tAverage training loss: 1.36144\tAverage validation loss: 1287.47107\n",
            "Epoch: 97 \tStep: 73/768 \tAverage training loss: 1.15958\tAverage validation loss: 1222.89832\n",
            "Epoch: 97 \tStep: 173/768 \tAverage training loss: 1.20576\tAverage validation loss: 1237.77954\n",
            "Epoch: 97 \tStep: 273/768 \tAverage training loss: 1.18417\tAverage validation loss: 1205.19775\n",
            "Epoch: 97 \tStep: 373/768 \tAverage training loss: 1.23412\tAverage validation loss: 1180.62231\n",
            "Epoch: 97 \tStep: 473/768 \tAverage training loss: 1.35496\tAverage validation loss: 1228.76135\n",
            "Epoch: 97 \tStep: 573/768 \tAverage training loss: 1.33651\tAverage validation loss: 1214.25317\n",
            "Epoch: 97 \tStep: 673/768 \tAverage training loss: 1.33236\tAverage validation loss: 1178.87659\n",
            "Epoch: 98 \tStep: 5/768 \tAverage training loss: 1.81079\tAverage validation loss: 1172.96924\n",
            "Epoch: 98 \tStep: 105/768 \tAverage training loss: 1.71709\tAverage validation loss: 1142.37744\n",
            "Epoch: 98 \tStep: 205/768 \tAverage training loss: 1.46644\tAverage validation loss: 1157.94580\n",
            "Epoch: 98 \tStep: 305/768 \tAverage training loss: 1.43276\tAverage validation loss: 1141.72693\n",
            "Epoch: 98 \tStep: 405/768 \tAverage training loss: 1.39897\tAverage validation loss: 1237.55603\n",
            "Epoch: 98 \tStep: 505/768 \tAverage training loss: 1.41413\tAverage validation loss: 1203.78247\n",
            "Epoch: 98 \tStep: 605/768 \tAverage training loss: 1.41309\tAverage validation loss: 1181.84106\n",
            "Epoch: 98 \tStep: 705/768 \tAverage training loss: 1.42763\tAverage validation loss: 1209.28638\n",
            "Epoch: 99 \tStep: 37/768 \tAverage training loss: 1.87755\tAverage validation loss: 1641.40222\n",
            "Epoch: 99 \tStep: 137/768 \tAverage training loss: 1.59027\tAverage validation loss: 1658.32996\n",
            "Epoch: 99 \tStep: 237/768 \tAverage training loss: 1.78916\tAverage validation loss: 1619.88806\n",
            "Epoch: 99 \tStep: 337/768 \tAverage training loss: 1.73927\tAverage validation loss: 1650.90845\n",
            "Epoch: 99 \tStep: 437/768 \tAverage training loss: 1.61909\tAverage validation loss: 1646.41431\n",
            "Epoch: 99 \tStep: 537/768 \tAverage training loss: 1.54014\tAverage validation loss: 1643.04529\n",
            "Epoch: 99 \tStep: 637/768 \tAverage training loss: 1.49041\tAverage validation loss: 1665.19421\n",
            "Epoch: 99 \tStep: 737/768 \tAverage training loss: 1.44513\tAverage validation loss: 1646.78894\n",
            "Epoch: 100 \tStep: 69/768 \tAverage training loss: 1.17330\tAverage validation loss: 1275.80530\n",
            "Epoch: 100 \tStep: 169/768 \tAverage training loss: 1.19881\tAverage validation loss: 1296.89771\n",
            "Epoch: 100 \tStep: 269/768 \tAverage training loss: 1.25715\tAverage validation loss: 1273.34814\n",
            "Epoch: 100 \tStep: 369/768 \tAverage training loss: 1.18856\tAverage validation loss: 1236.23706\n",
            "Epoch: 100 \tStep: 469/768 \tAverage training loss: 1.25426\tAverage validation loss: 1245.87207\n",
            "Epoch: 100 \tStep: 569/768 \tAverage training loss: 1.29806\tAverage validation loss: 1285.55481\n",
            "Epoch: 100 \tStep: 669/768 \tAverage training loss: 1.37302\tAverage validation loss: 1295.84753\n",
            "Training complete... Final Loss: 0.651775598526001\n",
            "Seconds elapsed:585.3739695549011\n",
            "Starting training...\n",
            "Epoch: 1 \tStep: 1/768 \tAverage training loss: 1090.46118\tAverage validation loss: 24743.86523\n",
            "Epoch: 1 \tStep: 101/768 \tAverage training loss: 1928.80257\tAverage validation loss: 21032.27734\n",
            "Epoch: 1 \tStep: 201/768 \tAverage training loss: 1693.75817\tAverage validation loss: 18982.84375\n",
            "Epoch: 1 \tStep: 301/768 \tAverage training loss: 1575.86416\tAverage validation loss: 17210.21094\n",
            "Epoch: 1 \tStep: 401/768 \tAverage training loss: 1442.63911\tAverage validation loss: 15390.95996\n",
            "Epoch: 1 \tStep: 501/768 \tAverage training loss: 1320.22976\tAverage validation loss: 13801.67969\n",
            "Epoch: 1 \tStep: 601/768 \tAverage training loss: 1215.83754\tAverage validation loss: 12386.54883\n",
            "Epoch: 1 \tStep: 701/768 \tAverage training loss: 1118.28921\tAverage validation loss: 11142.09180\n",
            "Epoch: 2 \tStep: 33/768 \tAverage training loss: 316.17056\tAverage validation loss: 10162.93066\n",
            "Epoch: 2 \tStep: 133/768 \tAverage training loss: 317.87736\tAverage validation loss: 9271.79883\n",
            "Epoch: 2 \tStep: 233/768 \tAverage training loss: 295.91759\tAverage validation loss: 8460.48828\n",
            "Epoch: 2 \tStep: 333/768 \tAverage training loss: 265.86461\tAverage validation loss: 7791.34961\n",
            "Epoch: 2 \tStep: 433/768 \tAverage training loss: 246.85277\tAverage validation loss: 7147.50146\n",
            "Epoch: 2 \tStep: 533/768 \tAverage training loss: 228.11949\tAverage validation loss: 6572.49707\n",
            "Epoch: 2 \tStep: 633/768 \tAverage training loss: 209.17953\tAverage validation loss: 6115.91602\n",
            "Epoch: 2 \tStep: 733/768 \tAverage training loss: 193.28680\tAverage validation loss: 5705.23926\n",
            "Epoch: 3 \tStep: 65/768 \tAverage training loss: 67.17026\tAverage validation loss: 5390.14209\n",
            "Epoch: 3 \tStep: 165/768 \tAverage training loss: 68.30093\tAverage validation loss: 5058.24805\n",
            "Epoch: 3 \tStep: 265/768 \tAverage training loss: 62.65958\tAverage validation loss: 4760.31055\n",
            "Epoch: 3 \tStep: 365/768 \tAverage training loss: 58.08912\tAverage validation loss: 4502.75732\n",
            "Epoch: 3 \tStep: 465/768 \tAverage training loss: 54.01458\tAverage validation loss: 4265.66064\n",
            "Epoch: 3 \tStep: 565/768 \tAverage training loss: 48.98402\tAverage validation loss: 4093.10840\n",
            "Epoch: 3 \tStep: 665/768 \tAverage training loss: 45.03271\tAverage validation loss: 3926.98608\n",
            "Epoch: 3 \tStep: 765/768 \tAverage training loss: 42.33833\tAverage validation loss: 3750.42871\n",
            "Epoch: 4 \tStep: 97/768 \tAverage training loss: 23.20156\tAverage validation loss: 3568.63623\n",
            "Epoch: 4 \tStep: 197/768 \tAverage training loss: 20.21008\tAverage validation loss: 3411.17920\n",
            "Epoch: 4 \tStep: 297/768 \tAverage training loss: 17.43210\tAverage validation loss: 3294.66406\n",
            "Epoch: 4 \tStep: 397/768 \tAverage training loss: 15.88257\tAverage validation loss: 3182.46924\n",
            "Epoch: 4 \tStep: 497/768 \tAverage training loss: 15.06465\tAverage validation loss: 3091.78223\n",
            "Epoch: 4 \tStep: 597/768 \tAverage training loss: 13.94362\tAverage validation loss: 3001.13159\n",
            "Epoch: 4 \tStep: 697/768 \tAverage training loss: 13.54582\tAverage validation loss: 2907.21558\n",
            "Epoch: 5 \tStep: 29/768 \tAverage training loss: 11.00384\tAverage validation loss: 2791.31836\n",
            "Epoch: 5 \tStep: 129/768 \tAverage training loss: 7.07751\tAverage validation loss: 2713.29663\n",
            "Epoch: 5 \tStep: 229/768 \tAverage training loss: 7.24482\tAverage validation loss: 2639.34473\n",
            "Epoch: 5 \tStep: 329/768 \tAverage training loss: 6.80703\tAverage validation loss: 2576.76147\n",
            "Epoch: 5 \tStep: 429/768 \tAverage training loss: 6.65180\tAverage validation loss: 2498.20972\n",
            "Epoch: 5 \tStep: 529/768 \tAverage training loss: 6.31531\tAverage validation loss: 2449.64746\n",
            "Epoch: 5 \tStep: 629/768 \tAverage training loss: 5.97793\tAverage validation loss: 2410.89893\n",
            "Epoch: 5 \tStep: 729/768 \tAverage training loss: 5.83988\tAverage validation loss: 2355.09204\n",
            "Epoch: 6 \tStep: 61/768 \tAverage training loss: 3.49621\tAverage validation loss: 2301.99536\n",
            "Epoch: 6 \tStep: 161/768 \tAverage training loss: 3.61454\tAverage validation loss: 2269.70117\n",
            "Epoch: 6 \tStep: 261/768 \tAverage training loss: 3.81406\tAverage validation loss: 2235.09058\n",
            "Epoch: 6 \tStep: 361/768 \tAverage training loss: 3.78941\tAverage validation loss: 2210.75146\n",
            "Epoch: 6 \tStep: 461/768 \tAverage training loss: 4.00058\tAverage validation loss: 2168.55371\n",
            "Epoch: 6 \tStep: 561/768 \tAverage training loss: 4.06357\tAverage validation loss: 2131.53784\n",
            "Epoch: 6 \tStep: 661/768 \tAverage training loss: 3.95726\tAverage validation loss: 2091.01660\n",
            "Epoch: 6 \tStep: 761/768 \tAverage training loss: 3.72044\tAverage validation loss: 2051.91357\n",
            "Epoch: 7 \tStep: 93/768 \tAverage training loss: 2.38618\tAverage validation loss: 2026.80762\n",
            "Epoch: 7 \tStep: 193/768 \tAverage training loss: 2.65997\tAverage validation loss: 1988.28662\n",
            "Epoch: 7 \tStep: 293/768 \tAverage training loss: 2.73229\tAverage validation loss: 1953.19995\n",
            "Epoch: 7 \tStep: 393/768 \tAverage training loss: 2.81691\tAverage validation loss: 1928.79688\n",
            "Epoch: 7 \tStep: 493/768 \tAverage training loss: 2.78411\tAverage validation loss: 1899.04883\n",
            "Epoch: 7 \tStep: 593/768 \tAverage training loss: 2.77892\tAverage validation loss: 1879.33276\n",
            "Epoch: 7 \tStep: 693/768 \tAverage training loss: 2.79036\tAverage validation loss: 1858.22839\n",
            "Epoch: 8 \tStep: 25/768 \tAverage training loss: 1.70023\tAverage validation loss: 1842.15356\n",
            "Epoch: 8 \tStep: 125/768 \tAverage training loss: 2.60427\tAverage validation loss: 1815.86621\n",
            "Epoch: 8 \tStep: 225/768 \tAverage training loss: 2.62123\tAverage validation loss: 1794.48584\n",
            "Epoch: 8 \tStep: 325/768 \tAverage training loss: 2.69164\tAverage validation loss: 1788.03589\n",
            "Epoch: 8 \tStep: 425/768 \tAverage training loss: 2.61594\tAverage validation loss: 1767.76196\n",
            "Epoch: 8 \tStep: 525/768 \tAverage training loss: 2.55450\tAverage validation loss: 1745.60547\n",
            "Epoch: 8 \tStep: 625/768 \tAverage training loss: 2.56584\tAverage validation loss: 1731.30261\n",
            "Epoch: 8 \tStep: 725/768 \tAverage training loss: 2.56125\tAverage validation loss: 1708.81677\n",
            "Epoch: 9 \tStep: 57/768 \tAverage training loss: 3.03359\tAverage validation loss: 1699.12451\n",
            "Epoch: 9 \tStep: 157/768 \tAverage training loss: 2.63565\tAverage validation loss: 1679.01489\n",
            "Epoch: 9 \tStep: 257/768 \tAverage training loss: 2.62396\tAverage validation loss: 1669.22070\n",
            "Epoch: 9 \tStep: 357/768 \tAverage training loss: 2.53967\tAverage validation loss: 1665.61157\n",
            "Epoch: 9 \tStep: 457/768 \tAverage training loss: 2.53290\tAverage validation loss: 1664.63428\n",
            "Epoch: 9 \tStep: 557/768 \tAverage training loss: 2.47928\tAverage validation loss: 1646.34937\n",
            "Epoch: 9 \tStep: 657/768 \tAverage training loss: 2.37931\tAverage validation loss: 1628.75708\n",
            "Epoch: 9 \tStep: 757/768 \tAverage training loss: 2.29210\tAverage validation loss: 1611.50818\n",
            "Epoch: 10 \tStep: 89/768 \tAverage training loss: 2.07491\tAverage validation loss: 1654.77441\n",
            "Epoch: 10 \tStep: 189/768 \tAverage training loss: 1.99796\tAverage validation loss: 1630.74976\n",
            "Epoch: 10 \tStep: 289/768 \tAverage training loss: 1.99949\tAverage validation loss: 1632.81580\n",
            "Epoch: 10 \tStep: 389/768 \tAverage training loss: 2.07211\tAverage validation loss: 1619.68311\n",
            "Epoch: 10 \tStep: 489/768 \tAverage training loss: 2.04196\tAverage validation loss: 1590.62158\n",
            "Epoch: 10 \tStep: 589/768 \tAverage training loss: 2.18392\tAverage validation loss: 1547.30640\n",
            "Epoch: 10 \tStep: 689/768 \tAverage training loss: 2.24610\tAverage validation loss: 1533.07031\n",
            "Epoch: 11 \tStep: 21/768 \tAverage training loss: 3.08810\tAverage validation loss: 1518.79175\n",
            "Epoch: 11 \tStep: 121/768 \tAverage training loss: 2.37281\tAverage validation loss: 1497.69470\n",
            "Epoch: 11 \tStep: 221/768 \tAverage training loss: 2.26690\tAverage validation loss: 1521.70044\n",
            "Epoch: 11 \tStep: 321/768 \tAverage training loss: 2.22037\tAverage validation loss: 1494.37549\n",
            "Epoch: 11 \tStep: 421/768 \tAverage training loss: 2.18060\tAverage validation loss: 1472.92505\n",
            "Epoch: 11 \tStep: 521/768 \tAverage training loss: 2.14770\tAverage validation loss: 1444.95874\n",
            "Epoch: 11 \tStep: 621/768 \tAverage training loss: 2.29030\tAverage validation loss: 1439.43066\n",
            "Epoch: 11 \tStep: 721/768 \tAverage training loss: 2.28656\tAverage validation loss: 1441.76367\n",
            "Epoch: 12 \tStep: 53/768 \tAverage training loss: 2.07125\tAverage validation loss: 1473.37720\n",
            "Epoch: 12 \tStep: 153/768 \tAverage training loss: 2.40851\tAverage validation loss: 1458.24878\n",
            "Epoch: 12 \tStep: 253/768 \tAverage training loss: 2.32840\tAverage validation loss: 1420.24829\n",
            "Epoch: 12 \tStep: 353/768 \tAverage training loss: 2.22329\tAverage validation loss: 1400.13269\n",
            "Epoch: 12 \tStep: 453/768 \tAverage training loss: 2.25581\tAverage validation loss: 1379.71826\n",
            "Epoch: 12 \tStep: 553/768 \tAverage training loss: 2.34298\tAverage validation loss: 1362.48657\n",
            "Epoch: 12 \tStep: 653/768 \tAverage training loss: 2.31348\tAverage validation loss: 1357.13623\n",
            "Epoch: 12 \tStep: 753/768 \tAverage training loss: 2.26308\tAverage validation loss: 1367.24292\n",
            "Epoch: 13 \tStep: 85/768 \tAverage training loss: 1.59563\tAverage validation loss: 1441.01416\n",
            "Epoch: 13 \tStep: 185/768 \tAverage training loss: 1.97775\tAverage validation loss: 1438.56152\n",
            "Epoch: 13 \tStep: 285/768 \tAverage training loss: 2.00823\tAverage validation loss: 1420.14648\n",
            "Epoch: 13 \tStep: 385/768 \tAverage training loss: 2.12485\tAverage validation loss: 1410.16431\n",
            "Epoch: 13 \tStep: 485/768 \tAverage training loss: 2.02109\tAverage validation loss: 1452.93933\n",
            "Epoch: 13 \tStep: 585/768 \tAverage training loss: 1.98678\tAverage validation loss: 1382.85522\n",
            "Epoch: 13 \tStep: 685/768 \tAverage training loss: 1.97695\tAverage validation loss: 1403.47461\n",
            "Epoch: 14 \tStep: 17/768 \tAverage training loss: 2.05404\tAverage validation loss: 1356.00684\n",
            "Epoch: 14 \tStep: 117/768 \tAverage training loss: 1.99043\tAverage validation loss: 1361.56494\n",
            "Epoch: 14 \tStep: 217/768 \tAverage training loss: 1.99002\tAverage validation loss: 1373.80994\n",
            "Epoch: 14 \tStep: 317/768 \tAverage training loss: 1.85110\tAverage validation loss: 1352.08960\n",
            "Epoch: 14 \tStep: 417/768 \tAverage training loss: 1.83119\tAverage validation loss: 1357.40051\n",
            "Epoch: 14 \tStep: 517/768 \tAverage training loss: 1.88080\tAverage validation loss: 1331.40381\n",
            "Epoch: 14 \tStep: 617/768 \tAverage training loss: 1.95300\tAverage validation loss: 1338.23401\n",
            "Epoch: 14 \tStep: 717/768 \tAverage training loss: 2.02122\tAverage validation loss: 1365.73901\n",
            "Epoch: 15 \tStep: 49/768 \tAverage training loss: 2.64886\tAverage validation loss: 1331.69312\n",
            "Epoch: 15 \tStep: 149/768 \tAverage training loss: 1.87631\tAverage validation loss: 1348.89819\n",
            "Epoch: 15 \tStep: 249/768 \tAverage training loss: 1.84948\tAverage validation loss: 1358.30054\n",
            "Epoch: 15 \tStep: 349/768 \tAverage training loss: 1.95232\tAverage validation loss: 1334.34204\n",
            "Epoch: 15 \tStep: 449/768 \tAverage training loss: 1.94214\tAverage validation loss: 1322.15466\n",
            "Epoch: 15 \tStep: 549/768 \tAverage training loss: 1.93338\tAverage validation loss: 1330.16431\n",
            "Epoch: 15 \tStep: 649/768 \tAverage training loss: 1.86572\tAverage validation loss: 1327.33044\n",
            "Epoch: 15 \tStep: 749/768 \tAverage training loss: 1.90278\tAverage validation loss: 1315.80640\n",
            "Epoch: 16 \tStep: 81/768 \tAverage training loss: 2.00615\tAverage validation loss: 1293.97144\n",
            "Epoch: 16 \tStep: 181/768 \tAverage training loss: 2.09798\tAverage validation loss: 1315.72144\n",
            "Epoch: 16 \tStep: 281/768 \tAverage training loss: 2.04760\tAverage validation loss: 1302.34290\n",
            "Epoch: 16 \tStep: 381/768 \tAverage training loss: 2.14188\tAverage validation loss: 1352.75977\n",
            "Epoch: 16 \tStep: 481/768 \tAverage training loss: 2.07672\tAverage validation loss: 1297.21045\n",
            "Epoch: 16 \tStep: 581/768 \tAverage training loss: 2.04784\tAverage validation loss: 1265.23706\n",
            "Epoch: 16 \tStep: 681/768 \tAverage training loss: 2.09856\tAverage validation loss: 1280.93579\n",
            "Epoch: 17 \tStep: 13/768 \tAverage training loss: 2.30032\tAverage validation loss: 1225.28296\n",
            "Epoch: 17 \tStep: 113/768 \tAverage training loss: 2.37524\tAverage validation loss: 1205.41724\n",
            "Epoch: 17 \tStep: 213/768 \tAverage training loss: 2.36156\tAverage validation loss: 1214.89856\n",
            "Epoch: 17 \tStep: 313/768 \tAverage training loss: 2.45500\tAverage validation loss: 1244.88440\n",
            "Epoch: 17 \tStep: 413/768 \tAverage training loss: 2.26413\tAverage validation loss: 1232.61877\n",
            "Epoch: 17 \tStep: 513/768 \tAverage training loss: 2.33386\tAverage validation loss: 1200.84851\n",
            "Epoch: 17 \tStep: 613/768 \tAverage training loss: 2.32356\tAverage validation loss: 1213.73193\n",
            "Epoch: 17 \tStep: 713/768 \tAverage training loss: 2.33559\tAverage validation loss: 1215.27856\n",
            "Epoch: 18 \tStep: 45/768 \tAverage training loss: 2.47864\tAverage validation loss: 1314.44055\n",
            "Epoch: 18 \tStep: 145/768 \tAverage training loss: 2.07447\tAverage validation loss: 1289.02466\n",
            "Epoch: 18 \tStep: 245/768 \tAverage training loss: 1.94950\tAverage validation loss: 1234.36768\n",
            "Epoch: 18 \tStep: 345/768 \tAverage training loss: 1.90971\tAverage validation loss: 1229.21729\n",
            "Epoch: 18 \tStep: 445/768 \tAverage training loss: 1.96325\tAverage validation loss: 1173.02429\n",
            "Epoch: 18 \tStep: 545/768 \tAverage training loss: 2.04471\tAverage validation loss: 1166.91357\n",
            "Epoch: 18 \tStep: 645/768 \tAverage training loss: 2.03804\tAverage validation loss: 1173.71118\n",
            "Epoch: 18 \tStep: 745/768 \tAverage training loss: 2.07144\tAverage validation loss: 1184.11072\n",
            "Epoch: 19 \tStep: 77/768 \tAverage training loss: 2.67976\tAverage validation loss: 1231.45093\n",
            "Epoch: 19 \tStep: 177/768 \tAverage training loss: 2.25058\tAverage validation loss: 1194.46448\n",
            "Epoch: 19 \tStep: 277/768 \tAverage training loss: 2.15278\tAverage validation loss: 1179.01636\n",
            "Epoch: 19 \tStep: 377/768 \tAverage training loss: 2.08754\tAverage validation loss: 1159.53882\n",
            "Epoch: 19 \tStep: 477/768 \tAverage training loss: 1.99930\tAverage validation loss: 1186.23755\n",
            "Epoch: 19 \tStep: 577/768 \tAverage training loss: 2.25267\tAverage validation loss: 1160.60693\n",
            "Epoch: 19 \tStep: 677/768 \tAverage training loss: 2.28508\tAverage validation loss: 1138.74463\n",
            "Epoch: 20 \tStep: 9/768 \tAverage training loss: 2.74704\tAverage validation loss: 1182.59033\n",
            "Epoch: 20 \tStep: 109/768 \tAverage training loss: 1.79188\tAverage validation loss: 1133.03418\n",
            "Epoch: 20 \tStep: 209/768 \tAverage training loss: 2.07443\tAverage validation loss: 1235.04736\n",
            "Epoch: 20 \tStep: 309/768 \tAverage training loss: 1.98147\tAverage validation loss: 1198.41345\n",
            "Epoch: 20 \tStep: 409/768 \tAverage training loss: 2.03999\tAverage validation loss: 1225.45508\n",
            "Epoch: 20 \tStep: 509/768 \tAverage training loss: 2.02185\tAverage validation loss: 1207.19836\n",
            "Epoch: 20 \tStep: 609/768 \tAverage training loss: 1.97032\tAverage validation loss: 1184.55908\n",
            "Epoch: 20 \tStep: 709/768 \tAverage training loss: 1.93318\tAverage validation loss: 1126.30957\n",
            "Epoch: 21 \tStep: 41/768 \tAverage training loss: 1.42000\tAverage validation loss: 1158.92407\n",
            "Epoch: 21 \tStep: 141/768 \tAverage training loss: 1.68213\tAverage validation loss: 1132.41479\n",
            "Epoch: 21 \tStep: 241/768 \tAverage training loss: 1.61847\tAverage validation loss: 1147.70654\n",
            "Epoch: 21 \tStep: 341/768 \tAverage training loss: 1.63771\tAverage validation loss: 1148.27832\n",
            "Epoch: 21 \tStep: 441/768 \tAverage training loss: 1.85815\tAverage validation loss: 1103.27393\n",
            "Epoch: 21 \tStep: 541/768 \tAverage training loss: 1.86188\tAverage validation loss: 1119.41064\n",
            "Epoch: 21 \tStep: 641/768 \tAverage training loss: 1.96228\tAverage validation loss: 1118.30005\n",
            "Epoch: 21 \tStep: 741/768 \tAverage training loss: 2.03575\tAverage validation loss: 1149.86597\n",
            "Epoch: 22 \tStep: 73/768 \tAverage training loss: 2.30902\tAverage validation loss: 1137.82007\n",
            "Epoch: 22 \tStep: 173/768 \tAverage training loss: 1.88263\tAverage validation loss: 1148.36951\n",
            "Epoch: 22 \tStep: 273/768 \tAverage training loss: 1.89482\tAverage validation loss: 1168.62744\n",
            "Epoch: 22 \tStep: 373/768 \tAverage training loss: 1.91630\tAverage validation loss: 1153.35620\n",
            "Epoch: 22 \tStep: 473/768 \tAverage training loss: 1.95474\tAverage validation loss: 1184.95117\n",
            "Epoch: 22 \tStep: 573/768 \tAverage training loss: 1.96457\tAverage validation loss: 1140.33435\n",
            "Epoch: 22 \tStep: 673/768 \tAverage training loss: 1.95663\tAverage validation loss: 1142.52747\n",
            "Epoch: 23 \tStep: 5/768 \tAverage training loss: 1.85685\tAverage validation loss: 1163.32837\n",
            "Epoch: 23 \tStep: 105/768 \tAverage training loss: 1.93052\tAverage validation loss: 1192.43018\n",
            "Epoch: 23 \tStep: 205/768 \tAverage training loss: 1.73649\tAverage validation loss: 1216.56921\n",
            "Epoch: 23 \tStep: 305/768 \tAverage training loss: 1.80171\tAverage validation loss: 1186.72351\n",
            "Epoch: 23 \tStep: 405/768 \tAverage training loss: 1.87835\tAverage validation loss: 1225.97656\n",
            "Epoch: 23 \tStep: 505/768 \tAverage training loss: 1.99426\tAverage validation loss: 1230.57251\n",
            "Epoch: 23 \tStep: 605/768 \tAverage training loss: 1.97990\tAverage validation loss: 1177.27441\n",
            "Epoch: 23 \tStep: 705/768 \tAverage training loss: 2.00200\tAverage validation loss: 1169.02271\n",
            "Epoch: 24 \tStep: 37/768 \tAverage training loss: 2.31731\tAverage validation loss: 1163.06958\n",
            "Epoch: 24 \tStep: 137/768 \tAverage training loss: 1.67266\tAverage validation loss: 1185.70691\n",
            "Epoch: 24 \tStep: 237/768 \tAverage training loss: 2.08769\tAverage validation loss: 1206.97266\n",
            "Epoch: 24 \tStep: 337/768 \tAverage training loss: 2.01717\tAverage validation loss: 1176.85181\n",
            "Epoch: 24 \tStep: 437/768 \tAverage training loss: 2.08271\tAverage validation loss: 1180.54248\n",
            "Epoch: 24 \tStep: 537/768 \tAverage training loss: 2.07691\tAverage validation loss: 1215.16003\n",
            "Epoch: 24 \tStep: 637/768 \tAverage training loss: 2.10980\tAverage validation loss: 1170.36316\n",
            "Epoch: 24 \tStep: 737/768 \tAverage training loss: 2.09585\tAverage validation loss: 1166.85071\n",
            "Epoch: 25 \tStep: 69/768 \tAverage training loss: 2.19555\tAverage validation loss: 1052.42932\n",
            "Epoch: 25 \tStep: 169/768 \tAverage training loss: 1.93656\tAverage validation loss: 1063.24084\n",
            "Epoch: 25 \tStep: 269/768 \tAverage training loss: 1.78288\tAverage validation loss: 1067.67065\n",
            "Epoch: 25 \tStep: 369/768 \tAverage training loss: 1.83725\tAverage validation loss: 1050.70752\n",
            "Epoch: 25 \tStep: 469/768 \tAverage training loss: 1.85298\tAverage validation loss: 1064.67847\n",
            "Epoch: 25 \tStep: 569/768 \tAverage training loss: 1.83876\tAverage validation loss: 1062.31384\n",
            "Epoch: 25 \tStep: 669/768 \tAverage training loss: 1.87040\tAverage validation loss: 1066.72461\n",
            "Epoch: 26 \tStep: 1/768 \tAverage training loss: 0.52634\tAverage validation loss: 1058.88049\n",
            "Epoch: 26 \tStep: 101/768 \tAverage training loss: 2.09897\tAverage validation loss: 1071.63611\n",
            "Epoch: 26 \tStep: 201/768 \tAverage training loss: 2.02660\tAverage validation loss: 1085.19019\n",
            "Epoch: 26 \tStep: 301/768 \tAverage training loss: 1.96669\tAverage validation loss: 1130.06445\n",
            "Epoch: 26 \tStep: 401/768 \tAverage training loss: 1.96562\tAverage validation loss: 1090.11255\n",
            "Epoch: 26 \tStep: 501/768 \tAverage training loss: 1.94497\tAverage validation loss: 1079.14270\n",
            "Epoch: 26 \tStep: 601/768 \tAverage training loss: 1.89454\tAverage validation loss: 1075.59656\n",
            "Epoch: 26 \tStep: 701/768 \tAverage training loss: 1.89056\tAverage validation loss: 1077.66943\n",
            "Epoch: 27 \tStep: 33/768 \tAverage training loss: 1.77611\tAverage validation loss: 1157.63135\n",
            "Epoch: 27 \tStep: 133/768 \tAverage training loss: 1.87986\tAverage validation loss: 1154.02051\n",
            "Epoch: 27 \tStep: 233/768 \tAverage training loss: 1.90602\tAverage validation loss: 1189.74207\n",
            "Epoch: 27 \tStep: 333/768 \tAverage training loss: 1.94137\tAverage validation loss: 1223.57239\n",
            "Epoch: 27 \tStep: 433/768 \tAverage training loss: 1.92502\tAverage validation loss: 1246.78857\n",
            "Epoch: 27 \tStep: 533/768 \tAverage training loss: 1.88212\tAverage validation loss: 1338.26819\n",
            "Epoch: 27 \tStep: 633/768 \tAverage training loss: 1.84627\tAverage validation loss: 1249.24866\n",
            "Epoch: 27 \tStep: 733/768 \tAverage training loss: 1.87605\tAverage validation loss: 1264.07520\n",
            "Epoch: 28 \tStep: 65/768 \tAverage training loss: 2.22862\tAverage validation loss: 1246.85999\n",
            "Epoch: 28 \tStep: 165/768 \tAverage training loss: 1.86651\tAverage validation loss: 1208.32556\n",
            "Epoch: 28 \tStep: 265/768 \tAverage training loss: 1.88517\tAverage validation loss: 1183.24585\n",
            "Epoch: 28 \tStep: 365/768 \tAverage training loss: 1.89498\tAverage validation loss: 1227.11011\n",
            "Epoch: 28 \tStep: 465/768 \tAverage training loss: 1.95984\tAverage validation loss: 1209.18115\n",
            "Epoch: 28 \tStep: 565/768 \tAverage training loss: 1.96733\tAverage validation loss: 1215.97412\n",
            "Epoch: 28 \tStep: 665/768 \tAverage training loss: 1.94483\tAverage validation loss: 1268.53394\n",
            "Epoch: 28 \tStep: 765/768 \tAverage training loss: 1.97383\tAverage validation loss: 1286.57849\n",
            "Epoch: 29 \tStep: 97/768 \tAverage training loss: 1.75270\tAverage validation loss: 1314.17432\n",
            "Epoch: 29 \tStep: 197/768 \tAverage training loss: 1.67683\tAverage validation loss: 1268.25244\n",
            "Epoch: 29 \tStep: 297/768 \tAverage training loss: 1.66853\tAverage validation loss: 1279.05298\n",
            "Epoch: 29 \tStep: 397/768 \tAverage training loss: 1.79619\tAverage validation loss: 1238.31567\n",
            "Epoch: 29 \tStep: 497/768 \tAverage training loss: 1.92465\tAverage validation loss: 1179.55200\n",
            "Epoch: 29 \tStep: 597/768 \tAverage training loss: 1.98718\tAverage validation loss: 1137.52148\n",
            "Epoch: 29 \tStep: 697/768 \tAverage training loss: 2.07586\tAverage validation loss: 1102.83496\n",
            "Epoch: 30 \tStep: 29/768 \tAverage training loss: 3.30119\tAverage validation loss: 1134.83582\n",
            "Epoch: 30 \tStep: 129/768 \tAverage training loss: 2.39969\tAverage validation loss: 1091.95325\n",
            "Epoch: 30 \tStep: 229/768 \tAverage training loss: 2.23700\tAverage validation loss: 1080.99182\n",
            "Epoch: 30 \tStep: 329/768 \tAverage training loss: 2.10615\tAverage validation loss: 1089.99902\n",
            "Epoch: 30 \tStep: 429/768 \tAverage training loss: 2.06985\tAverage validation loss: 1186.08496\n",
            "Epoch: 30 \tStep: 529/768 \tAverage training loss: 2.02048\tAverage validation loss: 1136.92407\n",
            "Epoch: 30 \tStep: 629/768 \tAverage training loss: 1.99540\tAverage validation loss: 1111.45300\n",
            "Epoch: 30 \tStep: 729/768 \tAverage training loss: 2.02242\tAverage validation loss: 1124.82422\n",
            "Epoch: 31 \tStep: 61/768 \tAverage training loss: 2.78894\tAverage validation loss: 1214.73511\n",
            "Epoch: 31 \tStep: 161/768 \tAverage training loss: 2.31198\tAverage validation loss: 1165.47961\n",
            "Epoch: 31 \tStep: 261/768 \tAverage training loss: 2.07523\tAverage validation loss: 1150.73901\n",
            "Epoch: 31 \tStep: 361/768 \tAverage training loss: 2.09228\tAverage validation loss: 1276.18677\n",
            "Epoch: 31 \tStep: 461/768 \tAverage training loss: 2.07827\tAverage validation loss: 1224.48840\n",
            "Epoch: 31 \tStep: 561/768 \tAverage training loss: 2.01521\tAverage validation loss: 1437.66589\n",
            "Epoch: 31 \tStep: 661/768 \tAverage training loss: 1.99191\tAverage validation loss: 1355.32288\n",
            "Epoch: 31 \tStep: 761/768 \tAverage training loss: 1.99600\tAverage validation loss: 1207.91992\n",
            "Epoch: 32 \tStep: 93/768 \tAverage training loss: 2.06136\tAverage validation loss: 1149.85669\n",
            "Epoch: 32 \tStep: 193/768 \tAverage training loss: 1.85031\tAverage validation loss: 1166.20947\n",
            "Epoch: 32 \tStep: 293/768 \tAverage training loss: 1.84739\tAverage validation loss: 1157.49109\n",
            "Epoch: 32 \tStep: 393/768 \tAverage training loss: 1.99217\tAverage validation loss: 1157.69910\n",
            "Epoch: 32 \tStep: 493/768 \tAverage training loss: 1.94528\tAverage validation loss: 1119.29639\n",
            "Epoch: 32 \tStep: 593/768 \tAverage training loss: 1.92720\tAverage validation loss: 1170.11072\n",
            "Epoch: 32 \tStep: 693/768 \tAverage training loss: 1.92818\tAverage validation loss: 1162.51611\n",
            "Epoch: 33 \tStep: 25/768 \tAverage training loss: 2.41021\tAverage validation loss: 1431.95972\n",
            "Epoch: 33 \tStep: 125/768 \tAverage training loss: 1.90789\tAverage validation loss: 1374.30115\n",
            "Epoch: 33 \tStep: 225/768 \tAverage training loss: 1.80003\tAverage validation loss: 1338.69751\n",
            "Epoch: 33 \tStep: 325/768 \tAverage training loss: 1.76314\tAverage validation loss: 1396.07056\n",
            "Epoch: 33 \tStep: 425/768 \tAverage training loss: 1.90479\tAverage validation loss: 1368.51550\n",
            "Epoch: 33 \tStep: 525/768 \tAverage training loss: 1.94712\tAverage validation loss: 1343.34399\n",
            "Epoch: 33 \tStep: 625/768 \tAverage training loss: 1.92343\tAverage validation loss: 1368.92957\n",
            "Epoch: 33 \tStep: 725/768 \tAverage training loss: 1.96422\tAverage validation loss: 1318.57959\n",
            "Epoch: 34 \tStep: 57/768 \tAverage training loss: 2.09509\tAverage validation loss: 1205.38281\n",
            "Epoch: 34 \tStep: 157/768 \tAverage training loss: 2.02109\tAverage validation loss: 1223.61816\n",
            "Epoch: 34 \tStep: 257/768 \tAverage training loss: 2.08468\tAverage validation loss: 1269.86426\n",
            "Epoch: 34 \tStep: 357/768 \tAverage training loss: 2.18254\tAverage validation loss: 1239.68176\n",
            "Epoch: 34 \tStep: 457/768 \tAverage training loss: 2.13705\tAverage validation loss: 1124.86060\n",
            "Epoch: 34 \tStep: 557/768 \tAverage training loss: 2.07687\tAverage validation loss: 1117.94104\n",
            "Epoch: 34 \tStep: 657/768 \tAverage training loss: 2.05919\tAverage validation loss: 1063.87256\n",
            "Epoch: 34 \tStep: 757/768 \tAverage training loss: 2.01883\tAverage validation loss: 1048.21057\n",
            "Epoch: 35 \tStep: 89/768 \tAverage training loss: 2.15484\tAverage validation loss: 1074.80591\n",
            "Epoch: 35 \tStep: 189/768 \tAverage training loss: 2.13130\tAverage validation loss: 1092.63147\n",
            "Epoch: 35 \tStep: 289/768 \tAverage training loss: 2.13004\tAverage validation loss: 1114.79956\n",
            "Epoch: 35 \tStep: 389/768 \tAverage training loss: 1.99378\tAverage validation loss: 1064.63452\n",
            "Epoch: 35 \tStep: 489/768 \tAverage training loss: 1.91747\tAverage validation loss: 1063.07910\n",
            "Epoch: 35 \tStep: 589/768 \tAverage training loss: 1.97427\tAverage validation loss: 987.79578\n",
            "Epoch: 35 \tStep: 689/768 \tAverage training loss: 1.98019\tAverage validation loss: 953.71301\n",
            "Epoch: 36 \tStep: 21/768 \tAverage training loss: 2.52738\tAverage validation loss: 1039.71204\n",
            "Epoch: 36 \tStep: 121/768 \tAverage training loss: 2.04821\tAverage validation loss: 1046.71655\n",
            "Epoch: 36 \tStep: 221/768 \tAverage training loss: 1.73202\tAverage validation loss: 1043.65564\n",
            "Epoch: 36 \tStep: 321/768 \tAverage training loss: 1.78148\tAverage validation loss: 1013.54633\n",
            "Epoch: 36 \tStep: 421/768 \tAverage training loss: 1.81910\tAverage validation loss: 1047.17407\n",
            "Epoch: 36 \tStep: 521/768 \tAverage training loss: 1.88452\tAverage validation loss: 969.57367\n",
            "Epoch: 36 \tStep: 621/768 \tAverage training loss: 1.89741\tAverage validation loss: 964.50848\n",
            "Epoch: 36 \tStep: 721/768 \tAverage training loss: 1.94480\tAverage validation loss: 947.66882\n",
            "Epoch: 37 \tStep: 53/768 \tAverage training loss: 2.48138\tAverage validation loss: 1166.34839\n",
            "Epoch: 37 \tStep: 153/768 \tAverage training loss: 2.29455\tAverage validation loss: 1120.95508\n",
            "Epoch: 37 \tStep: 253/768 \tAverage training loss: 2.10743\tAverage validation loss: 1046.01343\n",
            "Epoch: 37 \tStep: 353/768 \tAverage training loss: 2.11247\tAverage validation loss: 1108.22180\n",
            "Epoch: 37 \tStep: 453/768 \tAverage training loss: 2.04106\tAverage validation loss: 1183.84058\n",
            "Epoch: 37 \tStep: 553/768 \tAverage training loss: 2.09046\tAverage validation loss: 1159.99487\n",
            "Epoch: 37 \tStep: 653/768 \tAverage training loss: 2.04352\tAverage validation loss: 1178.00769\n",
            "Epoch: 37 \tStep: 753/768 \tAverage training loss: 2.03254\tAverage validation loss: 1088.49207\n",
            "Epoch: 38 \tStep: 85/768 \tAverage training loss: 2.43319\tAverage validation loss: 1193.70557\n",
            "Epoch: 38 \tStep: 185/768 \tAverage training loss: 1.99839\tAverage validation loss: 1137.45874\n",
            "Epoch: 38 \tStep: 285/768 \tAverage training loss: 1.88730\tAverage validation loss: 1113.05103\n",
            "Epoch: 38 \tStep: 385/768 \tAverage training loss: 1.91513\tAverage validation loss: 1078.60535\n",
            "Epoch: 38 \tStep: 485/768 \tAverage training loss: 1.90262\tAverage validation loss: 1056.65198\n",
            "Epoch: 38 \tStep: 585/768 \tAverage training loss: 1.80939\tAverage validation loss: 1056.61108\n",
            "Epoch: 38 \tStep: 685/768 \tAverage training loss: 1.95379\tAverage validation loss: 1124.19897\n",
            "Epoch: 39 \tStep: 17/768 \tAverage training loss: 2.08459\tAverage validation loss: 1192.68152\n",
            "Epoch: 39 \tStep: 117/768 \tAverage training loss: 1.66194\tAverage validation loss: 1232.99915\n",
            "Epoch: 39 \tStep: 217/768 \tAverage training loss: 1.77966\tAverage validation loss: 1236.98901\n",
            "Epoch: 39 \tStep: 317/768 \tAverage training loss: 1.83544\tAverage validation loss: 1238.48840\n",
            "Epoch: 39 \tStep: 417/768 \tAverage training loss: 1.90076\tAverage validation loss: 1194.39294\n",
            "Epoch: 39 \tStep: 517/768 \tAverage training loss: 1.95430\tAverage validation loss: 1183.02222\n",
            "Epoch: 39 \tStep: 617/768 \tAverage training loss: 1.93764\tAverage validation loss: 1167.76978\n",
            "Epoch: 39 \tStep: 717/768 \tAverage training loss: 1.90808\tAverage validation loss: 1187.32812\n",
            "Epoch: 40 \tStep: 49/768 \tAverage training loss: 1.98250\tAverage validation loss: 1246.50537\n",
            "Epoch: 40 \tStep: 149/768 \tAverage training loss: 1.70887\tAverage validation loss: 1335.30164\n",
            "Epoch: 40 \tStep: 249/768 \tAverage training loss: 1.78158\tAverage validation loss: 1319.46997\n",
            "Epoch: 40 \tStep: 349/768 \tAverage training loss: 1.90688\tAverage validation loss: 1319.94458\n",
            "Epoch: 40 \tStep: 449/768 \tAverage training loss: 1.84186\tAverage validation loss: 1288.80481\n",
            "Epoch: 40 \tStep: 549/768 \tAverage training loss: 1.82736\tAverage validation loss: 1240.35352\n",
            "Epoch: 40 \tStep: 649/768 \tAverage training loss: 1.77133\tAverage validation loss: 1218.39819\n",
            "Epoch: 40 \tStep: 749/768 \tAverage training loss: 1.76588\tAverage validation loss: 1230.45374\n",
            "Epoch: 41 \tStep: 81/768 \tAverage training loss: 2.12289\tAverage validation loss: 1182.84766\n",
            "Epoch: 41 \tStep: 181/768 \tAverage training loss: 2.00776\tAverage validation loss: 1163.23987\n",
            "Epoch: 41 \tStep: 281/768 \tAverage training loss: 1.88604\tAverage validation loss: 1176.95312\n",
            "Epoch: 41 \tStep: 381/768 \tAverage training loss: 1.98123\tAverage validation loss: 1179.83752\n",
            "Epoch: 41 \tStep: 481/768 \tAverage training loss: 1.88721\tAverage validation loss: 1123.47107\n",
            "Epoch: 41 \tStep: 581/768 \tAverage training loss: 1.84198\tAverage validation loss: 1083.81714\n",
            "Epoch: 41 \tStep: 681/768 \tAverage training loss: 1.90232\tAverage validation loss: 1073.42480\n",
            "Epoch: 42 \tStep: 13/768 \tAverage training loss: 2.02189\tAverage validation loss: 1142.85718\n",
            "Epoch: 42 \tStep: 113/768 \tAverage training loss: 1.77804\tAverage validation loss: 1170.91504\n",
            "Epoch: 42 \tStep: 213/768 \tAverage training loss: 2.11270\tAverage validation loss: 1153.83557\n",
            "Epoch: 42 \tStep: 313/768 \tAverage training loss: 1.96438\tAverage validation loss: 1166.28491\n",
            "Epoch: 42 \tStep: 413/768 \tAverage training loss: 1.91716\tAverage validation loss: 1149.31006\n",
            "Epoch: 42 \tStep: 513/768 \tAverage training loss: 1.88629\tAverage validation loss: 1113.69727\n",
            "Epoch: 42 \tStep: 613/768 \tAverage training loss: 1.83731\tAverage validation loss: 1126.36133\n",
            "Epoch: 42 \tStep: 713/768 \tAverage training loss: 1.84850\tAverage validation loss: 1143.18457\n",
            "Epoch: 43 \tStep: 45/768 \tAverage training loss: 2.20812\tAverage validation loss: 1036.77393\n",
            "Epoch: 43 \tStep: 145/768 \tAverage training loss: 2.01118\tAverage validation loss: 1082.44385\n",
            "Epoch: 43 \tStep: 245/768 \tAverage training loss: 2.09925\tAverage validation loss: 1085.63696\n",
            "Epoch: 43 \tStep: 345/768 \tAverage training loss: 2.11404\tAverage validation loss: 1069.88501\n",
            "Epoch: 43 \tStep: 445/768 \tAverage training loss: 2.09386\tAverage validation loss: 1008.89740\n",
            "Epoch: 43 \tStep: 545/768 \tAverage training loss: 2.02899\tAverage validation loss: 989.97241\n",
            "Epoch: 43 \tStep: 645/768 \tAverage training loss: 2.01407\tAverage validation loss: 1021.16907\n",
            "Epoch: 43 \tStep: 745/768 \tAverage training loss: 2.04169\tAverage validation loss: 945.22601\n",
            "Epoch: 44 \tStep: 77/768 \tAverage training loss: 1.38906\tAverage validation loss: 1024.60474\n",
            "Epoch: 44 \tStep: 177/768 \tAverage training loss: 1.38289\tAverage validation loss: 1057.69617\n",
            "Epoch: 44 \tStep: 277/768 \tAverage training loss: 1.65469\tAverage validation loss: 1097.61353\n",
            "Epoch: 44 \tStep: 377/768 \tAverage training loss: 1.70958\tAverage validation loss: 1051.90076\n",
            "Epoch: 44 \tStep: 477/768 \tAverage training loss: 1.87759\tAverage validation loss: 1091.30273\n",
            "Epoch: 44 \tStep: 577/768 \tAverage training loss: 1.85032\tAverage validation loss: 1124.86279\n",
            "Epoch: 44 \tStep: 677/768 \tAverage training loss: 1.79226\tAverage validation loss: 1090.13000\n",
            "Epoch: 45 \tStep: 9/768 \tAverage training loss: 3.99033\tAverage validation loss: 1061.62646\n",
            "Epoch: 45 \tStep: 109/768 \tAverage training loss: 2.42139\tAverage validation loss: 1227.71631\n",
            "Epoch: 45 \tStep: 209/768 \tAverage training loss: 2.06785\tAverage validation loss: 1329.34253\n",
            "Epoch: 45 \tStep: 309/768 \tAverage training loss: 2.46074\tAverage validation loss: 1146.61914\n",
            "Epoch: 45 \tStep: 409/768 \tAverage training loss: 2.88026\tAverage validation loss: 1199.87915\n",
            "Epoch: 45 \tStep: 509/768 \tAverage training loss: 2.75641\tAverage validation loss: 1251.97473\n",
            "Epoch: 45 \tStep: 609/768 \tAverage training loss: 2.63117\tAverage validation loss: 1216.51953\n",
            "Epoch: 45 \tStep: 709/768 \tAverage training loss: 2.54521\tAverage validation loss: 1226.80298\n",
            "Epoch: 46 \tStep: 41/768 \tAverage training loss: 1.90438\tAverage validation loss: 1169.17505\n",
            "Epoch: 46 \tStep: 141/768 \tAverage training loss: 1.96785\tAverage validation loss: 1120.80371\n",
            "Epoch: 46 \tStep: 241/768 \tAverage training loss: 1.87431\tAverage validation loss: 1096.84509\n",
            "Epoch: 46 \tStep: 341/768 \tAverage training loss: 1.89411\tAverage validation loss: 1068.20654\n",
            "Epoch: 46 \tStep: 441/768 \tAverage training loss: 1.88624\tAverage validation loss: 1110.04639\n",
            "Epoch: 46 \tStep: 541/768 \tAverage training loss: 1.91395\tAverage validation loss: 1183.46606\n",
            "Epoch: 46 \tStep: 641/768 \tAverage training loss: 1.90367\tAverage validation loss: 1154.73889\n",
            "Epoch: 46 \tStep: 741/768 \tAverage training loss: 1.91387\tAverage validation loss: 1152.53467\n",
            "Epoch: 47 \tStep: 73/768 \tAverage training loss: 1.55004\tAverage validation loss: 1331.00513\n",
            "Epoch: 47 \tStep: 173/768 \tAverage training loss: 1.86606\tAverage validation loss: 1319.30005\n",
            "Epoch: 47 \tStep: 273/768 \tAverage training loss: 1.84539\tAverage validation loss: 1317.60364\n",
            "Epoch: 47 \tStep: 373/768 \tAverage training loss: 1.79195\tAverage validation loss: 1239.82324\n",
            "Epoch: 47 \tStep: 473/768 \tAverage training loss: 1.76304\tAverage validation loss: 1272.11084\n",
            "Epoch: 47 \tStep: 573/768 \tAverage training loss: 1.72200\tAverage validation loss: 1277.96179\n",
            "Epoch: 47 \tStep: 673/768 \tAverage training loss: 1.73394\tAverage validation loss: 1296.79871\n",
            "Epoch: 48 \tStep: 5/768 \tAverage training loss: 1.76099\tAverage validation loss: 1322.42517\n",
            "Epoch: 48 \tStep: 105/768 \tAverage training loss: 1.90015\tAverage validation loss: 1376.00635\n",
            "Epoch: 48 \tStep: 205/768 \tAverage training loss: 2.23638\tAverage validation loss: 1360.98962\n",
            "Epoch: 48 \tStep: 305/768 \tAverage training loss: 2.10494\tAverage validation loss: 1367.28418\n",
            "Epoch: 48 \tStep: 405/768 \tAverage training loss: 2.05898\tAverage validation loss: 1274.50537\n",
            "Epoch: 48 \tStep: 505/768 \tAverage training loss: 2.02955\tAverage validation loss: 1272.51733\n",
            "Epoch: 48 \tStep: 605/768 \tAverage training loss: 1.95093\tAverage validation loss: 1338.58618\n",
            "Epoch: 48 \tStep: 705/768 \tAverage training loss: 1.91198\tAverage validation loss: 1310.27576\n",
            "Epoch: 49 \tStep: 37/768 \tAverage training loss: 1.61490\tAverage validation loss: 1350.62842\n",
            "Epoch: 49 \tStep: 137/768 \tAverage training loss: 1.75165\tAverage validation loss: 1320.60327\n",
            "Epoch: 49 \tStep: 237/768 \tAverage training loss: 1.73476\tAverage validation loss: 1287.91199\n",
            "Epoch: 49 \tStep: 337/768 \tAverage training loss: 1.73036\tAverage validation loss: 1252.06494\n",
            "Epoch: 49 \tStep: 437/768 \tAverage training loss: 1.64597\tAverage validation loss: 1259.43359\n",
            "Epoch: 49 \tStep: 537/768 \tAverage training loss: 1.62090\tAverage validation loss: 1328.40332\n",
            "Epoch: 49 \tStep: 637/768 \tAverage training loss: 1.66050\tAverage validation loss: 1322.89099\n",
            "Epoch: 49 \tStep: 737/768 \tAverage training loss: 1.70311\tAverage validation loss: 1239.59875\n",
            "Epoch: 50 \tStep: 69/768 \tAverage training loss: 2.62026\tAverage validation loss: 1078.54553\n",
            "Epoch: 50 \tStep: 169/768 \tAverage training loss: 2.25457\tAverage validation loss: 1087.02295\n",
            "Epoch: 50 \tStep: 269/768 \tAverage training loss: 2.14800\tAverage validation loss: 1093.24268\n",
            "Epoch: 50 \tStep: 369/768 \tAverage training loss: 2.10382\tAverage validation loss: 1095.06763\n",
            "Epoch: 50 \tStep: 469/768 \tAverage training loss: 1.98831\tAverage validation loss: 1023.85156\n",
            "Epoch: 50 \tStep: 569/768 \tAverage training loss: 1.91364\tAverage validation loss: 1061.54529\n",
            "Epoch: 50 \tStep: 669/768 \tAverage training loss: 1.83621\tAverage validation loss: 1040.58423\n",
            "Epoch: 51 \tStep: 1/768 \tAverage training loss: 4.49929\tAverage validation loss: 1070.79883\n",
            "Epoch: 51 \tStep: 101/768 \tAverage training loss: 2.38010\tAverage validation loss: 1189.68933\n",
            "Epoch: 51 \tStep: 201/768 \tAverage training loss: 1.96546\tAverage validation loss: 1192.13879\n",
            "Epoch: 51 \tStep: 301/768 \tAverage training loss: 2.08328\tAverage validation loss: 1103.95850\n",
            "Epoch: 51 \tStep: 401/768 \tAverage training loss: 1.99117\tAverage validation loss: 1129.47400\n",
            "Epoch: 51 \tStep: 501/768 \tAverage training loss: 1.91510\tAverage validation loss: 1162.11426\n",
            "Epoch: 51 \tStep: 601/768 \tAverage training loss: 1.96977\tAverage validation loss: 1139.31458\n",
            "Epoch: 51 \tStep: 701/768 \tAverage training loss: 1.94067\tAverage validation loss: 1152.83960\n",
            "Epoch: 52 \tStep: 33/768 \tAverage training loss: 2.13299\tAverage validation loss: 1057.34216\n",
            "Epoch: 52 \tStep: 133/768 \tAverage training loss: 1.98416\tAverage validation loss: 1011.83557\n",
            "Epoch: 52 \tStep: 233/768 \tAverage training loss: 1.92642\tAverage validation loss: 1080.92505\n",
            "Epoch: 52 \tStep: 333/768 \tAverage training loss: 1.91872\tAverage validation loss: 1030.49365\n",
            "Epoch: 52 \tStep: 433/768 \tAverage training loss: 1.95971\tAverage validation loss: 1004.44550\n",
            "Epoch: 52 \tStep: 533/768 \tAverage training loss: 1.94660\tAverage validation loss: 994.61169\n",
            "Epoch: 52 \tStep: 633/768 \tAverage training loss: 2.03203\tAverage validation loss: 1002.82996\n",
            "Epoch: 52 \tStep: 733/768 \tAverage training loss: 2.00340\tAverage validation loss: 990.88715\n",
            "Epoch: 53 \tStep: 65/768 \tAverage training loss: 2.28128\tAverage validation loss: 993.64862\n",
            "Epoch: 53 \tStep: 165/768 \tAverage training loss: 2.27392\tAverage validation loss: 1046.31226\n",
            "Epoch: 53 \tStep: 265/768 \tAverage training loss: 2.12924\tAverage validation loss: 988.38599\n",
            "Epoch: 53 \tStep: 365/768 \tAverage training loss: 2.11029\tAverage validation loss: 1044.72534\n",
            "Epoch: 53 \tStep: 465/768 \tAverage training loss: 2.17627\tAverage validation loss: 995.65228\n",
            "Epoch: 53 \tStep: 565/768 \tAverage training loss: 2.10647\tAverage validation loss: 997.41418\n",
            "Epoch: 53 \tStep: 665/768 \tAverage training loss: 2.03587\tAverage validation loss: 1017.28528\n",
            "Epoch: 53 \tStep: 765/768 \tAverage training loss: 1.98319\tAverage validation loss: 1027.81079\n",
            "Epoch: 54 \tStep: 97/768 \tAverage training loss: 1.73064\tAverage validation loss: 1103.30054\n",
            "Epoch: 54 \tStep: 197/768 \tAverage training loss: 1.78567\tAverage validation loss: 1064.12573\n",
            "Epoch: 54 \tStep: 297/768 \tAverage training loss: 1.68381\tAverage validation loss: 1034.54565\n",
            "Epoch: 54 \tStep: 397/768 \tAverage training loss: 1.65396\tAverage validation loss: 1022.20508\n",
            "Epoch: 54 \tStep: 497/768 \tAverage training loss: 1.73281\tAverage validation loss: 1123.64636\n",
            "Epoch: 54 \tStep: 597/768 \tAverage training loss: 1.72809\tAverage validation loss: 1083.66235\n",
            "Epoch: 54 \tStep: 697/768 \tAverage training loss: 1.77733\tAverage validation loss: 1044.09155\n",
            "Epoch: 55 \tStep: 29/768 \tAverage training loss: 1.89963\tAverage validation loss: 929.38788\n",
            "Epoch: 55 \tStep: 129/768 \tAverage training loss: 1.94848\tAverage validation loss: 914.93164\n",
            "Epoch: 55 \tStep: 229/768 \tAverage training loss: 1.83398\tAverage validation loss: 915.08856\n",
            "Epoch: 55 \tStep: 329/768 \tAverage training loss: 1.93538\tAverage validation loss: 903.02417\n",
            "Epoch: 55 \tStep: 429/768 \tAverage training loss: 1.93281\tAverage validation loss: 880.45410\n",
            "Epoch: 55 \tStep: 529/768 \tAverage training loss: 1.96493\tAverage validation loss: 870.44989\n",
            "Epoch: 55 \tStep: 629/768 \tAverage training loss: 2.09128\tAverage validation loss: 909.98969\n",
            "Epoch: 55 \tStep: 729/768 \tAverage training loss: 2.01556\tAverage validation loss: 904.00793\n",
            "Epoch: 56 \tStep: 61/768 \tAverage training loss: 2.69260\tAverage validation loss: 976.53125\n",
            "Epoch: 56 \tStep: 161/768 \tAverage training loss: 1.98249\tAverage validation loss: 972.31506\n",
            "Epoch: 56 \tStep: 261/768 \tAverage training loss: 1.95604\tAverage validation loss: 979.43762\n",
            "Epoch: 56 \tStep: 361/768 \tAverage training loss: 1.89466\tAverage validation loss: 943.45483\n",
            "Epoch: 56 \tStep: 461/768 \tAverage training loss: 1.93327\tAverage validation loss: 972.10785\n",
            "Epoch: 56 \tStep: 561/768 \tAverage training loss: 1.81459\tAverage validation loss: 985.12866\n",
            "Epoch: 56 \tStep: 661/768 \tAverage training loss: 1.79264\tAverage validation loss: 952.69312\n",
            "Epoch: 56 \tStep: 761/768 \tAverage training loss: 1.80543\tAverage validation loss: 971.19965\n",
            "Epoch: 57 \tStep: 93/768 \tAverage training loss: 1.90245\tAverage validation loss: 1016.25598\n",
            "Epoch: 57 \tStep: 193/768 \tAverage training loss: 2.06406\tAverage validation loss: 1031.75122\n",
            "Epoch: 57 \tStep: 293/768 \tAverage training loss: 1.99526\tAverage validation loss: 977.89368\n",
            "Epoch: 57 \tStep: 393/768 \tAverage training loss: 1.90654\tAverage validation loss: 1114.17749\n",
            "Epoch: 57 \tStep: 493/768 \tAverage training loss: 1.93013\tAverage validation loss: 1112.19067\n",
            "Epoch: 57 \tStep: 593/768 \tAverage training loss: 1.87527\tAverage validation loss: 1077.63354\n",
            "Epoch: 57 \tStep: 693/768 \tAverage training loss: 1.89165\tAverage validation loss: 1074.65918\n",
            "Epoch: 58 \tStep: 25/768 \tAverage training loss: 1.66684\tAverage validation loss: 1115.79431\n",
            "Epoch: 58 \tStep: 125/768 \tAverage training loss: 1.61077\tAverage validation loss: 1064.08020\n",
            "Epoch: 58 \tStep: 225/768 \tAverage training loss: 2.01040\tAverage validation loss: 1276.72461\n",
            "Epoch: 58 \tStep: 325/768 \tAverage training loss: 2.06159\tAverage validation loss: 1218.96118\n",
            "Epoch: 58 \tStep: 425/768 \tAverage training loss: 2.05918\tAverage validation loss: 1241.90161\n",
            "Epoch: 58 \tStep: 525/768 \tAverage training loss: 2.05456\tAverage validation loss: 1267.39221\n",
            "Epoch: 58 \tStep: 625/768 \tAverage training loss: 2.09994\tAverage validation loss: 1201.20959\n",
            "Epoch: 58 \tStep: 725/768 \tAverage training loss: 2.08267\tAverage validation loss: 1187.95459\n",
            "Epoch: 59 \tStep: 57/768 \tAverage training loss: 1.85471\tAverage validation loss: 1235.05481\n",
            "Epoch: 59 \tStep: 157/768 \tAverage training loss: 1.73165\tAverage validation loss: 1413.78613\n",
            "Epoch: 59 \tStep: 257/768 \tAverage training loss: 1.81096\tAverage validation loss: 1287.20251\n",
            "Epoch: 59 \tStep: 357/768 \tAverage training loss: 1.91982\tAverage validation loss: 1284.68359\n",
            "Epoch: 59 \tStep: 457/768 \tAverage training loss: 1.95429\tAverage validation loss: 1279.92480\n",
            "Epoch: 59 \tStep: 557/768 \tAverage training loss: 2.03804\tAverage validation loss: 1322.86865\n",
            "Epoch: 59 \tStep: 657/768 \tAverage training loss: 1.98892\tAverage validation loss: 1310.75513\n",
            "Epoch: 59 \tStep: 757/768 \tAverage training loss: 1.94431\tAverage validation loss: 1296.68018\n",
            "Epoch: 60 \tStep: 89/768 \tAverage training loss: 1.87518\tAverage validation loss: 966.32660\n",
            "Epoch: 60 \tStep: 189/768 \tAverage training loss: 1.77915\tAverage validation loss: 996.31171\n",
            "Epoch: 60 \tStep: 289/768 \tAverage training loss: 2.36082\tAverage validation loss: 1006.68042\n",
            "Epoch: 60 \tStep: 389/768 \tAverage training loss: 2.26310\tAverage validation loss: 1063.13623\n",
            "Epoch: 60 \tStep: 489/768 \tAverage training loss: 2.31873\tAverage validation loss: 1039.20215\n",
            "Epoch: 60 \tStep: 589/768 \tAverage training loss: 2.42893\tAverage validation loss: 1036.35376\n",
            "Epoch: 60 \tStep: 689/768 \tAverage training loss: 2.37566\tAverage validation loss: 1013.29901\n",
            "Epoch: 61 \tStep: 21/768 \tAverage training loss: 3.17092\tAverage validation loss: 1331.73779\n",
            "Epoch: 61 \tStep: 121/768 \tAverage training loss: 2.69148\tAverage validation loss: 1378.81860\n",
            "Epoch: 61 \tStep: 221/768 \tAverage training loss: 2.30690\tAverage validation loss: 1394.37622\n",
            "Epoch: 61 \tStep: 321/768 \tAverage training loss: 2.46874\tAverage validation loss: 1373.36157\n",
            "Epoch: 61 \tStep: 421/768 \tAverage training loss: 2.29109\tAverage validation loss: 1387.71899\n",
            "Epoch: 61 \tStep: 521/768 \tAverage training loss: 2.22375\tAverage validation loss: 1370.70789\n",
            "Epoch: 61 \tStep: 621/768 \tAverage training loss: 2.24080\tAverage validation loss: 1342.64746\n",
            "Epoch: 61 \tStep: 721/768 \tAverage training loss: 2.39201\tAverage validation loss: 1394.17859\n",
            "Epoch: 62 \tStep: 53/768 \tAverage training loss: 2.46663\tAverage validation loss: 1538.18787\n",
            "Epoch: 62 \tStep: 153/768 \tAverage training loss: 2.46574\tAverage validation loss: 1471.12744\n",
            "Epoch: 62 \tStep: 253/768 \tAverage training loss: 2.26243\tAverage validation loss: 1452.74927\n",
            "Epoch: 62 \tStep: 353/768 \tAverage training loss: 2.16025\tAverage validation loss: 1432.66797\n",
            "Epoch: 62 \tStep: 453/768 \tAverage training loss: 2.18088\tAverage validation loss: 1431.23022\n",
            "Epoch: 62 \tStep: 553/768 \tAverage training loss: 2.16184\tAverage validation loss: 1365.17798\n",
            "Epoch: 62 \tStep: 653/768 \tAverage training loss: 2.12512\tAverage validation loss: 1400.88770\n",
            "Epoch: 62 \tStep: 753/768 \tAverage training loss: 2.05971\tAverage validation loss: 1427.81665\n",
            "Epoch: 63 \tStep: 85/768 \tAverage training loss: 2.18302\tAverage validation loss: 1487.74219\n",
            "Epoch: 63 \tStep: 185/768 \tAverage training loss: 2.03675\tAverage validation loss: 1502.87427\n",
            "Epoch: 63 \tStep: 285/768 \tAverage training loss: 2.04808\tAverage validation loss: 1423.13208\n",
            "Epoch: 63 \tStep: 385/768 \tAverage training loss: 1.99526\tAverage validation loss: 1445.91626\n",
            "Epoch: 63 \tStep: 485/768 \tAverage training loss: 1.93129\tAverage validation loss: 1427.80457\n",
            "Epoch: 63 \tStep: 585/768 \tAverage training loss: 1.87011\tAverage validation loss: 1415.85876\n",
            "Epoch: 63 \tStep: 685/768 \tAverage training loss: 1.83656\tAverage validation loss: 1407.65332\n",
            "Epoch: 64 \tStep: 17/768 \tAverage training loss: 1.51422\tAverage validation loss: 1227.68738\n",
            "Epoch: 64 \tStep: 117/768 \tAverage training loss: 1.58451\tAverage validation loss: 1214.47461\n",
            "Epoch: 64 \tStep: 217/768 \tAverage training loss: 1.67596\tAverage validation loss: 1213.80493\n",
            "Epoch: 64 \tStep: 317/768 \tAverage training loss: 1.70525\tAverage validation loss: 1223.59717\n",
            "Epoch: 64 \tStep: 417/768 \tAverage training loss: 1.82982\tAverage validation loss: 1227.07922\n",
            "Epoch: 64 \tStep: 517/768 \tAverage training loss: 1.83502\tAverage validation loss: 1245.32202\n",
            "Epoch: 64 \tStep: 617/768 \tAverage training loss: 1.80492\tAverage validation loss: 1278.41748\n",
            "Epoch: 64 \tStep: 717/768 \tAverage training loss: 1.87238\tAverage validation loss: 1250.34680\n",
            "Epoch: 65 \tStep: 49/768 \tAverage training loss: 1.78644\tAverage validation loss: 1307.08557\n",
            "Epoch: 65 \tStep: 149/768 \tAverage training loss: 1.84516\tAverage validation loss: 1356.90674\n",
            "Epoch: 65 \tStep: 249/768 \tAverage training loss: 1.79825\tAverage validation loss: 1360.10278\n",
            "Epoch: 65 \tStep: 349/768 \tAverage training loss: 1.84556\tAverage validation loss: 1363.51172\n",
            "Epoch: 65 \tStep: 449/768 \tAverage training loss: 1.82759\tAverage validation loss: 1366.66675\n",
            "Epoch: 65 \tStep: 549/768 \tAverage training loss: 1.85345\tAverage validation loss: 1351.24414\n",
            "Epoch: 65 \tStep: 649/768 \tAverage training loss: 1.81702\tAverage validation loss: 1367.98999\n",
            "Epoch: 65 \tStep: 749/768 \tAverage training loss: 1.84344\tAverage validation loss: 1402.32446\n",
            "Epoch: 66 \tStep: 81/768 \tAverage training loss: 2.40875\tAverage validation loss: 1146.93518\n",
            "Epoch: 66 \tStep: 181/768 \tAverage training loss: 2.29397\tAverage validation loss: 1135.63708\n",
            "Epoch: 66 \tStep: 281/768 \tAverage training loss: 2.13951\tAverage validation loss: 1114.08569\n",
            "Epoch: 66 \tStep: 381/768 \tAverage training loss: 2.03239\tAverage validation loss: 1104.87292\n",
            "Epoch: 66 \tStep: 481/768 \tAverage training loss: 2.01054\tAverage validation loss: 1142.51270\n",
            "Epoch: 66 \tStep: 581/768 \tAverage training loss: 1.91833\tAverage validation loss: 1172.27417\n",
            "Epoch: 66 \tStep: 681/768 \tAverage training loss: 1.90509\tAverage validation loss: 1170.75122\n",
            "Epoch: 67 \tStep: 13/768 \tAverage training loss: 3.12233\tAverage validation loss: 1520.73511\n",
            "Epoch: 67 \tStep: 113/768 \tAverage training loss: 2.00925\tAverage validation loss: 1418.30176\n",
            "Epoch: 67 \tStep: 213/768 \tAverage training loss: 2.03912\tAverage validation loss: 1429.73279\n",
            "Epoch: 67 \tStep: 313/768 \tAverage training loss: 2.08442\tAverage validation loss: 1474.69482\n",
            "Epoch: 67 \tStep: 413/768 \tAverage training loss: 1.98572\tAverage validation loss: 1523.02197\n",
            "Epoch: 67 \tStep: 513/768 \tAverage training loss: 1.95141\tAverage validation loss: 1495.27283\n",
            "Epoch: 67 \tStep: 613/768 \tAverage training loss: 1.96118\tAverage validation loss: 1533.50171\n",
            "Epoch: 67 \tStep: 713/768 \tAverage training loss: 2.02110\tAverage validation loss: 1547.23572\n",
            "Epoch: 68 \tStep: 45/768 \tAverage training loss: 1.81624\tAverage validation loss: 1434.90186\n",
            "Epoch: 68 \tStep: 145/768 \tAverage training loss: 1.74105\tAverage validation loss: 1376.27954\n",
            "Epoch: 68 \tStep: 245/768 \tAverage training loss: 1.78018\tAverage validation loss: 1414.15625\n",
            "Epoch: 68 \tStep: 345/768 \tAverage training loss: 2.18240\tAverage validation loss: 1448.01404\n",
            "Epoch: 68 \tStep: 445/768 \tAverage training loss: 2.15405\tAverage validation loss: 1455.64185\n",
            "Epoch: 68 \tStep: 545/768 \tAverage training loss: 2.14323\tAverage validation loss: 1447.12476\n",
            "Epoch: 68 \tStep: 645/768 \tAverage training loss: 2.14236\tAverage validation loss: 1423.38989\n",
            "Epoch: 68 \tStep: 745/768 \tAverage training loss: 2.15395\tAverage validation loss: 1442.16553\n",
            "Epoch: 69 \tStep: 77/768 \tAverage training loss: 2.17252\tAverage validation loss: 1495.17468\n",
            "Epoch: 69 \tStep: 177/768 \tAverage training loss: 2.12347\tAverage validation loss: 1489.58594\n",
            "Epoch: 69 \tStep: 277/768 \tAverage training loss: 1.93751\tAverage validation loss: 1336.71423\n",
            "Epoch: 69 \tStep: 377/768 \tAverage training loss: 1.86314\tAverage validation loss: 1348.61426\n",
            "Epoch: 69 \tStep: 477/768 \tAverage training loss: 1.84304\tAverage validation loss: 1405.53247\n",
            "Epoch: 69 \tStep: 577/768 \tAverage training loss: 1.86052\tAverage validation loss: 1385.47070\n",
            "Epoch: 69 \tStep: 677/768 \tAverage training loss: 1.85957\tAverage validation loss: 1380.00439\n",
            "Epoch: 70 \tStep: 9/768 \tAverage training loss: 3.10016\tAverage validation loss: 1376.38611\n",
            "Epoch: 70 \tStep: 109/768 \tAverage training loss: 2.11180\tAverage validation loss: 1366.87256\n",
            "Epoch: 70 \tStep: 209/768 \tAverage training loss: 2.36844\tAverage validation loss: 1361.99341\n",
            "Epoch: 70 \tStep: 309/768 \tAverage training loss: 2.14858\tAverage validation loss: 1364.49744\n",
            "Epoch: 70 \tStep: 409/768 \tAverage training loss: 2.19079\tAverage validation loss: 1286.45898\n",
            "Epoch: 70 \tStep: 509/768 \tAverage training loss: 2.10838\tAverage validation loss: 1348.72815\n",
            "Epoch: 70 \tStep: 609/768 \tAverage training loss: 2.05381\tAverage validation loss: 1327.76196\n",
            "Epoch: 70 \tStep: 709/768 \tAverage training loss: 2.02054\tAverage validation loss: 1315.39282\n",
            "Epoch: 71 \tStep: 41/768 \tAverage training loss: 2.36782\tAverage validation loss: 1165.06323\n",
            "Epoch: 71 \tStep: 141/768 \tAverage training loss: 2.31931\tAverage validation loss: 1274.30017\n",
            "Epoch: 71 \tStep: 241/768 \tAverage training loss: 2.08180\tAverage validation loss: 1241.56421\n",
            "Epoch: 71 \tStep: 341/768 \tAverage training loss: 1.99086\tAverage validation loss: 1269.58081\n",
            "Epoch: 71 \tStep: 441/768 \tAverage training loss: 1.94159\tAverage validation loss: 1286.76294\n",
            "Epoch: 71 \tStep: 541/768 \tAverage training loss: 1.89572\tAverage validation loss: 1261.29614\n",
            "Epoch: 71 \tStep: 641/768 \tAverage training loss: 1.91537\tAverage validation loss: 1278.32666\n",
            "Epoch: 71 \tStep: 741/768 \tAverage training loss: 1.92815\tAverage validation loss: 1315.05420\n",
            "Epoch: 72 \tStep: 73/768 \tAverage training loss: 1.81722\tAverage validation loss: 1381.14136\n",
            "Epoch: 72 \tStep: 173/768 \tAverage training loss: 2.01235\tAverage validation loss: 1294.20190\n",
            "Epoch: 72 \tStep: 273/768 \tAverage training loss: 1.85364\tAverage validation loss: 1289.17029\n",
            "Epoch: 72 \tStep: 373/768 \tAverage training loss: 1.91589\tAverage validation loss: 1347.25879\n",
            "Epoch: 72 \tStep: 473/768 \tAverage training loss: 1.96681\tAverage validation loss: 1299.34082\n",
            "Epoch: 72 \tStep: 573/768 \tAverage training loss: 1.99710\tAverage validation loss: 1306.16394\n",
            "Epoch: 72 \tStep: 673/768 \tAverage training loss: 1.98565\tAverage validation loss: 1321.53174\n",
            "Epoch: 73 \tStep: 5/768 \tAverage training loss: 1.78093\tAverage validation loss: 1269.21899\n",
            "Epoch: 73 \tStep: 105/768 \tAverage training loss: 1.66383\tAverage validation loss: 1278.85535\n",
            "Epoch: 73 \tStep: 205/768 \tAverage training loss: 1.76364\tAverage validation loss: 1225.29724\n",
            "Epoch: 73 \tStep: 305/768 \tAverage training loss: 1.90735\tAverage validation loss: 1222.05957\n",
            "Epoch: 73 \tStep: 405/768 \tAverage training loss: 1.89273\tAverage validation loss: 1298.62048\n",
            "Epoch: 73 \tStep: 505/768 \tAverage training loss: 1.89802\tAverage validation loss: 1206.58472\n",
            "Epoch: 73 \tStep: 605/768 \tAverage training loss: 1.95644\tAverage validation loss: 1234.53027\n",
            "Epoch: 73 \tStep: 705/768 \tAverage training loss: 1.93655\tAverage validation loss: 1197.67310\n",
            "Epoch: 74 \tStep: 37/768 \tAverage training loss: 1.60478\tAverage validation loss: 1272.50476\n",
            "Epoch: 74 \tStep: 137/768 \tAverage training loss: 1.63886\tAverage validation loss: 1339.41992\n",
            "Epoch: 74 \tStep: 237/768 \tAverage training loss: 1.88848\tAverage validation loss: 1312.17944\n",
            "Epoch: 74 \tStep: 337/768 \tAverage training loss: 1.96493\tAverage validation loss: 1282.59082\n",
            "Epoch: 74 \tStep: 437/768 \tAverage training loss: 1.88516\tAverage validation loss: 1279.69690\n",
            "Epoch: 74 \tStep: 537/768 \tAverage training loss: 1.85612\tAverage validation loss: 1341.65210\n",
            "Epoch: 74 \tStep: 637/768 \tAverage training loss: 1.87086\tAverage validation loss: 1258.38953\n",
            "Epoch: 74 \tStep: 737/768 \tAverage training loss: 1.87671\tAverage validation loss: 1279.80640\n",
            "Epoch: 75 \tStep: 69/768 \tAverage training loss: 1.86453\tAverage validation loss: 1266.78796\n",
            "Epoch: 75 \tStep: 169/768 \tAverage training loss: 1.81685\tAverage validation loss: 1295.66418\n",
            "Epoch: 75 \tStep: 269/768 \tAverage training loss: 1.81335\tAverage validation loss: 1334.62317\n",
            "Epoch: 75 \tStep: 369/768 \tAverage training loss: 1.84708\tAverage validation loss: 1428.41016\n",
            "Epoch: 75 \tStep: 469/768 \tAverage training loss: 1.79976\tAverage validation loss: 1370.34814\n",
            "Epoch: 75 \tStep: 569/768 \tAverage training loss: 1.83263\tAverage validation loss: 1273.61487\n",
            "Epoch: 75 \tStep: 669/768 \tAverage training loss: 1.83179\tAverage validation loss: 1219.89307\n",
            "Epoch: 76 \tStep: 1/768 \tAverage training loss: 3.50900\tAverage validation loss: 1285.63452\n",
            "Epoch: 76 \tStep: 101/768 \tAverage training loss: 2.23397\tAverage validation loss: 1016.75659\n",
            "Epoch: 76 \tStep: 201/768 \tAverage training loss: 2.19939\tAverage validation loss: 1040.19507\n",
            "Epoch: 76 \tStep: 301/768 \tAverage training loss: 2.37573\tAverage validation loss: 1042.55249\n",
            "Epoch: 76 \tStep: 401/768 \tAverage training loss: 2.47247\tAverage validation loss: 1153.65417\n",
            "Epoch: 76 \tStep: 501/768 \tAverage training loss: 2.39156\tAverage validation loss: 1173.61035\n",
            "Epoch: 76 \tStep: 601/768 \tAverage training loss: 2.32267\tAverage validation loss: 1147.01196\n",
            "Epoch: 76 \tStep: 701/768 \tAverage training loss: 2.24187\tAverage validation loss: 1100.11072\n",
            "Epoch: 77 \tStep: 33/768 \tAverage training loss: 2.74907\tAverage validation loss: 1303.77429\n",
            "Epoch: 77 \tStep: 133/768 \tAverage training loss: 2.33181\tAverage validation loss: 1280.58618\n",
            "Epoch: 77 \tStep: 233/768 \tAverage training loss: 2.18808\tAverage validation loss: 1224.73804\n",
            "Epoch: 77 \tStep: 333/768 \tAverage training loss: 2.06276\tAverage validation loss: 1272.02295\n",
            "Epoch: 77 \tStep: 433/768 \tAverage training loss: 2.02991\tAverage validation loss: 1294.61365\n",
            "Epoch: 77 \tStep: 533/768 \tAverage training loss: 2.01804\tAverage validation loss: 1267.86584\n",
            "Epoch: 77 \tStep: 633/768 \tAverage training loss: 2.05977\tAverage validation loss: 1268.27502\n",
            "Epoch: 77 \tStep: 733/768 \tAverage training loss: 2.05116\tAverage validation loss: 1261.70435\n",
            "Epoch: 78 \tStep: 65/768 \tAverage training loss: 2.68248\tAverage validation loss: 1306.08630\n",
            "Epoch: 78 \tStep: 165/768 \tAverage training loss: 2.31827\tAverage validation loss: 1263.98169\n",
            "Epoch: 78 \tStep: 265/768 \tAverage training loss: 2.13540\tAverage validation loss: 1250.87305\n",
            "Epoch: 78 \tStep: 365/768 \tAverage training loss: 2.05171\tAverage validation loss: 1287.49316\n",
            "Epoch: 78 \tStep: 465/768 \tAverage training loss: 2.11018\tAverage validation loss: 1282.16138\n",
            "Epoch: 78 \tStep: 565/768 \tAverage training loss: 2.06085\tAverage validation loss: 1295.73193\n",
            "Epoch: 78 \tStep: 665/768 \tAverage training loss: 2.04002\tAverage validation loss: 1285.54907\n",
            "Epoch: 78 \tStep: 765/768 \tAverage training loss: 2.01092\tAverage validation loss: 1292.13379\n",
            "Epoch: 79 \tStep: 97/768 \tAverage training loss: 1.59290\tAverage validation loss: 1320.55835\n",
            "Epoch: 79 \tStep: 197/768 \tAverage training loss: 1.83294\tAverage validation loss: 1338.10217\n",
            "Epoch: 79 \tStep: 297/768 \tAverage training loss: 1.89274\tAverage validation loss: 1293.92542\n",
            "Epoch: 79 \tStep: 397/768 \tAverage training loss: 1.99287\tAverage validation loss: 1273.95532\n",
            "Epoch: 79 \tStep: 497/768 \tAverage training loss: 1.96427\tAverage validation loss: 1252.78076\n",
            "Epoch: 79 \tStep: 597/768 \tAverage training loss: 1.98947\tAverage validation loss: 1243.06836\n",
            "Epoch: 79 \tStep: 697/768 \tAverage training loss: 1.95765\tAverage validation loss: 1245.36011\n",
            "Epoch: 80 \tStep: 29/768 \tAverage training loss: 1.31682\tAverage validation loss: 1229.93799\n",
            "Epoch: 80 \tStep: 129/768 \tAverage training loss: 1.31624\tAverage validation loss: 1227.86621\n",
            "Epoch: 80 \tStep: 229/768 \tAverage training loss: 1.51338\tAverage validation loss: 1239.72791\n",
            "Epoch: 80 \tStep: 329/768 \tAverage training loss: 1.62713\tAverage validation loss: 1224.78662\n",
            "Epoch: 80 \tStep: 429/768 \tAverage training loss: 1.81834\tAverage validation loss: 1279.02014\n",
            "Epoch: 80 \tStep: 529/768 \tAverage training loss: 1.79927\tAverage validation loss: 1279.80469\n",
            "Epoch: 80 \tStep: 629/768 \tAverage training loss: 1.80760\tAverage validation loss: 1293.77686\n",
            "Epoch: 80 \tStep: 729/768 \tAverage training loss: 1.82528\tAverage validation loss: 1333.27979\n",
            "Epoch: 81 \tStep: 61/768 \tAverage training loss: 3.29005\tAverage validation loss: 1427.18799\n",
            "Epoch: 81 \tStep: 161/768 \tAverage training loss: 2.36867\tAverage validation loss: 1388.11951\n",
            "Epoch: 81 \tStep: 261/768 \tAverage training loss: 2.05652\tAverage validation loss: 1372.59302\n",
            "Epoch: 81 \tStep: 361/768 \tAverage training loss: 2.03376\tAverage validation loss: 1370.61023\n",
            "Epoch: 81 \tStep: 461/768 \tAverage training loss: 1.99597\tAverage validation loss: 1362.71899\n",
            "Epoch: 81 \tStep: 561/768 \tAverage training loss: 2.09071\tAverage validation loss: 1328.69873\n",
            "Epoch: 81 \tStep: 661/768 \tAverage training loss: 2.08398\tAverage validation loss: 1266.54102\n",
            "Epoch: 81 \tStep: 761/768 \tAverage training loss: 2.09196\tAverage validation loss: 1247.47510\n",
            "Epoch: 82 \tStep: 93/768 \tAverage training loss: 2.13211\tAverage validation loss: 1295.90417\n",
            "Epoch: 82 \tStep: 193/768 \tAverage training loss: 2.06042\tAverage validation loss: 1323.51855\n",
            "Epoch: 82 \tStep: 293/768 \tAverage training loss: 2.03011\tAverage validation loss: 1314.54541\n",
            "Epoch: 82 \tStep: 393/768 \tAverage training loss: 2.07753\tAverage validation loss: 1331.33643\n",
            "Epoch: 82 \tStep: 493/768 \tAverage training loss: 2.06854\tAverage validation loss: 1351.78979\n",
            "Epoch: 82 \tStep: 593/768 \tAverage training loss: 2.14455\tAverage validation loss: 1387.23145\n",
            "Epoch: 82 \tStep: 693/768 \tAverage training loss: 2.25619\tAverage validation loss: 1332.04663\n",
            "Epoch: 83 \tStep: 25/768 \tAverage training loss: 2.94888\tAverage validation loss: 1901.27832\n",
            "Epoch: 83 \tStep: 125/768 \tAverage training loss: 2.46157\tAverage validation loss: 1693.40857\n",
            "Epoch: 83 \tStep: 225/768 \tAverage training loss: 2.17366\tAverage validation loss: 1681.64783\n",
            "Epoch: 83 \tStep: 325/768 \tAverage training loss: 2.18859\tAverage validation loss: 1744.47437\n",
            "Epoch: 83 \tStep: 425/768 \tAverage training loss: 2.20591\tAverage validation loss: 1732.84790\n",
            "Epoch: 83 \tStep: 525/768 \tAverage training loss: 2.16814\tAverage validation loss: 1700.21216\n",
            "Epoch: 83 \tStep: 625/768 \tAverage training loss: 2.11055\tAverage validation loss: 1655.76306\n",
            "Epoch: 83 \tStep: 725/768 \tAverage training loss: 2.02917\tAverage validation loss: 1638.99609\n",
            "Epoch: 84 \tStep: 57/768 \tAverage training loss: 1.96323\tAverage validation loss: 1139.06812\n",
            "Epoch: 84 \tStep: 157/768 \tAverage training loss: 2.13319\tAverage validation loss: 1154.88281\n",
            "Epoch: 84 \tStep: 257/768 \tAverage training loss: 2.11443\tAverage validation loss: 1138.36353\n",
            "Epoch: 84 \tStep: 357/768 \tAverage training loss: 2.04640\tAverage validation loss: 1145.13354\n",
            "Epoch: 84 \tStep: 457/768 \tAverage training loss: 2.08393\tAverage validation loss: 1113.61182\n",
            "Epoch: 84 \tStep: 557/768 \tAverage training loss: 2.05499\tAverage validation loss: 1140.73438\n",
            "Epoch: 84 \tStep: 657/768 \tAverage training loss: 2.06073\tAverage validation loss: 1159.05188\n",
            "Epoch: 84 \tStep: 757/768 \tAverage training loss: 2.07297\tAverage validation loss: 1134.49036\n",
            "Epoch: 85 \tStep: 89/768 \tAverage training loss: 1.53801\tAverage validation loss: 1355.75232\n",
            "Epoch: 85 \tStep: 189/768 \tAverage training loss: 1.72389\tAverage validation loss: 1316.88062\n",
            "Epoch: 85 \tStep: 289/768 \tAverage training loss: 1.80486\tAverage validation loss: 1318.88403\n",
            "Epoch: 85 \tStep: 389/768 \tAverage training loss: 1.85396\tAverage validation loss: 1296.25867\n",
            "Epoch: 85 \tStep: 489/768 \tAverage training loss: 1.89474\tAverage validation loss: 1303.61890\n",
            "Epoch: 85 \tStep: 589/768 \tAverage training loss: 1.94875\tAverage validation loss: 1297.52271\n",
            "Epoch: 85 \tStep: 689/768 \tAverage training loss: 1.91848\tAverage validation loss: 1306.62744\n",
            "Epoch: 86 \tStep: 21/768 \tAverage training loss: 1.83649\tAverage validation loss: 1180.22266\n",
            "Epoch: 86 \tStep: 121/768 \tAverage training loss: 2.30506\tAverage validation loss: 1182.66895\n",
            "Epoch: 86 \tStep: 221/768 \tAverage training loss: 2.22781\tAverage validation loss: 1192.38330\n",
            "Epoch: 86 \tStep: 321/768 \tAverage training loss: 2.17746\tAverage validation loss: 1154.04895\n",
            "Epoch: 86 \tStep: 421/768 \tAverage training loss: 2.25073\tAverage validation loss: 1143.34607\n",
            "Epoch: 86 \tStep: 521/768 \tAverage training loss: 2.24832\tAverage validation loss: 1141.37036\n",
            "Epoch: 86 \tStep: 621/768 \tAverage training loss: 2.23549\tAverage validation loss: 1156.69604\n",
            "Epoch: 86 \tStep: 721/768 \tAverage training loss: 2.22892\tAverage validation loss: 1127.70605\n",
            "Epoch: 87 \tStep: 53/768 \tAverage training loss: 2.70751\tAverage validation loss: 1361.89868\n",
            "Epoch: 87 \tStep: 153/768 \tAverage training loss: 2.35634\tAverage validation loss: 1386.12964\n",
            "Epoch: 87 \tStep: 253/768 \tAverage training loss: 2.27003\tAverage validation loss: 1413.49194\n",
            "Epoch: 87 \tStep: 353/768 \tAverage training loss: 2.21758\tAverage validation loss: 1456.99243\n",
            "Epoch: 87 \tStep: 453/768 \tAverage training loss: 2.13220\tAverage validation loss: 1389.58032\n",
            "Epoch: 87 \tStep: 553/768 \tAverage training loss: 2.14933\tAverage validation loss: 1447.51111\n",
            "Epoch: 87 \tStep: 653/768 \tAverage training loss: 2.14204\tAverage validation loss: 1366.73181\n",
            "Epoch: 87 \tStep: 753/768 \tAverage training loss: 2.19616\tAverage validation loss: 1456.80115\n",
            "Epoch: 88 \tStep: 85/768 \tAverage training loss: 2.85360\tAverage validation loss: 1386.60156\n",
            "Epoch: 88 \tStep: 185/768 \tAverage training loss: 2.73018\tAverage validation loss: 1423.52759\n",
            "Epoch: 88 \tStep: 285/768 \tAverage training loss: 2.61133\tAverage validation loss: 1391.13257\n",
            "Epoch: 88 \tStep: 385/768 \tAverage training loss: 2.36295\tAverage validation loss: 1418.43359\n",
            "Epoch: 88 \tStep: 485/768 \tAverage training loss: 2.37934\tAverage validation loss: 1373.89343\n",
            "Epoch: 88 \tStep: 585/768 \tAverage training loss: 2.36517\tAverage validation loss: 1355.45996\n",
            "Epoch: 88 \tStep: 685/768 \tAverage training loss: 2.27019\tAverage validation loss: 1252.29517\n",
            "Epoch: 89 \tStep: 17/768 \tAverage training loss: 1.88794\tAverage validation loss: 1238.86621\n",
            "Epoch: 89 \tStep: 117/768 \tAverage training loss: 2.39535\tAverage validation loss: 1201.16296\n",
            "Epoch: 89 \tStep: 217/768 \tAverage training loss: 2.24494\tAverage validation loss: 1216.29126\n",
            "Epoch: 89 \tStep: 317/768 \tAverage training loss: 2.24510\tAverage validation loss: 1300.58850\n",
            "Epoch: 89 \tStep: 417/768 \tAverage training loss: 2.28190\tAverage validation loss: 1259.39270\n",
            "Epoch: 89 \tStep: 517/768 \tAverage training loss: 2.28777\tAverage validation loss: 1244.94263\n",
            "Epoch: 89 \tStep: 617/768 \tAverage training loss: 2.25331\tAverage validation loss: 1233.91260\n",
            "Epoch: 89 \tStep: 717/768 \tAverage training loss: 2.20943\tAverage validation loss: 1273.59424\n",
            "Epoch: 90 \tStep: 49/768 \tAverage training loss: 2.44413\tAverage validation loss: 1184.02637\n",
            "Epoch: 90 \tStep: 149/768 \tAverage training loss: 2.51635\tAverage validation loss: 1142.76819\n",
            "Epoch: 90 \tStep: 249/768 \tAverage training loss: 2.42953\tAverage validation loss: 1145.76428\n",
            "Epoch: 90 \tStep: 349/768 \tAverage training loss: 2.26317\tAverage validation loss: 1114.25269\n",
            "Epoch: 90 \tStep: 449/768 \tAverage training loss: 2.12737\tAverage validation loss: 1086.52222\n",
            "Epoch: 90 \tStep: 549/768 \tAverage training loss: 2.06591\tAverage validation loss: 1059.21777\n",
            "Epoch: 90 \tStep: 649/768 \tAverage training loss: 2.03750\tAverage validation loss: 1085.92456\n",
            "Epoch: 90 \tStep: 749/768 \tAverage training loss: 1.98894\tAverage validation loss: 939.33569\n",
            "Epoch: 91 \tStep: 81/768 \tAverage training loss: 2.12437\tAverage validation loss: 1084.48450\n",
            "Epoch: 91 \tStep: 181/768 \tAverage training loss: 2.21771\tAverage validation loss: 1062.21118\n",
            "Epoch: 91 \tStep: 281/768 \tAverage training loss: 2.14562\tAverage validation loss: 1063.64636\n",
            "Epoch: 91 \tStep: 381/768 \tAverage training loss: 2.17009\tAverage validation loss: 1006.23022\n",
            "Epoch: 91 \tStep: 481/768 \tAverage training loss: 2.10239\tAverage validation loss: 1067.25488\n",
            "Epoch: 91 \tStep: 581/768 \tAverage training loss: 2.08547\tAverage validation loss: 1035.91895\n",
            "Epoch: 91 \tStep: 681/768 \tAverage training loss: 2.16439\tAverage validation loss: 1097.55042\n",
            "Epoch: 92 \tStep: 13/768 \tAverage training loss: 3.09401\tAverage validation loss: 1151.79480\n",
            "Epoch: 92 \tStep: 113/768 \tAverage training loss: 2.28698\tAverage validation loss: 1395.35840\n",
            "Epoch: 92 \tStep: 213/768 \tAverage training loss: 2.31809\tAverage validation loss: 1394.55273\n",
            "Epoch: 92 \tStep: 313/768 \tAverage training loss: 2.32238\tAverage validation loss: 1397.44092\n",
            "Epoch: 92 \tStep: 413/768 \tAverage training loss: 2.30284\tAverage validation loss: 1413.70349\n",
            "Epoch: 92 \tStep: 513/768 \tAverage training loss: 2.23088\tAverage validation loss: 1440.22156\n",
            "Epoch: 92 \tStep: 613/768 \tAverage training loss: 2.14082\tAverage validation loss: 1412.59363\n",
            "Epoch: 92 \tStep: 713/768 \tAverage training loss: 2.10545\tAverage validation loss: 1529.34009\n",
            "Epoch: 93 \tStep: 45/768 \tAverage training loss: 2.53978\tAverage validation loss: 1129.72217\n",
            "Epoch: 93 \tStep: 145/768 \tAverage training loss: 2.31504\tAverage validation loss: 1151.47754\n",
            "Epoch: 93 \tStep: 245/768 \tAverage training loss: 2.33400\tAverage validation loss: 1108.02539\n",
            "Epoch: 93 \tStep: 345/768 \tAverage training loss: 2.32670\tAverage validation loss: 1086.91553\n",
            "Epoch: 93 \tStep: 445/768 \tAverage training loss: 2.28033\tAverage validation loss: 1104.72705\n",
            "Epoch: 93 \tStep: 545/768 \tAverage training loss: 2.24864\tAverage validation loss: 1140.76660\n",
            "Epoch: 93 \tStep: 645/768 \tAverage training loss: 2.24098\tAverage validation loss: 1163.20825\n",
            "Epoch: 93 \tStep: 745/768 \tAverage training loss: 2.18203\tAverage validation loss: 1141.94836\n",
            "Epoch: 94 \tStep: 77/768 \tAverage training loss: 2.70867\tAverage validation loss: 1283.15234\n",
            "Epoch: 94 \tStep: 177/768 \tAverage training loss: 2.11246\tAverage validation loss: 1253.94751\n",
            "Epoch: 94 \tStep: 277/768 \tAverage training loss: 1.95713\tAverage validation loss: 1211.90125\n",
            "Epoch: 94 \tStep: 377/768 \tAverage training loss: 2.05479\tAverage validation loss: 1160.38086\n",
            "Epoch: 94 \tStep: 477/768 \tAverage training loss: 2.05892\tAverage validation loss: 1228.71741\n",
            "Epoch: 94 \tStep: 577/768 \tAverage training loss: 2.04019\tAverage validation loss: 1240.20288\n",
            "Epoch: 94 \tStep: 677/768 \tAverage training loss: 2.07621\tAverage validation loss: 1266.18750\n",
            "Epoch: 95 \tStep: 9/768 \tAverage training loss: 3.44836\tAverage validation loss: 1303.43823\n",
            "Epoch: 95 \tStep: 109/768 \tAverage training loss: 2.05756\tAverage validation loss: 1325.32166\n",
            "Epoch: 95 \tStep: 209/768 \tAverage training loss: 2.15977\tAverage validation loss: 1448.70093\n",
            "Epoch: 95 \tStep: 309/768 \tAverage training loss: 2.15167\tAverage validation loss: 1232.88367\n",
            "Epoch: 95 \tStep: 409/768 \tAverage training loss: 2.13077\tAverage validation loss: 1188.46484\n",
            "Epoch: 95 \tStep: 509/768 \tAverage training loss: 2.07637\tAverage validation loss: 1135.12732\n",
            "Epoch: 95 \tStep: 609/768 \tAverage training loss: 2.05036\tAverage validation loss: 1145.39624\n",
            "Epoch: 95 \tStep: 709/768 \tAverage training loss: 2.05050\tAverage validation loss: 1177.62756\n",
            "Epoch: 96 \tStep: 41/768 \tAverage training loss: 1.83450\tAverage validation loss: 1315.35852\n",
            "Epoch: 96 \tStep: 141/768 \tAverage training loss: 1.95401\tAverage validation loss: 1316.24829\n",
            "Epoch: 96 \tStep: 241/768 \tAverage training loss: 1.93450\tAverage validation loss: 1295.79565\n",
            "Epoch: 96 \tStep: 341/768 \tAverage training loss: 1.95393\tAverage validation loss: 1304.49512\n",
            "Epoch: 96 \tStep: 441/768 \tAverage training loss: 2.00624\tAverage validation loss: 1292.73938\n",
            "Epoch: 96 \tStep: 541/768 \tAverage training loss: 1.90209\tAverage validation loss: 1318.45459\n",
            "Epoch: 96 \tStep: 641/768 \tAverage training loss: 1.94449\tAverage validation loss: 1242.82593\n",
            "Epoch: 96 \tStep: 741/768 \tAverage training loss: 2.02509\tAverage validation loss: 1322.10608\n",
            "Epoch: 97 \tStep: 73/768 \tAverage training loss: 1.83751\tAverage validation loss: 1385.46875\n",
            "Epoch: 97 \tStep: 173/768 \tAverage training loss: 1.81210\tAverage validation loss: 1323.65393\n",
            "Epoch: 97 \tStep: 273/768 \tAverage training loss: 1.85579\tAverage validation loss: 1290.39917\n",
            "Epoch: 97 \tStep: 373/768 \tAverage training loss: 1.85703\tAverage validation loss: 1281.97742\n",
            "Epoch: 97 \tStep: 473/768 \tAverage training loss: 1.89366\tAverage validation loss: 1359.40784\n",
            "Epoch: 97 \tStep: 573/768 \tAverage training loss: 1.93916\tAverage validation loss: 1382.63306\n",
            "Epoch: 97 \tStep: 673/768 \tAverage training loss: 1.92123\tAverage validation loss: 1395.31812\n",
            "Epoch: 98 \tStep: 5/768 \tAverage training loss: 1.99167\tAverage validation loss: 1434.16724\n",
            "Epoch: 98 \tStep: 105/768 \tAverage training loss: 2.34788\tAverage validation loss: 1410.11938\n",
            "Epoch: 98 \tStep: 205/768 \tAverage training loss: 2.19449\tAverage validation loss: 1509.45312\n",
            "Epoch: 98 \tStep: 305/768 \tAverage training loss: 2.53980\tAverage validation loss: 1318.96936\n",
            "Epoch: 98 \tStep: 405/768 \tAverage training loss: 2.49238\tAverage validation loss: 1279.41162\n",
            "Epoch: 98 \tStep: 505/768 \tAverage training loss: 2.46548\tAverage validation loss: 1255.56201\n",
            "Epoch: 98 \tStep: 605/768 \tAverage training loss: 2.41866\tAverage validation loss: 1322.27979\n",
            "Epoch: 98 \tStep: 705/768 \tAverage training loss: 2.41223\tAverage validation loss: 1319.14954\n",
            "Epoch: 99 \tStep: 37/768 \tAverage training loss: 3.44421\tAverage validation loss: 1323.26221\n",
            "Epoch: 99 \tStep: 137/768 \tAverage training loss: 2.06782\tAverage validation loss: 1314.55811\n",
            "Epoch: 99 \tStep: 237/768 \tAverage training loss: 2.31925\tAverage validation loss: 1264.37183\n",
            "Epoch: 99 \tStep: 337/768 \tAverage training loss: 2.28676\tAverage validation loss: 1278.11035\n",
            "Epoch: 99 \tStep: 437/768 \tAverage training loss: 2.26514\tAverage validation loss: 1264.29553\n",
            "Epoch: 99 \tStep: 537/768 \tAverage training loss: 2.19867\tAverage validation loss: 1244.80542\n",
            "Epoch: 99 \tStep: 637/768 \tAverage training loss: 2.19118\tAverage validation loss: 1192.21313\n",
            "Epoch: 99 \tStep: 737/768 \tAverage training loss: 2.17398\tAverage validation loss: 1368.71265\n",
            "Epoch: 100 \tStep: 69/768 \tAverage training loss: 2.32329\tAverage validation loss: 1329.65186\n",
            "Epoch: 100 \tStep: 169/768 \tAverage training loss: 2.32268\tAverage validation loss: 1351.10291\n",
            "Epoch: 100 \tStep: 269/768 \tAverage training loss: 2.14140\tAverage validation loss: 1322.30298\n",
            "Epoch: 100 \tStep: 369/768 \tAverage training loss: 2.10457\tAverage validation loss: 1309.71423\n",
            "Epoch: 100 \tStep: 469/768 \tAverage training loss: 2.12911\tAverage validation loss: 1347.65723\n",
            "Epoch: 100 \tStep: 569/768 \tAverage training loss: 2.12473\tAverage validation loss: 1368.11890\n",
            "Epoch: 100 \tStep: 669/768 \tAverage training loss: 2.13444\tAverage validation loss: 1323.52930\n",
            "Training complete... Final Loss: 2.108959197998047\n",
            "Seconds elapsed:595.9816462993622\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BnceNtXEQQ6d",
        "outputId": "170dd5bf-5dce-42ce-c02f-f7eb0abbba18"
      },
      "source": [
        "iters = list(range(1, epochs*len(trainloader), 100))\r\n",
        "\r\n",
        "def epoch_lines():\r\n",
        "    for x in range(0, iters[-1], len(trainloader)):\r\n",
        "        plt.axvline(x=x, lw=0.05, c='black')\r\n",
        "\r\n",
        "_, ax1 = plt.subplots()\r\n",
        "ax1.plot(iters, lstm_loss)\r\n",
        "ax1.plot(iters, gru_loss)\r\n",
        "epoch_lines()\r\n",
        "plt.title('Training Loss')\r\n",
        "plt.xlabel('Iterations')\r\n",
        "plt.ylabel('Average Loss')\r\n",
        "plt.legend(['LSTM','GRU'])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "_, ax2 = plt.subplots()\r\n",
        "ax2.plot(iters, [gru_loss[i]-lstm_loss[i] for i in range(len(lstm_loss))])\r\n",
        "plt.title('Training Loss $\\Delta$ (GRU - LSTM)')\r\n",
        "epoch_lines()\r\n",
        "plt.xlabel('Iterations')\r\n",
        "plt.ylabel('Loss $\\Delta$')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "_, ax3 = plt.subplots()\r\n",
        "ax3.plot(iters, lstm_val_loss)\r\n",
        "ax3.plot(iters, gru_val_loss)\r\n",
        "epoch_lines()\r\n",
        "plt.title('Validation Loss')\r\n",
        "plt.xlabel('Iterations')\r\n",
        "plt.ylabel('Average Loss')\r\n",
        "plt.legend(['LSTM','GRU'])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "_, ax4 = plt.subplots()\r\n",
        "ax4.plot(iters, [gru_val_loss[i]-lstm_val_loss[i] for i in range(len(lstm_val_loss))])\r\n",
        "epoch_lines()\r\n",
        "plt.title('Validation Loss $\\Delta$ (GRU - LSTM)')\r\n",
        "plt.xlabel('Iterations')\r\n",
        "plt.ylabel('Loss $\\Delta$')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "lstm_eval = validate(lstm_net, testloader, model='LSTM')\r\n",
        "gru_eval = validate(gru_net, testloader, model='GRU')\r\n",
        "\r\n",
        "print('Final LSTM validation loss:{}'.format(lstm_eval))\r\n",
        "print('Final GRU validation loss:{}'.format(gru_eval))\r\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Final LSTM validation loss:1319.904296875\n",
            "Final GRU validation loss:1326.589111328125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQmIGdGmT-g2"
      },
      "source": [
        "'''\r\n",
        "TODO:\r\n",
        "get loss on test set and graph\r\n",
        "fit the original stock curve\r\n",
        "USE SCALED DATA 'data' instead of df\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH3B2eTJU0Bb"
      },
      "source": [
        "'''\r\n",
        "Dataset augmentation - ideas:\r\n",
        "1. Use the open prices for stocks as a separate dataset\r\n",
        "2. Add Gaussian Noise to the dataset\r\n",
        "3. Run sequences backwards - market doesn't seem symmetrical though\r\n",
        "\r\n",
        "Notes:\r\n",
        "Stateful vs stateless?\r\n",
        "What is causing the large jumps with epochs?\r\n",
        "Variable learning rate\r\n",
        "Tweak parameters and hyperparameters\r\n",
        "Test multiple symbols at the same time\r\n",
        "Tanh vs ReLU?\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJqETisl3KS-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}